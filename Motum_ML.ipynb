{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad200de-745b-4006-8711-0e64737aa82b",
   "metadata": {},
   "source": [
    "Modelle vergleichen über CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c16cb8-f281-4df9-a7b3-c64d7477a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# Führt CV durch und berechnet die Metriken\n",
    "def repeated_k_fold(model, X, y, n_splits=5, n_repeats=10):\n",
    "    rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "\n",
    "    accuracy_train, accuracy_test = [], []\n",
    "    f1, recall, roc_auc = [], [], []\n",
    "\n",
    "    for train_index, test_index in rkf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy_train.append(accuracy_score(y_train, y_train_pred))\n",
    "        accuracy_test.append(accuracy_score(y_test, y_test_pred))\n",
    "        f1.append(f1_score(y_test, y_test_pred))\n",
    "        recall.append(recall_score(y_test, y_test_pred))\n",
    "        roc_auc.append(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "    return {\n",
    "        \"Train Accuracy\": (np.mean(accuracy_train), np.std(accuracy_train)),\n",
    "        \"Test Accuracy\": (np.mean(accuracy_test), np.std(accuracy_test)),\n",
    "        \"F1-Score_1\": (np.mean(f1), np.std(f1)),\n",
    "        \"Recall_1\": (np.mean(recall), np.std(recall)),\n",
    "        \"ROC-AUC_1\": (np.mean(roc_auc), np.std(roc_auc)),\n",
    "    }\n",
    "\n",
    "\n",
    "# Pfad zur Datei\n",
    "file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML.xlsx\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Zielvariable (y) und Features (X) extrahieren\n",
    "    y = df['Verletzungsstatus']\n",
    "    \n",
    "    # Dummy-Variable \"Geschlecht_weiblich\" separieren\n",
    "    if 'Geschlecht_weiblich' in df.columns:\n",
    "        geschlecht_weiblich = df[['Geschlecht_weiblich']]\n",
    "        X = df.drop(columns=['Verletzungsstatus', 'Geschlecht_weiblich'])\n",
    "    else:\n",
    "        X = df.drop(columns=['Verletzungsstatus'])\n",
    "        geschlecht_weiblich = None  \n",
    "\n",
    "    # Skalierung der Features (ohne \"Geschlecht_weiblich\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Falls vorhanden, die Dummy-Variable wieder anhängen\n",
    "    if geschlecht_weiblich is not None:\n",
    "        X_scaled = np.hstack((X_scaled, geschlecht_weiblich.values))\n",
    "\n",
    "    # Modelle definieren\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42),\n",
    "        \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42),\n",
    "        \"SVC\": SVC(probability=True, random_state=42),\n",
    "        \"k-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"MLP Classifier\": MLPClassifier(max_iter=1000, random_state=42),\n",
    "        \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "        \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "        \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "        \"Bagging Classifier\": BaggingClassifier(random_state=42),\n",
    "        \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Modell wird validiert: {model_name}\")\n",
    "        metrics = repeated_k_fold(model, X_scaled, y)  \n",
    "        \n",
    "        # Formatierung der Ergebnisse mit ±\n",
    "        formatted_metrics = {\n",
    "            \"Model\": model_name,\n",
    "            \"Train Accuracy\": f\"{metrics['Train Accuracy'][0]:.4f} ± {metrics['Train Accuracy'][1]:.4f}\",\n",
    "            \"Test Accuracy\": f\"{metrics['Test Accuracy'][0]:.4f} ± {metrics['Test Accuracy'][1]:.4f}\",\n",
    "            \"F1-Score_1\": f\"{metrics['F1-Score_1'][0]:.4f} ± {metrics['F1-Score_1'][1]:.4f}\",\n",
    "            \"Recall_1\": f\"{metrics['Recall_1'][0]:.4f} ± {metrics['Recall_1'][1]:.4f}\",\n",
    "            \"ROC-AUC_1\": f\"{metrics['ROC-AUC_1'][0]:.4f} ± {metrics['ROC-AUC_1'][1]:.4f}\",\n",
    "        }\n",
    "\n",
    "        results.append(formatted_metrics)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by=\"ROC-AUC_1\", ascending=False)\n",
    "\n",
    "    print(\"\\nErgebnisse der Modelle:\")\n",
    "    print(results_df)\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Die Datei wurde nicht gefunden. Bitte überprüfe den Pfad.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist aufgetreten: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4673f6-9dd8-4823-ba3b-f94d0b41d78d",
   "metadata": {},
   "source": [
    "Normalisierung innerhalb der CV (Datenleakage gänzlich vermeiden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dcc97-d051-45cc-bc9b-ed23928ccfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "def repeated_k_fold(model, X, y, n_splits=5, n_repeats=10):\n",
    "    rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "\n",
    "    accuracy_train, accuracy_test = [], []\n",
    "    f1, recall, roc_auc = [], [], []\n",
    "\n",
    "    for train_index, test_index in rkf.split(X, y):\n",
    "        # Aufteilen in Trainings- und Testdaten\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Skalierung: nur an den Trainingsdaten fitten\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train_scaled)\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        accuracy_train.append(accuracy_score(y_train, y_train_pred))\n",
    "        accuracy_test.append(accuracy_score(y_test, y_test_pred))\n",
    "        f1.append(f1_score(y_test, y_test_pred))\n",
    "        recall.append(recall_score(y_test, y_test_pred))\n",
    "        roc_auc.append(roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:, 1]))\n",
    "\n",
    "    return {\n",
    "        \"Train Accuracy\": (np.mean(accuracy_train), np.std(accuracy_train)),\n",
    "        \"Test Accuracy\": (np.mean(accuracy_test), np.std(accuracy_test)),\n",
    "        \"F1-Score_1\": (np.mean(f1), np.std(f1)),\n",
    "        \"Recall_1\": (np.mean(recall), np.std(recall)),\n",
    "        \"ROC-AUC_1\": (np.mean(roc_auc), np.std(roc_auc)),\n",
    "    }\n",
    "\n",
    "\n",
    "# Pfad zur Datei\n",
    "file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_neu.xlsx\"\n",
    "\n",
    "try: \n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Zielvariable (y) und Features (X) extrahieren\n",
    "    y = df['Verletzungsstatus']\n",
    "    \n",
    "    # Dummy-Variable \"Geschlecht_weiblich\" separieren, falls vorhanden\n",
    "    if 'Geschlecht_weiblich' in df.columns:\n",
    "        geschlecht_weiblich = df[['Geschlecht_weiblich']]\n",
    "        X = df.drop(columns=['Verletzungsstatus', 'Geschlecht_weiblich'])\n",
    "        # Die Dummy-Variable wieder anhängen\n",
    "        X = np.hstack((X.values, geschlecht_weiblich.values))\n",
    "    else:\n",
    "        X = df.drop(columns=['Verletzungsstatus']).values\n",
    "    \n",
    "    # Modelle definieren\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42),\n",
    "        \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42),\n",
    "        \"SVC\": SVC(probability=True, random_state=42),\n",
    "        \"k-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"MLP Classifier\": MLPClassifier(max_iter=1000, random_state=42),\n",
    "        \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "        \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "        \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "        \"Bagging Classifier\": BaggingClassifier(random_state=42),\n",
    "        \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Modell wird validiert: {model_name}\")\n",
    "        metrics = repeated_k_fold(model, X, y)\n",
    "        \n",
    "        formatted_metrics = {\n",
    "            \"Model\": model_name,\n",
    "            \"Train Accuracy\": f\"{metrics['Train Accuracy'][0]:.4f} ± {metrics['Train Accuracy'][1]:.4f}\",\n",
    "            \"Test Accuracy\": f\"{metrics['Test Accuracy'][0]:.4f} ± {metrics['Test Accuracy'][1]:.4f}\",\n",
    "            \"F1-Score_1\": f\"{metrics['F1-Score_1'][0]:.4f} ± {metrics['F1-Score_1'][1]:.4f}\",\n",
    "            \"Recall_1\": f\"{metrics['Recall_1'][0]:.4f} ± {metrics['Recall_1'][1]:.4f}\",\n",
    "            \"ROC-AUC_1\": f\"{metrics['ROC-AUC_1'][0]:.4f} ± {metrics['ROC-AUC_1'][1]:.4f}\",\n",
    "        }\n",
    "        results.append(formatted_metrics)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by=\"ROC-AUC_1\", ascending=False)\n",
    "    \n",
    "    print(\"\\nErgebnisse der Modelle:\")\n",
    "    print(results_df)\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Die Datei wurde nicht gefunden. Bitte überprüfe den Pfad.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist aufgetreten: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7ec0d-c2f9-4058-94d3-deedf2d7cac5",
   "metadata": {},
   "source": [
    "Mutual Information wird mit Korrelationsmatrix kombiniert und über Optuna-Optimierung werden die Variablen ausgewählt, die ROC-AUC optimieren. CV: split=5, repeats=10; r=0,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c7f68-6d03-47bb-99fd-5247a9ee77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "\n",
    "# Laden der Daten\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    X = df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    y = df[\"Verletzungsstatus\"]\n",
    "    return X, y\n",
    "\n",
    "# Vorverarbeitung der Daten\n",
    "def preprocess_data(X):\n",
    "    dummy_var = X[\"Geschlecht_weiblich\"]\n",
    "    cols_to_scale = [col for col in X.columns if col != \"Geschlecht_weiblich\"]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[cols_to_scale] = scaler.fit_transform(X[cols_to_scale])\n",
    "    X_scaled[\"Geschlecht_weiblich\"] = dummy_var  \n",
    "    return X_scaled\n",
    "\n",
    "# Auswahl an nicht hochkorrelierten Features herstellen\n",
    "def calculate_feature_selection(X_train, y_train, correlation_threshold=0.8):\n",
    "    # Berechnungen für Feature Selektion\n",
    "    correlation_matrix = X_train.corr().abs()\n",
    "    mutual_info = mutual_info_classif(X_train, y_train)\n",
    "    \n",
    "    # ausgewählte Features\n",
    "    selected_features = list(X_train.columns)  # Beginne mit allen Features\n",
    "    \n",
    "    # Iteriere über alle Feature-Paare\n",
    "    for col in X_train.columns:\n",
    "        if col in selected_features:\n",
    "            # Suche nach anderen hochkorrelierten Features\n",
    "            correlated_features = correlation_matrix[col].loc[correlation_matrix[col] > correlation_threshold].index.tolist()\n",
    "            correlated_features.remove(col)  # Entferne das aktuelle Feature selbst\n",
    "            \n",
    "            if correlated_features:\n",
    "                # Wenn es hochkorrelierte Features gibt, wähle das mit der höchsten Mutual Information\n",
    "                for correlated_feature in correlated_features:\n",
    "                    if mutual_info[X_train.columns.get_loc(col)] < mutual_info[X_train.columns.get_loc(correlated_feature)]:\n",
    "                        # Entferne das Feature mit der geringeren Mutual Information\n",
    "                        if col in selected_features:\n",
    "                            selected_features.remove(col)\n",
    "                    else:\n",
    "                        # Entferne das Feature mit der geringeren Mutual Information\n",
    "                        if correlated_feature in selected_features:\n",
    "                            selected_features.remove(correlated_feature)\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "\n",
    "# Optuna-Optimierung für äußere CV mit durchschnittlicher Anzahl an Features aus der inneren CV als Zielwert\n",
    "def optimize_feature_selection(X_train, y_train, target_num_features):\n",
    "    # Zuerst die nicht hochkorrelierten Features bestimmen\n",
    "    candidate_features = calculate_feature_selection(X_train, y_train, correlation_threshold=0.8)\n",
    "    candidate_features = sorted(candidate_features)\n",
    "    # Stelle sicher, dass target_num_features nicht größer als die Anzahl der Kandidaten ist:\n",
    "    target_num_features = min(target_num_features, len(candidate_features))\n",
    "    \n",
    "    def objective(trial):\n",
    "        # Der Suchraum orientiert sich an target_num_features, aber es darf nicht mehr als die\n",
    "        # vorhandenen Kandidatenfeatures ausgewählt werden.\n",
    "        num_features = trial.suggest_int(\n",
    "            \"num_features\",\n",
    "            max(5, target_num_features-5),\n",
    "            min(len(candidate_features), target_num_features+5)\n",
    "        )\n",
    "        \n",
    "        # Falls num_features größer als die Anzahl der Kandidatenfeatures sein könnte, beschränke sie\n",
    "        num_features = min(num_features, len(candidate_features))\n",
    "        \n",
    "        # Auswahl der ersten num_features aus dem Kandidatenpool\n",
    "        X_train_optimized = X_train[candidate_features[:num_features]]\n",
    "        \n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        score = cross_val_score(model, X_train_optimized, y_train, cv=5, scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "        return score\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    return study.best_trial\n",
    "\n",
    "\n",
    "# komplette innere CV mit Berechnung der duchschnittlichen Anzahl an Features als Ausgabe\n",
    "def inner_cv_feature_selection(X_train, y_train):\n",
    "    inner_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    best_num_features = []\n",
    "    feature_counts = []  # Speichert die Anzahl der nicht hochkorrelierten Features pro Fold\n",
    "\n",
    "    for inner_train_idx, inner_test_idx in inner_cv.split(X_train, y_train):\n",
    "        X_inner_train, X_inner_test = X_train.iloc[inner_train_idx], X_train.iloc[inner_test_idx]\n",
    "        y_inner_train, y_inner_test = y_train.iloc[inner_train_idx], y_train.iloc[inner_test_idx]\n",
    "\n",
    "        # Berechne den Kandidatenpool\n",
    "        candidate_features = calculate_feature_selection(X_inner_train, y_inner_train, correlation_threshold=0.8)\n",
    "        candidate_features = sorted(candidate_features)\n",
    "        \n",
    "        # Speicher die Anzahl der übrig gebliebenen Features\n",
    "        feature_counts.append(len(candidate_features))\n",
    "        \n",
    "        # Falls der Kandidatenpool leer ist, setze alle Features ein\n",
    "        if len(candidate_features) == 0:\n",
    "            candidate_features = list(X_inner_train.columns)\n",
    "        \n",
    "        def objective(trial):\n",
    "            low_bound = 1\n",
    "            high_bound = len(candidate_features)\n",
    "            num_features = trial.suggest_int(\"num_features\", low_bound, high_bound)\n",
    "            X_selected = X_inner_train[candidate_features[:num_features]]\n",
    "\n",
    "            model = LogisticRegression(max_iter=1000)\n",
    "            score = cross_val_score(model, X_selected, y_inner_train, cv=5, scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "            return score\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "        best_num_features.append(study.best_trial.params[\"num_features\"])\n",
    "        \n",
    "    # Berechnung von Median der besten Feature-Anzahl\n",
    "    median_features = int(np.median(best_num_features))\n",
    "\n",
    "    return median_features, feature_counts\n",
    "\n",
    "\n",
    "def cross_validate(X, y):\n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    \n",
    "    # Listen zum Sammeln der Metriken\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []  # Neue Liste für Precision\n",
    "    roc_auc_scores = []\n",
    "    num_features = []\n",
    "    selected_features_outer = []\n",
    "    confusion_matrices = []  # Neue Liste für Konfusionsmatrizen\n",
    "    \n",
    "    all_feature_counts = []\n",
    "\n",
    "    for outer_train_idx, outer_test_idx in outer_cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[outer_train_idx], X.iloc[outer_test_idx]\n",
    "        y_train, y_test = y.iloc[outer_train_idx], y.iloc[outer_test_idx]\n",
    "\n",
    "        avg_selected_features, feature_counts_inner = inner_cv_feature_selection(X_train, y_train)\n",
    "        all_feature_counts.extend(feature_counts_inner)\n",
    "        \n",
    "        candidate_features = calculate_feature_selection(X_train, y_train, correlation_threshold=0.8)\n",
    "        candidate_features = sorted(candidate_features)\n",
    "        trial = optimize_feature_selection(X_train[candidate_features], y_train, avg_selected_features)\n",
    "        num_features_optimized = trial.params['num_features']\n",
    "        \n",
    "        selected_features_outer.append(candidate_features[:num_features_optimized])\n",
    "        \n",
    "        X_train_optimized = X_train[candidate_features[:num_features_optimized]]\n",
    "        X_test_optimized = X_test[candidate_features[:num_features_optimized]]\n",
    "\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train_optimized, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train_optimized)\n",
    "        y_test_pred = model.predict(X_test_optimized)\n",
    "\n",
    "        # Berechnungen der Metriken\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "        recall = recall_score(y_test, y_test_pred)\n",
    "        precision = precision_score(y_test, y_test_pred)  # Neue Metrik\n",
    "        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_optimized)[:, 1])\n",
    "        \n",
    "        # Konfusionsmatrix berechnen\n",
    "        conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "        confusion_matrices.append(conf_matrix)\n",
    "\n",
    "        # Speichern der Metriken\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        recall_scores.append(recall)\n",
    "        precision_scores.append(precision)  # Neue Metrik speichern\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        num_features.append(num_features_optimized)\n",
    "    \n",
    "    # Durchschnittliche Konfusionsmatrix berechnen\n",
    "    avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    std_confusion_matrix = np.std(confusion_matrices, axis=0)\n",
    "    \n",
    "    results_summary = {\n",
    "        'Train Accuracy': np.mean(train_accuracies),\n",
    "        'Train Accuracy Std': np.std(train_accuracies),\n",
    "        'Test Accuracy': np.mean(test_accuracies),\n",
    "        'Test Accuracy Std': np.std(test_accuracies),\n",
    "        'F1-Score_1': np.mean(f1_scores),\n",
    "        'F1-Score Std': np.std(f1_scores),\n",
    "        'Recall_1': np.mean(recall_scores),\n",
    "        'Recall Std': np.std(recall_scores),\n",
    "        'Precision_1': np.mean(precision_scores),  # Neue Metrik\n",
    "        'Precision Std': np.std(precision_scores),  # Neue Metrik\n",
    "        'ROC-AUC_1': np.mean(roc_auc_scores),\n",
    "        'ROC-AUC Std': np.std(roc_auc_scores),\n",
    "        'Feature-Anzahl': np.mean(num_features),\n",
    "        'Feature-Anzahl Std': np.std(num_features)\n",
    "    }\n",
    "\n",
    "    raw_metrics = {\n",
    "        \"Train Accuracies\": train_accuracies,\n",
    "        \"Test Accuracies\": test_accuracies,\n",
    "        \"F1 Scores\": f1_scores,\n",
    "        \"Recall Scores\": recall_scores,\n",
    "        \"Precision Scores\": precision_scores,  # Neue Metrik\n",
    "        \"ROC-AUC Scores\": roc_auc_scores,\n",
    "        \"Feature-Anzahlen\": num_features\n",
    "    }\n",
    "\n",
    "    return results_summary, raw_metrics, selected_features_outer, all_feature_counts, (avg_confusion_matrix, std_confusion_matrix)\n",
    "\n",
    "\n",
    "def compute_feature_usage(selected_features_outer):\n",
    "    # Flache Liste aller ausgewählten Features aus den einzelnen Folds erstellen\n",
    "    all_selected_features = [feature for fold in selected_features_outer for feature in fold]\n",
    "    # Häufigkeiten zählen\n",
    "    feature_usage = Counter(all_selected_features)\n",
    "    # Filter nur Features, die mindestens einmal vorkamen (was per Definition immer der Fall ist)\n",
    "    most_common_features = feature_usage.most_common()\n",
    "    return most_common_features\n",
    "\n",
    "def compute_feature_stats(all_feature_counts):\n",
    "    # Berechnung der durchschnittlichen Anzahl der nicht hochkorrelierten Features\n",
    "    mean_features = np.mean(all_feature_counts)\n",
    "    std_features = np.std(all_feature_counts)\n",
    "    \n",
    "    # Rückgabe der berechneten Werte\n",
    "    return mean_features, std_features\n",
    "\n",
    "\n",
    "def display_results_summary(results_summary):\n",
    "    # Formatierte Metriken mit ± Standardabweichung\n",
    "    formatted_metrics = {\n",
    "        \"Gruppe\": [\"Total\", \"1 (Verletzte)\"],\n",
    "        \"Train Accuracy\": [\n",
    "            f\"{results_summary['Train Accuracy']*100:.2f} ± {results_summary['Train Accuracy Std']*100:.2f}\",\n",
    "            \"-\"\n",
    "        ],\n",
    "        \"Test Accuracy\": [\n",
    "            f\"{results_summary['Test Accuracy']*100:.2f} ± {results_summary['Test Accuracy Std']*100:.2f}\",\n",
    "            \"-\"\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            \"-\",\n",
    "            f\"{results_summary['F1-Score_1']*100:.2f} ± {results_summary['F1-Score Std']*100:.2f}\"\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            \"-\",\n",
    "            f\"{results_summary['Recall_1']*100:.2f} ± {results_summary['Recall Std']*100:.2f}\"\n",
    "        ],\n",
    "        \"Precision\": [  # Hinzugefügt\n",
    "            \"-\",\n",
    "            f\"{results_summary['Precision_1']*100:.2f} ± {results_summary['Precision Std']*100:.2f}\"\n",
    "        ],\n",
    "        \"ROC-AUC\": [\n",
    "            f\"{results_summary['ROC-AUC_1']*100:.2f} ± {results_summary['ROC-AUC Std']*100:.2f}\",\n",
    "            f\"{results_summary['ROC-AUC_1']*100:.2f} ± {results_summary['ROC-AUC Std']*100:.2f}\"\n",
    "        ],\n",
    "        \"Anzahl-Features\": [\n",
    "            f\"{results_summary['Feature-Anzahl']:.2f} ± {results_summary['Feature-Anzahl Std']:.2f}\",\n",
    "            \"-\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Erstellen des DataFrames\n",
    "    df = pd.DataFrame(formatted_metrics)\n",
    "\n",
    "    # Formatierung des DataFrames für HTML-Ausgabe\n",
    "    styled_df = df.style.set_properties(**{\"text-align\": \"center\", \"color\": \"black\"}) \\\n",
    "                        .set_table_styles([{\n",
    "                            \"selector\": \"th\", \n",
    "                            \"props\": [(\"font-size\", \"14px\"), \n",
    "                                      (\"background-color\", \"#f2f2f2\"), \n",
    "                                      (\"color\", \"black\")]\n",
    "                        }]) \\\n",
    "                        .set_caption(\"Durchschnittliche Evaluierungsmetriken über die äußere CV\")\n",
    "\n",
    "    display(styled_df)\n",
    "\n",
    "\n",
    "def plot_raw_metrics(raw_metrics):\n",
    "    # Erstellen eines DataFrames für die fünf Metriken\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Train Accuracy\": raw_metrics[\"Train Accuracies\"],\n",
    "        \"Test Accuracy\": raw_metrics[\"Test Accuracies\"],\n",
    "        \"F1 Score\": raw_metrics[\"F1 Scores\"],\n",
    "        \"Recall\": raw_metrics[\"Recall Scores\"],\n",
    "        \"Precision\": raw_metrics[\"Precision Scores\"], \n",
    "        \"ROC-AUC\": raw_metrics[\"ROC-AUC Scores\"]\n",
    "    })\n",
    "    # Umwandlung in das Long-Format (tidy data)\n",
    "    metrics_long = metrics_df.melt(var_name=\"Metrik\", value_name=\"Wert\")\n",
    "    \n",
    "    # Erstellen des Boxplots für die fünf Metriken\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x=\"Wert\", y=\"Metrik\", data=metrics_long)\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.title(\"Verteilung der Evaluierungsmetriken über die äußere CV\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Erstellen eines separaten DataFrames für die Feature-Anzahl\n",
    "    features_df = pd.DataFrame({\n",
    "        \"Feature-Anzahl\": raw_metrics[\"Feature-Anzahlen\"]\n",
    "    })\n",
    "    \n",
    "    # Erstellen eines separaten Boxplots für die Feature-Anzahl\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=\"Feature-Anzahl\", data=features_df)\n",
    "    plt.xlabel(\"Feature-Anzahl\")\n",
    "    plt.title(\"Verteilung der Feature-Anzahlen über die äußere CV\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(avg_confusion_matrix, std_confusion_matrix):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Erstelle eine Matrix mit formatierten Strings (Durchschnitt ± Std)\n",
    "    formatted_matrix = np.empty_like(avg_confusion_matrix, dtype=object)\n",
    "    for i in range(avg_confusion_matrix.shape[0]):\n",
    "        for j in range(avg_confusion_matrix.shape[1]):\n",
    "            formatted_matrix[i,j] = f'{avg_confusion_matrix[i,j]:.2f}\\n±{std_confusion_matrix[i,j]:.2f}'\n",
    "    \n",
    "    # Erstelle Heatmap\n",
    "    sns.heatmap(avg_confusion_matrix, \n",
    "                annot=formatted_matrix, \n",
    "                fmt='', \n",
    "                cmap='Blues',\n",
    "                cbar_kws={'label': 'Durchschnittliche Anzahl'})\n",
    "    \n",
    "    plt.title('Konfusionsmatrix (Durchschnitt ± Standardabweichung)')\n",
    "    plt.xlabel('Vorhergesagte Klasse')\n",
    "    plt.ylabel('Tatsächliche Klasse')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_feature_importance_table(most_common_features):\n",
    "    # Erstelle ein DataFrame aus dem Counter\n",
    "    df_features = pd.DataFrame(most_common_features, columns=[\"Feature\", \"Häufigkeit\"])\n",
    "    # Formatierung der Tabelle\n",
    "    styled_df = df_features.style.set_properties(**{\"text-align\": \"center\", \"color\": \"black\"}) \\\n",
    "                         .set_table_styles([{\"selector\": \"th\", \n",
    "                                              \"props\": [(\"font-size\", \"14px\"), \n",
    "                                                        (\"background-color\", \"#f2f2f2\"), \n",
    "                                                        (\"color\", \"black\")]}]) \\\n",
    "                         .set_caption(\"Häufigste in der finalen Feature-Auswahl verwendete Features\")\n",
    "    display(styled_df)\n",
    "    \n",
    "def main():\n",
    "    file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_neu.xlsx\"\n",
    "    X, y = load_data(file_path)\n",
    "    X_scaled = preprocess_data(X)\n",
    "    \n",
    "    results_summary, raw_metrics, selected_features_outer, all_feature_counts, confusion_matrices = cross_validate(X_scaled, y)\n",
    "    \n",
    "    print(\"\\nErgebnisse der äußeren Cross-Validation (aggregiert):\")\n",
    "    display_results_summary(results_summary)\n",
    "    \n",
    "    print(\"\\nVerteilung der Evaluierungsmetriken (Boxplot):\")\n",
    "    plot_raw_metrics(raw_metrics)\n",
    "    \n",
    "    print(\"\\nKonfusionsmatrix:\")\n",
    "    plot_confusion_matrix(confusion_matrices[0], confusion_matrices[1])\n",
    "    \n",
    "    most_common_features = compute_feature_usage(selected_features_outer)\n",
    "    print(\"\\nHäufigste verwendete Features:\")\n",
    "    print_feature_importance_table(most_common_features)\n",
    "    \n",
    "    mean_features, std_features = compute_feature_stats(all_feature_counts)\n",
    "    print(f\"\\nDurchschnittliche Anzahl nicht hochkorrelierter Features über alle inneren CVs: {mean_features:.2f} ± {std_features:.2f}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938dc3de-0eaa-4701-ab07-a0d037029d2a",
   "metadata": {},
   "source": [
    "Evaluierungsmetriken der Modelle im Vergleich bei reduzierter Variablenanzahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afed43d-dea6-4f70-8fa6-d110013d5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# Führt CV durch und berechnet die Metriken\n",
    "def repeated_k_fold(model, X, y, n_splits=5, n_repeats=10):\n",
    "    rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "\n",
    "    accuracy_train, accuracy_test = [], []\n",
    "    f1, recall, roc_auc = [], [], []\n",
    "\n",
    "    for train_index, test_index in rkf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy_train.append(accuracy_score(y_train, y_train_pred))\n",
    "        accuracy_test.append(accuracy_score(y_test, y_test_pred))\n",
    "        f1.append(f1_score(y_test, y_test_pred))\n",
    "        recall.append(recall_score(y_test, y_test_pred))\n",
    "        roc_auc.append(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "    return {\n",
    "        \"Train Accuracy\": (np.mean(accuracy_train), np.std(accuracy_train)),\n",
    "        \"Test Accuracy\": (np.mean(accuracy_test), np.std(accuracy_test)),\n",
    "        \"F1-Score_1\": (np.mean(f1), np.std(f1)),\n",
    "        \"Recall_1\": (np.mean(recall), np.std(recall)),\n",
    "        \"ROC-AUC_1\": (np.mean(roc_auc), np.std(roc_auc)),\n",
    "    }\n",
    "\n",
    "\n",
    "# Pfad zur Datei\n",
    "file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_mutualinf_korr.xlsx\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Zielvariable (y) und Features (X) extrahieren\n",
    "    y = df['Verletzungsstatus']\n",
    "    \n",
    "    # Dummy-Variable \"Geschlecht_weiblich\" separieren\n",
    "    if 'Geschlecht_weiblich' in df.columns:\n",
    "        geschlecht_weiblich = df[['Geschlecht_weiblich']]\n",
    "        X = df.drop(columns=['Verletzungsstatus', 'Geschlecht_weiblich'])\n",
    "    else:\n",
    "        X = df.drop(columns=['Verletzungsstatus'])\n",
    "        geschlecht_weiblich = None  \n",
    "\n",
    "    # Skalierung der Features (ohne \"Geschlecht_weiblich\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Falls vorhanden, die Dummy-Variable wieder anhängen\n",
    "    if geschlecht_weiblich is not None:\n",
    "        X_scaled = np.hstack((X_scaled, geschlecht_weiblich.values))\n",
    "\n",
    "    # Modelle definieren\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42),\n",
    "        \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42),\n",
    "        \"SVC\": SVC(probability=True, random_state=42),\n",
    "        \"k-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"MLP Classifier\": MLPClassifier(max_iter=1000, random_state=42),\n",
    "        \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "        \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "        \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "        \"Bagging Classifier\": BaggingClassifier(random_state=42),\n",
    "        \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Modell wird validiert: {model_name}\")\n",
    "        metrics = repeated_k_fold(model, X_scaled, y)  \n",
    "        \n",
    "        # Formatierung der Ergebnisse mit ±\n",
    "        formatted_metrics = {\n",
    "            \"Model\": model_name,\n",
    "            \"Train Accuracy\": f\"{metrics['Train Accuracy'][0]:.4f} ± {metrics['Train Accuracy'][1]:.4f}\",\n",
    "            \"Test Accuracy\": f\"{metrics['Test Accuracy'][0]:.4f} ± {metrics['Test Accuracy'][1]:.4f}\",\n",
    "            \"F1-Score_1\": f\"{metrics['F1-Score_1'][0]:.4f} ± {metrics['F1-Score_1'][1]:.4f}\",\n",
    "            \"Recall_1\": f\"{metrics['Recall_1'][0]:.4f} ± {metrics['Recall_1'][1]:.4f}\",\n",
    "            \"ROC-AUC_1\": f\"{metrics['ROC-AUC_1'][0]:.4f} ± {metrics['ROC-AUC_1'][1]:.4f}\",\n",
    "        }\n",
    "\n",
    "        results.append(formatted_metrics)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by=\"ROC-AUC_1\", ascending=False)\n",
    "\n",
    "    print(\"\\nErgebnisse der Modelle:\")\n",
    "    print(results_df)\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Die Datei wurde nicht gefunden. Bitte überprüfe den Pfad.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist aufgetreten: {e}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147be24-eb68-49f8-b357-8cf82f872272",
   "metadata": {},
   "source": [
    "Datenaugmentation mit Clusteransatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eea2c5-32be-452f-8ee0-128c31dce90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "\n",
    "def perform_clustering(X_sub, max_clusters=4):\n",
    "    \"\"\"\n",
    "    Führt eine Clusteranalyse auf den numerischen Parametern (außer den\n",
    "    Gruppierungsvariablen \"Verletzungsstatus\" und \"Geschlecht_weiblich\")\n",
    "    durch und teilt diese in max_clusters Gruppen ein.\n",
    "    \"\"\"\n",
    "    # Wähle alle numerischen Spalten außer \"Verletzungsstatus\" und \"Geschlecht_weiblich\"\n",
    "    cols = [col for col in X_sub.columns if col not in [\"Verletzungsstatus\", \"Geschlecht_weiblich\"]]\n",
    "    X_num = X_sub[cols]\n",
    "    \n",
    "    # Berechne die Korrelationsmatrix und transformiere sie in eine Distanzmatrix\n",
    "    corr = X_num.corr().abs()\n",
    "    dist = np.clip(1 - corr, a_min=0, a_max=None)  # Clippe negative Werte auf 0\n",
    "    \n",
    "    # Konvertiere die Distanzmatrix in ein 1D-Array (upper triangular)\n",
    "    dists = squareform(dist.values)\n",
    "    \n",
    "    # Hierarchische Clusteranalyse (z. B. mit der Ward-Methode)\n",
    "    Z = linkage(dists, method='ward')\n",
    "    \n",
    "    # Führe fcluster aus, um die Spalten in max_clusters Cluster zu unterteilen\n",
    "    cluster_labels = fcluster(Z, max_clusters, criterion='maxclust')\n",
    "    \n",
    "    # Ordne den Spalten Clusterlabels zu\n",
    "    clusters = {}\n",
    "    for col, label in zip(cols, cluster_labels):\n",
    "        clusters.setdefault(label, []).append(col)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def augment_subgroup(X_sub, clusters, p_augment=0.7):\n",
    "    \"\"\"\n",
    "    Augmentiert die Daten in X_sub (einen DataFrame für eine Subgruppe)\n",
    "    für alle in clusters definierten Parametergruppen.\n",
    "    \n",
    "    Für jede Zeile und für jede Cluster-Gruppe wird mit Wahrscheinlichkeit p_augment\n",
    "    ein neuer Wert gezogen – ansonsten wird der Originalwert beibehalten.\n",
    "    Dabei werden für jede Parametergruppe der Mittelwertvektor und die Kovarianzmatrix\n",
    "    des gesamten Subdatensatzes berechnet.\n",
    "    \n",
    "    Rückgabe: DataFrame mit augmentierten Zeilen (1 augmentiertes Sample pro Originalzeile)\n",
    "    \"\"\"\n",
    "    augmented_rows = []\n",
    "    \n",
    "    # Für jede Cluster-Gruppe: Berechne Mittelwert und Kovarianzmatrix\n",
    "    cluster_params = {}\n",
    "    for cl_id, cols in clusters.items():\n",
    "        cluster_data = X_sub[cols]\n",
    "        mu = cluster_data.mean().values\n",
    "        # Falls nur ein Feature im Cluster ist, gibt np.cov einen Skalar zurück.\n",
    "        if len(cols) == 1:\n",
    "            cov = np.cov(cluster_data.values.flatten(), ddof=0)\n",
    "            cov = np.atleast_2d(cov)\n",
    "        else:\n",
    "            cov = np.cov(cluster_data.values, rowvar=False)\n",
    "        cluster_params[cl_id] = (mu, cov, cols)\n",
    "    \n",
    "    # Gehe jede Zeile (Originaldatensatz) durch\n",
    "    for idx, row in X_sub.iterrows():\n",
    "        new_row = row.copy()\n",
    "        # Für jede Cluster-Gruppe stochastisch augmentieren\n",
    "        for cl_id, (mu, cov, cols) in cluster_params.items():\n",
    "            if np.random.rand() < p_augment:\n",
    "                # Ziehe einen neuen Vektor aus der multivariaten Normalverteilung\n",
    "                new_values = np.random.multivariate_normal(mu, cov)\n",
    "                # Überschreibe nur die Werte in den entsprechenden Spalten\n",
    "                for col, val in zip(cols, new_values):\n",
    "                    new_row[col] = val\n",
    "        augmented_rows.append(new_row)\n",
    "    \n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    \n",
    "    # Sicherstellen, dass Gruppierungsvariablen den richtigen Datentyp behalten:\n",
    "    for col in [\"Geschlecht_weiblich\", \"Verletzungsstatus\"]:\n",
    "        if col in augmented_df.columns:\n",
    "            augmented_df[col] = augmented_df[col].astype(int)\n",
    "    \n",
    "    return augmented_df\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Funktion: Stratifikation und Augmentation der Trainingsdaten\n",
    "# ----------------------------------------------------------------\n",
    "def augment_training_data(X_train, y_train, max_clusters=4, p_augment=0.7, num_new_samples=1):\n",
    "    \"\"\"\n",
    "    Führt zuerst eine Stratifikation des Trainingsdatensatzes nach \"Verletzungsstatus\"\n",
    "    und \"Geschlecht_weiblich\" durch und wendet dann in jeder Subgruppe:\n",
    "      - eine Clusteranalyse (auf alle übrigen numerischen Features)\n",
    "      - die Augmentation (Ziehung neuer Samples aus multivariater Normalverteilung)\n",
    "    an.\n",
    "    \n",
    "    num_new_samples gibt an, wie viele augmentierte Samples pro Originalzeile generiert werden.\n",
    "    \"\"\"\n",
    "    # Kombiniere X_train und y_train, damit wir gruppieren können\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Stratifikation: Erstelle eine Gruppierung nach (Verletzungsstatus, Geschlecht_weiblich)\n",
    "    augmented_groups = []\n",
    "    for key, group_df in df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        # Führe Clusteranalyse auf dieser Subgruppe durch\n",
    "        clusters = perform_clustering(group_df, max_clusters=max_clusters)\n",
    "        # Erzeuge für diese Subgruppe num_new_samples augmentierte Samples pro Zeile\n",
    "        aug_list = []\n",
    "        for _ in range(num_new_samples):\n",
    "            aug = augment_subgroup(group_df, clusters, p_augment=p_augment)\n",
    "            aug_list.append(aug)\n",
    "        aug_group = pd.concat(aug_list, axis=0)\n",
    "        augmented_groups.append(aug_group)\n",
    "    \n",
    "    # Vereinige alle augmentierten Subgruppen\n",
    "    augmented_df = pd.concat(augmented_groups, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Trenne Zielvariable und Features (hier war \"Verletzungsstatus\" in df_train enthalten)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    \n",
    "    return X_aug, y_aug\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Integration in den Trainingssplit (innerer CV) mit Augmentation\n",
    "# ----------------------------------------------------------------\n",
    "def inner_cv_with_augmentation(X_train, y_train):\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    inner_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, test_idx in inner_cv.split(X_train, y_train):\n",
    "        # Kopien der Daten erstellen\n",
    "        X_inner_train = X_train.iloc[train_idx].copy()\n",
    "        X_inner_test = X_train.iloc[test_idx].copy()\n",
    "        y_inner_train, y_inner_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # Normalisierung innerhalb des Folds:\n",
    "        dummy = \"Geschlecht_weiblich\"\n",
    "        cols_to_scale = [col for col in X_inner_train.columns if col != dummy]\n",
    "        scaler = StandardScaler()\n",
    "        X_inner_train[cols_to_scale] = scaler.fit_transform(X_inner_train[cols_to_scale])\n",
    "        X_inner_test[cols_to_scale] = scaler.transform(X_inner_test[cols_to_scale])\n",
    "\n",
    "        # Augmentation auf den normalisierten Trainingsdaten durchführen:\n",
    "        X_inner_train_aug, y_inner_train_aug = augment_training_data(\n",
    "            X_inner_train, y_inner_train, max_clusters=4, p_augment=0.7, num_new_samples=3\n",
    "        )\n",
    "\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        # Auch hier wird cross_val_score innerhalb der Trainingsdaten-CV eingesetzt\n",
    "        score = cross_val_score(model, X_inner_train_aug, y_inner_train_aug, cv=3,\n",
    "                                scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "        scores.append(score)\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "    #print(\"Durchschnittliche innere CV-ROC-AUC mit Augmentation:\", avg_score)\n",
    "    return avg_score\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Integration in den Trainingssplit (innerer CV) ohne Augmentation\n",
    "#------------------------------------------------------------------------\n",
    "def inner_cv_without_augmentation(X_train, y_train):\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    inner_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, test_idx in inner_cv.split(X_train, y_train):\n",
    "        # Kopien der Daten erstellen, um spätere Änderungen lokal zu halten\n",
    "        X_inner_train = X_train.iloc[train_idx].copy()\n",
    "        X_inner_test = X_train.iloc[test_idx].copy()\n",
    "        y_inner_train, y_inner_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # Normalisierung innerhalb des Folds:\n",
    "        dummy = \"Geschlecht_weiblich\"\n",
    "        cols_to_scale = [col for col in X_inner_train.columns if col != dummy]\n",
    "        scaler = StandardScaler()\n",
    "        X_inner_train[cols_to_scale] = scaler.fit_transform(X_inner_train[cols_to_scale])\n",
    "        X_inner_test[cols_to_scale] = scaler.transform(X_inner_test[cols_to_scale])\n",
    "\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        # cross_val_score führt hier eine weitere CV auf den inneren Trainingsdaten durch\n",
    "        score = cross_val_score(model, X_inner_train, y_inner_train, cv=3,\n",
    "                                scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "        scores.append(score)\n",
    "    \n",
    "    avg_score = np.mean(scores)\n",
    "    #print(\"Durchschnittliche innere CV-ROC-AUC ohne Augmentation:\", avg_score)\n",
    "    return avg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e59c0-548e-4991-b27c-7007ee30f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clusterbildung mit Rauschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8695b1-945d-44f5-b87a-115a30003f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# -----------------------------\n",
    "# 0. Hilfsfunktion: Gruppenschlüssel übersetzen\n",
    "# -----------------------------\n",
    "def map_group_label(key):\n",
    "    \"\"\"\n",
    "    Übersetzt den Gruppenschlüssel (Verletzungsstatus, Geschlecht_weiblich) \n",
    "    in eine lesbare Bezeichnung.\n",
    "    \n",
    "    Verletzungsstatus: 0 -> \"unverletzt\", 1 -> \"verletzt\"\n",
    "    Geschlecht_weiblich: 0 -> \"männlich\", 1 -> \"weiblich\"\n",
    "    \"\"\"\n",
    "    status = \"verletzt\" if key[0] == 1 else \"unverletzt\"\n",
    "    gender = \"weiblich\" if key[1] == 1 else \"männlich\"\n",
    "    return f\"Gruppe ({status}-{gender})\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Funktion: Rauschen hinzufügen\n",
    "# -----------------------------\n",
    "def add_noise_to_data(df, noise_factor=0.1):\n",
    "    \"\"\"\n",
    "    Fügt allen numerischen Spalten (außer \"Geschlecht_weiblich\" und \"Verletzungsstatus\")\n",
    "    Rauschen hinzu, wobei das Rauschen ein Anteil (noise_factor) der ursprünglichen\n",
    "    Standardabweichung beträgt.\n",
    "    \"\"\"\n",
    "    df_noisy = df.copy()\n",
    "    numeric_cols = [col for col in df_noisy.select_dtypes(include=['float64', 'int64']).columns \n",
    "                    if col not in [\"Geschlecht_weiblich\", \"Verletzungsstatus\"]]\n",
    "    for col in numeric_cols:\n",
    "        std = df_noisy[col].std()\n",
    "        noise = np.random.normal(0, std * noise_factor, size=df_noisy.shape[0])\n",
    "        df_noisy[col] += noise\n",
    "    return df_noisy\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Funktion: Clusterbildung\n",
    "# -----------------------------\n",
    "def perform_clustering(X_sub, max_clusters=4):\n",
    "    \"\"\"\n",
    "    Führt eine hierarchische Clusteranalyse auf den numerischen Features (ohne \n",
    "    \"Geschlecht_weiblich\" und \"Verletzungsstatus\") durch und teilt in max_clusters ein.\n",
    "    \"\"\"\n",
    "    cols = [col for col in X_sub.columns if col not in [\"Verletzungsstatus\", \"Geschlecht_weiblich\"]]\n",
    "    X_num = X_sub[cols]\n",
    "    corr = X_num.corr().abs()\n",
    "    dist = np.clip(1 - corr, a_min=0, a_max=None)\n",
    "    dists = squareform(dist.values)\n",
    "    Z = linkage(dists, method='ward')\n",
    "    cluster_labels = fcluster(Z, max_clusters, criterion='maxclust')\n",
    "    clusters = {}\n",
    "    for col, label in zip(cols, cluster_labels):\n",
    "        clusters.setdefault(label, []).append(col)\n",
    "    return clusters\n",
    "\n",
    "# -----------------------------\n",
    "# Hilfsfunktionen für Stabilitätsmetriken und Visualisierung\n",
    "# -----------------------------\n",
    "def get_feature_order(df):\n",
    "    return [col for col in df.columns if col not in [\"Verletzungsstatus\", \"Geschlecht_weiblich\"]]\n",
    "\n",
    "def get_cluster_labels(clusters, feature_order):\n",
    "    feature_cluster = {}\n",
    "    for cl, feats in clusters.items():\n",
    "        for feat in feats:\n",
    "            feature_cluster[feat] = cl\n",
    "    return [feature_cluster.get(feat, -1) for feat in feature_order]\n",
    "\n",
    "def visualize_clusters(df_group, clusters, title=\"Cluster Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualisiert die Cluster der Features mittels PCA (auf der Korrelationsmatrix).\n",
    "    Es werden keine Textannotationen angezeigt, damit die Grafik übersichtlicher bleibt.\n",
    "    \"\"\"\n",
    "    feature_order = get_feature_order(df_group)\n",
    "    X_num = df_group[feature_order]\n",
    "    corr = X_num.corr().values\n",
    "    pca = PCA(n_components=2)\n",
    "    coords = pca.fit_transform(corr)\n",
    "    labels = get_cluster_labels(clusters, feature_order)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    scatter = plt.scatter(coords[:,0], coords[:,1], c=labels, cmap='viridis', s=100)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar(scatter, label=\"Cluster\")\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Funktionen für Gruppierung und Vergleich\n",
    "# -----------------------------\n",
    "def get_group_clusters(df):\n",
    "    \"\"\"\n",
    "    Gruppiert den Datensatz anhand von (\"Verletzungsstatus\", \"Geschlecht_weiblich\")\n",
    "    und berechnet für jede Gruppe die Cluster.\n",
    "    \"\"\"\n",
    "    groups = {}\n",
    "    for key, group in df.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        group = group.reset_index(drop=True)\n",
    "        clusters = perform_clustering(group, max_clusters=4)\n",
    "        groups[key] = clusters\n",
    "    return groups\n",
    "\n",
    "def compute_stability_metrics(clusters_1, clusters_2, feature_order):\n",
    "    \"\"\"\n",
    "    Vergleicht zwei Clusterlösungen anhand von ARI und NMI.\n",
    "    \"\"\"\n",
    "    labels_1 = get_cluster_labels(clusters_1, feature_order)\n",
    "    labels_2 = get_cluster_labels(clusters_2, feature_order)\n",
    "    ari = adjusted_rand_score(labels_1, labels_2)\n",
    "    nmi = normalized_mutual_info_score(labels_1, labels_2)\n",
    "    return ari, nmi\n",
    "\n",
    "def compute_pairwise_metrics(solution_list, feature_order):\n",
    "    \"\"\"\n",
    "    Berechnet pairwise ARI und NMI über eine Liste von Clusterlösungen.\n",
    "    Gibt (mean_ARI, std_ARI, mean_NMI, std_NMI) zurück.\n",
    "    \"\"\"\n",
    "    aris = []\n",
    "    nmis = []\n",
    "    n = len(solution_list)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            ari, nmi = compute_stability_metrics(solution_list[i], solution_list[j], feature_order)\n",
    "            aris.append(ari)\n",
    "            nmis.append(nmi)\n",
    "    return np.mean(aris), np.std(aris), np.mean(nmis), np.std(nmis)\n",
    "\n",
    "def compute_pairwise_consistency(solution_list):\n",
    "    \"\"\"\n",
    "    Berechnet pairwise Cluster-Konsistenz (durchschnittlicher Match-Prozentsatz) über eine Liste von Clusterlösungen.\n",
    "    \"\"\"\n",
    "    consistencies = []\n",
    "    n = len(solution_list)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            cons = average_cluster_consistency(solution_list[i], solution_list[j])\n",
    "            consistencies.append(cons)\n",
    "    return np.mean(consistencies), np.std(consistencies)\n",
    "\n",
    "def average_cluster_consistency(clusters_1, clusters_2):\n",
    "    \"\"\"\n",
    "    Berechnet für einen Vergleich zweier Clusterlösungen den durchschnittlichen Match-Prozentsatz.\n",
    "    Für jeden Cluster in clusters_1 wird der beste Matching-Cluster in clusters_2 gesucht.\n",
    "    \"\"\"\n",
    "    match_percentages = []\n",
    "    for cluster_id, features_1 in clusters_1.items():\n",
    "        best_match = max(clusters_2.items(), key=lambda x: len(set(features_1).intersection(set(x[1]))))\n",
    "        match_percentage = len(set(features_1).intersection(set(best_match[1]))) / len(features_1) * 100\n",
    "        match_percentages.append(match_percentage)\n",
    "    return np.mean(match_percentages) if match_percentages else np.nan\n",
    "\n",
    "def get_detailed_cluster_consistency(clusters_1, clusters_2):\n",
    "    \"\"\"\n",
    "    Für jeden Cluster in clusters_1 wird der beste Matching-Cluster in clusters_2 gesucht.\n",
    "    Gibt ein Dictionary zurück: {orig_cluster: (matched_cluster, match_percentage)}\n",
    "    \"\"\"\n",
    "    details = {}\n",
    "    for cluster_id, features_1 in clusters_1.items():\n",
    "        best_match = max(clusters_2.items(), key=lambda x: len(set(features_1).intersection(set(x[1]))))\n",
    "        match_percentage = len(set(features_1).intersection(set(best_match[1]))) / len(features_1) * 100\n",
    "        details[cluster_id] = (best_match[0], match_percentage)\n",
    "    return details\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Funktion: Gruppenspezifisches Rauschen hinzufügen\n",
    "# -----------------------------\n",
    "def add_noise_to_group(df_group, noise_factor=0.1):\n",
    "    return add_noise_to_data(df_group, noise_factor=noise_factor)\n",
    "\n",
    "# -----------------------------\n",
    "# Simulation: Für eine gegebene Untergruppe\n",
    "# -----------------------------\n",
    "def simulate_state_for_group(df_original, key, noise_factor=0.1, n_reps=100, state=\"global\"):\n",
    "    \"\"\"\n",
    "    Simuliert n_reps Clusterlösungen für eine gegebene Subgruppe (key) im Zustand:\n",
    "      - \"global\": Es wird global Rauschen zum gesamten Datensatz hinzugefügt.\n",
    "      - \"group\": Es wird nur in der Subgruppe Rauschen hinzugefügt.\n",
    "    Gibt eine Liste von Clusterlösungen zurück.\n",
    "    \"\"\"\n",
    "    solutions = []\n",
    "    group_orig = df_original[(df_original[\"Verletzungsstatus\"] == key[0]) & (df_original[\"Geschlecht_weiblich\"] == key[1])]\n",
    "    for _ in range(n_reps):\n",
    "        if state == \"global\":\n",
    "            df_global_noisy = add_noise_to_data(df_original, noise_factor)\n",
    "            group = df_global_noisy[(df_global_noisy[\"Verletzungsstatus\"] == key[0]) & (df_global_noisy[\"Geschlecht_weiblich\"] == key[1])]\n",
    "        elif state == \"group\":\n",
    "            group = add_noise_to_group(group_orig, noise_factor)\n",
    "        else:\n",
    "            raise ValueError(\"state muss 'global' oder 'group' sein.\")\n",
    "        clusters = perform_clustering(group, max_clusters=4)\n",
    "        solutions.append(clusters)\n",
    "    return solutions\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main-Funktion\n",
    "# -----------------------------\n",
    "def main():\n",
    "    # 5.1 Daten laden\n",
    "    file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_neu.xlsx\"\n",
    "    df_original = pd.read_excel(file_path)\n",
    "    print(\"Original Data Shape:\", df_original.shape, \"\\n\")\n",
    "    \n",
    "    # Baseline: Original Cluster (deterministisch)\n",
    "    clusters_original = get_group_clusters(df_original)\n",
    "    \n",
    "    # --- ERSTER DURCHLAUF: Ausgabe von Variablenlisten und Visualisierungen ---\n",
    "    print(\"==== ERSTER DURCHLAUF: Variablenlisten und Visualisierungen ====\\n\")\n",
    "    \n",
    "    # Global verrauschte Cluster (ein Durchlauf)\n",
    "    df_global_noisy = add_noise_to_data(df_original, noise_factor=0.1)\n",
    "    clusters_global_noisy = get_group_clusters(df_global_noisy)\n",
    "    \n",
    "    # Gruppenspezifisch verrauschte Cluster (ein Durchlauf)\n",
    "    clusters_group_specific = {}\n",
    "    for key, group in df_original.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        group = group.reset_index(drop=True)\n",
    "        group_noisy = add_noise_to_group(group, noise_factor=0.1)\n",
    "        clusters_group_specific[key] = perform_clustering(group_noisy, max_clusters=4)\n",
    "    \n",
    "    # Ausgabe der Clusterzuordnungen (Variablenlisten)\n",
    "    print(\"--- Cluster Zuordnungen: Original ---\\n\")\n",
    "    for key, clusters in clusters_original.items():\n",
    "        print(map_group_label(key))\n",
    "        for cl, cols in clusters.items():\n",
    "            print(\"  Cluster\", cl, \":\", cols)\n",
    "        print(\"\")\n",
    "    \n",
    "    print(\"--- Cluster Zuordnungen: Global Noisy ---\\n\")\n",
    "    for key, clusters in clusters_global_noisy.items():\n",
    "        print(map_group_label(key))\n",
    "        for cl, cols in clusters.items():\n",
    "            print(\"  Cluster\", cl, \":\", cols)\n",
    "        print(\"\")\n",
    "    \n",
    "    print(\"--- Cluster Zuordnungen: Gruppenspezifisch Noisy ---\\n\")\n",
    "    for key, clusters in clusters_group_specific.items():\n",
    "        print(map_group_label(key))\n",
    "        for cl, cols in clusters.items():\n",
    "            print(\"  Cluster\", cl, \":\", cols)\n",
    "        print(\"\")\n",
    "    \n",
    "    # Visualisierung für eine Beispieluntergruppe\n",
    "    example_key = list(clusters_original.keys())[0]\n",
    "    group_orig = df_original[(df_original[\"Verletzungsstatus\"]==example_key[0]) & \n",
    "                             (df_original[\"Geschlecht_weiblich\"]==example_key[1])]\n",
    "    group_global_noisy = df_global_noisy[(df_global_noisy[\"Verletzungsstatus\"]==example_key[0]) & \n",
    "                                         (df_global_noisy[\"Geschlecht_weiblich\"]==example_key[1])]\n",
    "    group_group_noisy = add_noise_to_group(group_orig, noise_factor=0.1)\n",
    "    clusters_example = perform_clustering(group_group_noisy, max_clusters=4)\n",
    "    \n",
    "    visualize_clusters(group_orig, clusters_original[example_key],\n",
    "                         title=f\"Original Cluster ({map_group_label(example_key)})\")\n",
    "    visualize_clusters(group_global_noisy, clusters_global_noisy[example_key],\n",
    "                         title=f\"Global Noisy Cluster ({map_group_label(example_key)})\")\n",
    "    visualize_clusters(group_group_noisy, clusters_example,\n",
    "                         title=f\"Gruppenspezifisch Noisy Cluster ({map_group_label(example_key)})\")\n",
    "    \n",
    "    # --- SIMULATION (50 Wiederholungen) zur Aggregation der Metriken ---\n",
    "    n_reps = 50\n",
    "    sim_results = {}   # Speichert für jede Subgruppe: { 'original': (ARI, NMI, Consistency),\n",
    "                      #  'global': (mean_ARI, std_ARI, mean_NMI, std_NMI, mean_cons, std_cons),\n",
    "                      #  'group': (mean_ARI, std_ARI, mean_NMI, std_NMI, mean_cons, std_cons) }\n",
    "    sim_details = {}   # Für die detaillierte Konsistenz: {key: {comp: {orig_cluster: {'matched': [], 'consistency': []}} } }\n",
    "    \n",
    "    for key in clusters_original.keys():\n",
    "        sim_results[key] = {\n",
    "            'original': (1.0, 0.0, 1.0, 0.0, 100.0, 0.0),\n",
    "            'global': None,\n",
    "            'group': None\n",
    "        }\n",
    "        sim_details[key] = {\n",
    "            'orig_vs_global': {},\n",
    "            'orig_vs_group': {},\n",
    "            'global_vs_group': {}\n",
    "        }\n",
    "        \n",
    "        feature_order = get_feature_order(df_original[(df_original[\"Verletzungsstatus\"]==key[0]) & \n",
    "                                                      (df_original[\"Geschlecht_weiblich\"]==key[1])])\n",
    "        \n",
    "        # Global verrauscht\n",
    "        global_solutions = simulate_state_for_group(df_original, key, 0.1, n_reps, state=\"global\")\n",
    "        ari_g, std_ari_g, nmi_g, std_nmi_g = compute_pairwise_metrics(global_solutions, feature_order)\n",
    "        cons_g, std_cons_g = compute_pairwise_consistency(global_solutions)\n",
    "        \n",
    "        # Gruppenspezifisch verrauscht\n",
    "        group_solutions = simulate_state_for_group(df_original, key, 0.1, n_reps, state=\"group\")\n",
    "        ari_grp, std_ari_grp, nmi_grp, std_nmi_grp = compute_pairwise_metrics(group_solutions, feature_order)\n",
    "        cons_grp, std_cons_grp = compute_pairwise_consistency(group_solutions)\n",
    "        \n",
    "        sim_results[key]['global'] = (ari_g, std_ari_g, nmi_g, std_nmi_g, cons_g, std_cons_g)\n",
    "        sim_results[key]['group'] = (ari_grp, std_ari_grp, nmi_grp, std_nmi_grp, cons_grp, std_cons_grp)\n",
    "        \n",
    "        # Aggregiere detaillierte Konsistenzdaten\n",
    "        for comp, sols in zip(['orig_vs_global', 'orig_vs_group'], [global_solutions, group_solutions]):\n",
    "            details = [get_detailed_cluster_consistency(clusters_original[key], sol) for sol in sols]\n",
    "            # Nun berechnen wir für jeden Originalcluster die Liste der matched Werte und Consistencies\n",
    "            for d in details:\n",
    "                for orig_cluster, (matched, cons) in d.items():\n",
    "                    if orig_cluster not in sim_details[key][comp]:\n",
    "                        sim_details[key][comp][orig_cluster] = {'matched': [], 'consistency': []}\n",
    "                    sim_details[key][comp][orig_cluster]['matched'].append(matched)\n",
    "                    sim_details[key][comp][orig_cluster]['consistency'].append(cons)\n",
    "        \n",
    "        # Für global_vs_group Vergleich\n",
    "        details = [get_detailed_cluster_consistency(sol1, sol2) for sol1, sol2 in zip(global_solutions, group_solutions)]\n",
    "        for d in details:\n",
    "            for orig_cluster, (matched, cons) in d.items():\n",
    "                if orig_cluster not in sim_details[key]['global_vs_group']:\n",
    "                    sim_details[key]['global_vs_group'][orig_cluster] = {'matched': [], 'consistency': []}\n",
    "                sim_details[key]['global_vs_group'][orig_cluster]['matched'].append(matched)\n",
    "                sim_details[key]['global_vs_group'][orig_cluster]['consistency'].append(cons)\n",
    "    \n",
    "    # Aggregierte Ausgabe der stabilitätsmetriken\n",
    "    print(\"=== Aggregierte Stabilitätsmetriken über\", n_reps, \"Wiederholungen ===\\n\")\n",
    "    for key, metrics in sim_results.items():\n",
    "        print(map_group_label(key))\n",
    "        orig = metrics['original']\n",
    "        print(f\"  original:             ARI = {orig[0]:.3f} ± {orig[1]:.3f}, NMI = {orig[2]:.3f} ± {orig[3]:.3f}, Consistency = {orig[4]:.2f}% ± {orig[5]:.2f}%\")\n",
    "        glob = metrics['global']\n",
    "        print(f\"  global verrauscht:    ARI = {glob[0]:.3f} ± {glob[1]:.3f}, NMI = {glob[2]:.3f} ± {glob[3]:.3f}, Consistency = {glob[4]:.2f}% ± {glob[5]:.2f}%\")\n",
    "        grp = metrics['group']\n",
    "        print(f\"  gruppenspezifisch:    ARI = {grp[0]:.3f} ± {grp[1]:.3f}, NMI = {grp[2]:.3f} ± {grp[3]:.3f}, Consistency = {grp[4]:.2f}% ± {grp[5]:.2f}%\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Aggregierte Ausgabe der detaillierten Cluster-Konsistenz\n",
    "    print(\"=== Aggregierte Detaillierte Cluster-Konsistenz (Übereinstimmungsprozente) ===\\n\")\n",
    "    for key, comp_dict in sim_details.items():\n",
    "        print(map_group_label(key))\n",
    "        for comp, clusters_dict in comp_dict.items():\n",
    "            print(f\"  {comp}:\")\n",
    "            for orig_cluster, values in clusters_dict.items():\n",
    "                cons_mean = np.mean(values['consistency'])\n",
    "                cons_std = np.std(values['consistency'])\n",
    "                mode = Counter(values['matched']).most_common(1)[0][0]\n",
    "                print(f\"    Orig. Cluster {orig_cluster}: {mode} (Übereinstimmung: {cons_mean:.2f}% ± {cons_std:.2f}%)\")\n",
    "            print(\"\")\n",
    "        print(\"\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f943c-1634-4a06-8a15-e5744b7d019b",
   "metadata": {},
   "source": [
    "Clusterbildung-Validierung mit Rauschen global und gruppenspezifisch, über 100 wiederholungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b3798-931d-4bf2-a671-e967b84d4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# -----------------------------\n",
    "# 0. Hilfsfunktion: Gruppenschlüssel übersetzen\n",
    "# -----------------------------\n",
    "def map_group_label(key):\n",
    "    \"\"\"\n",
    "    Übersetzt den Gruppenschlüssel (Verletzungsstatus, Geschlecht_weiblich) \n",
    "    in eine lesbare Bezeichnung.\n",
    "    \n",
    "    Verletzungsstatus: 0 -> \"unverletzt\", 1 -> \"verletzt\"\n",
    "    Geschlecht_weiblich: 0 -> \"männlich\", 1 -> \"weiblich\"\n",
    "    \"\"\"\n",
    "    status = \"verletzt\" if key[0] == 1 else \"unverletzt\"\n",
    "    gender = \"weiblich\" if key[1] == 1 else \"männlich\"\n",
    "    return f\"Gruppe ({status}-{gender})\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Funktion: Rauschen hinzufügen\n",
    "# -----------------------------\n",
    "def add_noise_to_data(df, noise_factor=0.1):\n",
    "    \"\"\"\n",
    "    Fügt allen numerischen Spalten (außer \"Geschlecht_weiblich\" und \"Verletzungsstatus\")\n",
    "    Rauschen hinzu, wobei das Rauschen ein Anteil (noise_factor) der ursprünglichen\n",
    "    Standardabweichung beträgt.\n",
    "    \"\"\"\n",
    "    df_noisy = df.copy()\n",
    "    numeric_cols = [col for col in df_noisy.select_dtypes(include=['float64', 'int64']).columns \n",
    "                    if col not in [\"Geschlecht_weiblich\", \"Verletzungsstatus\"]]\n",
    "    for col in numeric_cols:\n",
    "        std = df_noisy[col].std()\n",
    "        noise = np.random.normal(0, std * noise_factor, size=df_noisy.shape[0])\n",
    "        df_noisy[col] += noise\n",
    "    return df_noisy\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Funktion: Clusterbildung\n",
    "# -----------------------------\n",
    "def perform_clustering(X_sub, max_clusters=4):\n",
    "    \"\"\"\n",
    "    Führt eine hierarchische Clusteranalyse auf den numerischen Features (ohne \n",
    "    \"Geschlecht_weiblich\" und \"Verletzungsstatus\") durch und teilt in max_clusters ein.\n",
    "    \"\"\"\n",
    "    cols = [col for col in X_sub.columns if col not in [\"Verletzungsstatus\", \"Geschlecht_weiblich\"]]\n",
    "    X_num = X_sub[cols]\n",
    "    corr = X_num.corr().abs()\n",
    "    dist = np.clip(1 - corr, a_min=0, a_max=None)\n",
    "    dists = squareform(dist.values)\n",
    "    Z = linkage(dists, method='ward')\n",
    "    cluster_labels = fcluster(Z, max_clusters, criterion='maxclust')\n",
    "    clusters = {}\n",
    "    for col, label in zip(cols, cluster_labels):\n",
    "        clusters.setdefault(label, []).append(col)\n",
    "    return clusters\n",
    "\n",
    "# -----------------------------\n",
    "# Hilfsfunktionen für Stabilitätsmetriken und Visualisierung\n",
    "# -----------------------------\n",
    "def get_feature_order(df):\n",
    "    return [col for col in df.columns if col not in [\"Verletzungsstatus\", \"Geschlecht_weiblich\"]]\n",
    "\n",
    "def get_cluster_labels(clusters, feature_order):\n",
    "    feature_cluster = {}\n",
    "    for cl, feats in clusters.items():\n",
    "        for feat in feats:\n",
    "            feature_cluster[feat] = cl\n",
    "    return [feature_cluster.get(feat, -1) for feat in feature_order]\n",
    "\n",
    "def visualize_clusters(df_group, clusters, title=\"Cluster Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualisiert die Cluster der Features mittels PCA (auf der Korrelationsmatrix).\n",
    "    Es werden keine Textannotationen angezeigt, damit die Grafik übersichtlicher bleibt.\n",
    "    \"\"\"\n",
    "    feature_order = get_feature_order(df_group)\n",
    "    X_num = df_group[feature_order]\n",
    "    corr = X_num.corr().values\n",
    "    pca = PCA(n_components=2)\n",
    "    coords = pca.fit_transform(corr)\n",
    "    labels = get_cluster_labels(clusters, feature_order)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    scatter = plt.scatter(coords[:,0], coords[:,1], c=labels, cmap='viridis', s=100)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar(scatter, label=\"Cluster\")\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Funktionen für Gruppierung und Vergleich\n",
    "# -----------------------------\n",
    "def get_group_clusters(df):\n",
    "    \"\"\"\n",
    "    Gruppiert den Datensatz anhand von (\"Verletzungsstatus\", \"Geschlecht_weiblich\")\n",
    "    und berechnet für jede Gruppe die Cluster.\n",
    "    \"\"\"\n",
    "    groups = {}\n",
    "    for key, group in df.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        group = group.reset_index(drop=True)\n",
    "        clusters = perform_clustering(group, max_clusters=4)\n",
    "        groups[key] = clusters\n",
    "    return groups\n",
    "\n",
    "def compute_stability_metrics(clusters_1, clusters_2, feature_order):\n",
    "    \"\"\"\n",
    "    Vergleicht zwei Clusterlösungen anhand von ARI und NMI.\n",
    "    \"\"\"\n",
    "    labels_1 = get_cluster_labels(clusters_1, feature_order)\n",
    "    labels_2 = get_cluster_labels(clusters_2, feature_order)\n",
    "    ari = adjusted_rand_score(labels_1, labels_2)\n",
    "    nmi = normalized_mutual_info_score(labels_1, labels_2)\n",
    "    return ari, nmi\n",
    "\n",
    "def compute_pairwise_metrics(solution_list, feature_order):\n",
    "    \"\"\"\n",
    "    Berechnet pairwise ARI und NMI über eine Liste von Clusterlösungen.\n",
    "    Gibt (mean_ARI, std_ARI, mean_NMI, std_NMI) zurück.\n",
    "    \"\"\"\n",
    "    aris = []\n",
    "    nmis = []\n",
    "    n = len(solution_list)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            ari, nmi = compute_stability_metrics(solution_list[i], solution_list[j], feature_order)\n",
    "            aris.append(ari)\n",
    "            nmis.append(nmi)\n",
    "    return np.mean(aris), np.std(aris), np.mean(nmis), np.std(nmis)\n",
    "\n",
    "def compute_pairwise_consistency(solution_list):\n",
    "    \"\"\"\n",
    "    Berechnet pairwise Cluster-Konsistenz (durchschnittlicher Match-Prozentsatz) über eine Liste von Clusterlösungen.\n",
    "    \"\"\"\n",
    "    consistencies = []\n",
    "    n = len(solution_list)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            cons = average_cluster_consistency(solution_list[i], solution_list[j])\n",
    "            consistencies.append(cons)\n",
    "    return np.mean(consistencies), np.std(consistencies)\n",
    "\n",
    "def average_cluster_consistency(clusters_1, clusters_2):\n",
    "    \"\"\"\n",
    "    Berechnet für einen Vergleich zweier Clusterlösungen den durchschnittlichen Match-Prozentsatz.\n",
    "    Für jeden Cluster in clusters_1 wird der beste Matching-Cluster in clusters_2 gesucht.\n",
    "    \"\"\"\n",
    "    match_percentages = []\n",
    "    for cluster_id, features_1 in clusters_1.items():\n",
    "        best_match = max(clusters_2.items(), key=lambda x: len(set(features_1).intersection(set(x[1]))))\n",
    "        match_percentage = len(set(features_1).intersection(set(best_match[1]))) / len(features_1) * 100\n",
    "        match_percentages.append(match_percentage)\n",
    "    return np.mean(match_percentages) if match_percentages else np.nan\n",
    "\n",
    "def get_detailed_cluster_consistency(clusters_1, clusters_2):\n",
    "    \"\"\"\n",
    "    Für jeden Cluster in clusters_1 wird der beste Matching-Cluster in clusters_2 gesucht.\n",
    "    Gibt ein Dictionary zurück: {orig_cluster: (matched_cluster, match_percentage)}\n",
    "    \"\"\"\n",
    "    details = {}\n",
    "    for cluster_id, features_1 in clusters_1.items():\n",
    "        best_match = max(clusters_2.items(), key=lambda x: len(set(features_1).intersection(set(x[1]))))\n",
    "        match_percentage = len(set(features_1).intersection(set(best_match[1]))) / len(features_1) * 100\n",
    "        details[cluster_id] = (best_match[0], match_percentage)\n",
    "    return details\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Funktion: Gruppenspezifisches Rauschen hinzufügen\n",
    "# -----------------------------\n",
    "def add_noise_to_group(df_group, noise_factor=0.1):\n",
    "    return add_noise_to_data(df_group, noise_factor=noise_factor)\n",
    "\n",
    "# -----------------------------\n",
    "# Simulation: Für eine gegebene Untergruppe\n",
    "# -----------------------------\n",
    "def simulate_state_for_group(df_original, key, noise_factor=0.1, n_reps=100, state=\"global\"):\n",
    "    \"\"\"\n",
    "    Simuliert n_reps Clusterlösungen für eine gegebene Subgruppe (key) im Zustand:\n",
    "      - \"global\": Es wird global Rauschen zum gesamten Datensatz hinzugefügt.\n",
    "      - \"group\": Es wird nur in der Subgruppe Rauschen hinzugefügt.\n",
    "    Gibt eine Liste von Clusterlösungen zurück.\n",
    "    \"\"\"\n",
    "    solutions = []\n",
    "    group_orig = df_original[(df_original[\"Verletzungsstatus\"] == key[0]) & (df_original[\"Geschlecht_weiblich\"] == key[1])]\n",
    "    for _ in range(n_reps):\n",
    "        if state == \"global\":\n",
    "            df_global_noisy = add_noise_to_data(df_original, noise_factor)\n",
    "            group = df_global_noisy[(df_global_noisy[\"Verletzungsstatus\"] == key[0]) & (df_global_noisy[\"Geschlecht_weiblich\"] == key[1])]\n",
    "        elif state == \"group\":\n",
    "            group = add_noise_to_group(group_orig, noise_factor)\n",
    "        else:\n",
    "            raise ValueError(\"state muss 'global' oder 'group' sein.\")\n",
    "        clusters = perform_clustering(group, max_clusters=4)\n",
    "        solutions.append(clusters)\n",
    "    return solutions\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Main-Funktion\n",
    "# -----------------------------\n",
    "def main():\n",
    "    # 5.1 Daten laden\n",
    "    file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_neu.xlsx\"\n",
    "    df_original = pd.read_excel(file_path)\n",
    "    print(\"Original Data Shape:\", df_original.shape, \"\\n\")\n",
    "    \n",
    "    # Baseline: Original Cluster (deterministisch)\n",
    "    clusters_original = get_group_clusters(df_original)\n",
    "    \n",
    "    # --- ERSTER DURCHLAUF: Ausgabe von Variablenlisten und Visualisierungen ---\n",
    "    print(\"==== ERSTER DURCHLAUF: Variablenlisten und Visualisierungen ====\\n\")\n",
    "    \n",
    "    # Global verrauschte Cluster (ein Durchlauf)\n",
    "    df_global_noisy = add_noise_to_data(df_original, noise_factor=0.1)\n",
    "    clusters_global_noisy = get_group_clusters(df_global_noisy)\n",
    "    \n",
    "    # Gruppenspezifisch verrauschte Cluster (ein Durchlauf)\n",
    "    clusters_group_specific = {}\n",
    "    for key, group in df_original.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        group = group.reset_index(drop=True)\n",
    "        group_noisy = add_noise_to_group(group, noise_factor=0.1)\n",
    "        clusters_group_specific[key] = perform_clustering(group_noisy, max_clusters=4)\n",
    "    \n",
    "    # Ausgabe der Clusterzuordnungen (Variablenlisten)\n",
    "    print(\"--- Cluster Zuordnungen: Original ---\\n\")\n",
    "    for key, clusters in clusters_original.items():\n",
    "        print(map_group_label(key))\n",
    "        for cl, cols in clusters.items():\n",
    "            print(\"  Cluster\", cl, \":\", cols)\n",
    "        print(\"\")\n",
    "    \n",
    "    print(\"--- Cluster Zuordnungen: Global Noisy ---\\n\")\n",
    "    for key, clusters in clusters_global_noisy.items():\n",
    "        print(map_group_label(key))\n",
    "        for cl, cols in clusters.items():\n",
    "            print(\"  Cluster\", cl, \":\", cols)\n",
    "        print(\"\")\n",
    "    \n",
    "    print(\"--- Cluster Zuordnungen: Gruppenspezifisch Noisy ---\\n\")\n",
    "    for key, clusters in clusters_group_specific.items():\n",
    "        print(map_group_label(key))\n",
    "        for cl, cols in clusters.items():\n",
    "            print(\"  Cluster\", cl, \":\", cols)\n",
    "        print(\"\")\n",
    "    \n",
    "    # Visualisierung für eine Beispieluntergruppe\n",
    "    example_key = list(clusters_original.keys())[0]\n",
    "    group_orig = df_original[(df_original[\"Verletzungsstatus\"]==example_key[0]) & \n",
    "                             (df_original[\"Geschlecht_weiblich\"]==example_key[1])]\n",
    "    group_global_noisy = df_global_noisy[(df_global_noisy[\"Verletzungsstatus\"]==example_key[0]) & \n",
    "                                         (df_global_noisy[\"Geschlecht_weiblich\"]==example_key[1])]\n",
    "    group_group_noisy = add_noise_to_group(group_orig, noise_factor=0.1)\n",
    "    clusters_example = perform_clustering(group_group_noisy, max_clusters=4)\n",
    "    \n",
    "    visualize_clusters(group_orig, clusters_original[example_key],\n",
    "                         title=f\"Original Cluster ({map_group_label(example_key)})\")\n",
    "    visualize_clusters(group_global_noisy, clusters_global_noisy[example_key],\n",
    "                         title=f\"Global Noisy Cluster ({map_group_label(example_key)})\")\n",
    "    visualize_clusters(group_group_noisy, clusters_example,\n",
    "                         title=f\"Gruppenspezifisch Noisy Cluster ({map_group_label(example_key)})\")\n",
    "    \n",
    "    # Aggregation der Metriken\n",
    "    n_reps = 100\n",
    "    sim_results = {}   # Speichert für jede Subgruppe: { 'original': (ARI, NMI, Consistency),\n",
    "                      #  'global': (mean_ARI, std_ARI, mean_NMI, std_NMI, mean_cons, std_cons),\n",
    "                      #  'group': (mean_ARI, std_ARI, mean_NMI, std_NMI, mean_cons, std_cons) }\n",
    "    sim_details = {}   # Für die detaillierte Konsistenz: {key: {comp: {orig_cluster: {'matched': [], 'consistency': []}} } }\n",
    "    \n",
    "    for key in clusters_original.keys():\n",
    "        sim_results[key] = {\n",
    "            'original': (1.0, 0.0, 1.0, 0.0, 100.0, 0.0),\n",
    "            'global': None,\n",
    "            'group': None\n",
    "        }\n",
    "        sim_details[key] = {\n",
    "            'orig_vs_global': {},\n",
    "            'orig_vs_group': {},\n",
    "            'global_vs_group': {}\n",
    "        }\n",
    "        \n",
    "        feature_order = get_feature_order(df_original[(df_original[\"Verletzungsstatus\"]==key[0]) & \n",
    "                                                      (df_original[\"Geschlecht_weiblich\"]==key[1])])\n",
    "        \n",
    "        # Global verrauscht\n",
    "        global_solutions = simulate_state_for_group(df_original, key, 0.1, n_reps, state=\"global\")\n",
    "        ari_g, std_ari_g, nmi_g, std_nmi_g = compute_pairwise_metrics(global_solutions, feature_order)\n",
    "        cons_g, std_cons_g = compute_pairwise_consistency(global_solutions)\n",
    "        \n",
    "        # Gruppenspezifisch verrauscht\n",
    "        group_solutions = simulate_state_for_group(df_original, key, 0.1, n_reps, state=\"group\")\n",
    "        ari_grp, std_ari_grp, nmi_grp, std_nmi_grp = compute_pairwise_metrics(group_solutions, feature_order)\n",
    "        cons_grp, std_cons_grp = compute_pairwise_consistency(group_solutions)\n",
    "        \n",
    "        sim_results[key]['global'] = (ari_g, std_ari_g, nmi_g, std_nmi_g, cons_g, std_cons_g)\n",
    "        sim_results[key]['group'] = (ari_grp, std_ari_grp, nmi_grp, std_nmi_grp, cons_grp, std_cons_grp)\n",
    "        \n",
    "        # Aggregiere detaillierte Konsistenzdaten\n",
    "        for comp, sols in zip(['orig_vs_global', 'orig_vs_group'], [global_solutions, group_solutions]):\n",
    "            details = [get_detailed_cluster_consistency(clusters_original[key], sol) for sol in sols]\n",
    "            # Nun berechnen wir für jeden Originalcluster die Liste der matched Werte und Consistencies\n",
    "            for d in details:\n",
    "                for orig_cluster, (matched, cons) in d.items():\n",
    "                    if orig_cluster not in sim_details[key][comp]:\n",
    "                        sim_details[key][comp][orig_cluster] = {'matched': [], 'consistency': []}\n",
    "                    sim_details[key][comp][orig_cluster]['matched'].append(matched)\n",
    "                    sim_details[key][comp][orig_cluster]['consistency'].append(cons)\n",
    "        \n",
    "        # Für global_vs_group Vergleich\n",
    "        details = [get_detailed_cluster_consistency(sol1, sol2) for sol1, sol2 in zip(global_solutions, group_solutions)]\n",
    "        for d in details:\n",
    "            for orig_cluster, (matched, cons) in d.items():\n",
    "                if orig_cluster not in sim_details[key]['global_vs_group']:\n",
    "                    sim_details[key]['global_vs_group'][orig_cluster] = {'matched': [], 'consistency': []}\n",
    "                sim_details[key]['global_vs_group'][orig_cluster]['matched'].append(matched)\n",
    "                sim_details[key]['global_vs_group'][orig_cluster]['consistency'].append(cons)\n",
    "    \n",
    "    # Aggregierte Ausgabe der stabilitätsmetriken\n",
    "    print(\"=== Aggregierte Stabilitätsmetriken über\", n_reps, \"Wiederholungen ===\\n\")\n",
    "    for key, metrics in sim_results.items():\n",
    "        print(map_group_label(key))\n",
    "        orig = metrics['original']\n",
    "        print(f\"  original:             ARI = {orig[0]:.3f} ± {orig[1]:.3f}, NMI = {orig[2]:.3f} ± {orig[3]:.3f}, Consistency = {orig[4]:.2f}% ± {orig[5]:.2f}%\")\n",
    "        glob = metrics['global']\n",
    "        print(f\"  global verrauscht:    ARI = {glob[0]:.3f} ± {glob[1]:.3f}, NMI = {glob[2]:.3f} ± {glob[3]:.3f}, Consistency = {glob[4]:.2f}% ± {glob[5]:.2f}%\")\n",
    "        grp = metrics['group']\n",
    "        print(f\"  gruppenspezifisch:    ARI = {grp[0]:.3f} ± {grp[1]:.3f}, NMI = {grp[2]:.3f} ± {grp[3]:.3f}, Consistency = {grp[4]:.2f}% ± {grp[5]:.2f}%\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Aggregierte Ausgabe der detaillierten Cluster-Konsistenz\n",
    "    print(\"=== Aggregierte Detaillierte Cluster-Konsistenz (Übereinstimmungsprozente) ===\\n\")\n",
    "    for key, comp_dict in sim_details.items():\n",
    "        print(map_group_label(key))\n",
    "        for comp, clusters_dict in comp_dict.items():\n",
    "            print(f\"  {comp}:\")\n",
    "            for orig_cluster, values in clusters_dict.items():\n",
    "                cons_mean = np.mean(values['consistency'])\n",
    "                cons_std = np.std(values['consistency'])\n",
    "                mode = Counter(values['matched']).most_common(1)[0][0]\n",
    "                print(f\"    Orig. Cluster {orig_cluster}: {mode} (Übereinstimmung: {cons_mean:.2f}% ± {cons_std:.2f}%)\")\n",
    "            print(\"\")\n",
    "        print(\"\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c1e7e9-7fe9-432e-b1e9-0c01753a8d19",
   "metadata": {},
   "source": [
    "Frankenstein-Datenaugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe9aaa-52c4-4a3d-a748-c095fcf99d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# -----------------------------\n",
    "# Datenaugmentierung: Funktionen\n",
    "# -----------------------------\n",
    "def load_dataset(filepath):\n",
    "    \"\"\"\n",
    "    Lädt den Datensatz und bereitet ihn für die Analyse vor.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(filepath)\n",
    "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    numeric_features = [col for col in numeric_features if col not in ['Geschlecht_weiblich', 'Verletzungsstatus']]\n",
    "    X = df[numeric_features + ['Geschlecht_weiblich']]\n",
    "    y = df['Verletzungsstatus']\n",
    "    return X, y\n",
    "\n",
    "def augment_data_by_group_means(X_train, y_train, augmentation_factor=4):\n",
    "    \"\"\"\n",
    "    Augmentiert Daten basierend auf Gruppenmittelwerten.\n",
    "    Die Augmentation erfolgt **innerhalb** der Gruppen, die durch 'Verletzungsstatus'\n",
    "    und 'Geschlecht_weiblich' definiert sind.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    \n",
    "    # Gruppierung nach Verletzungsstatus und Geschlecht\n",
    "    groups = df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"])\n",
    "    \n",
    "    total_original_samples = len(df_train)\n",
    "    total_new_samples = int(total_original_samples * (augmentation_factor - 1))\n",
    "    \n",
    "    augmented_groups = []\n",
    "    group_sizes = groups.size()\n",
    "    group_proportions = group_sizes / total_original_samples\n",
    "    \n",
    "    for (injury_status, is_female), group_df in groups:\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        group_new_samples = int(total_new_samples * group_proportions[(injury_status, is_female)])\n",
    "        new_group_samples = []\n",
    "        \n",
    "        for _ in range(group_new_samples):\n",
    "            sample_indices = np.random.choice(len(group_df), 2, replace=False)\n",
    "            sample1 = group_df.iloc[sample_indices[0]]\n",
    "            sample2 = group_df.iloc[sample_indices[1]]\n",
    "            \n",
    "            mean_sample = sample1.copy()\n",
    "            numeric_cols = [col for col in X_train.columns if col != \"Geschlecht_weiblich\"]\n",
    "            for col in numeric_cols:\n",
    "                mean_sample[col] = (sample1[col] + sample2[col]) / 2\n",
    "            \n",
    "            new_group_samples.append(mean_sample)\n",
    "        \n",
    "        if new_group_samples:\n",
    "            new_group_df = pd.DataFrame(new_group_samples)\n",
    "            augmented_groups.append(new_group_df)\n",
    "    \n",
    "    augmented_df = pd.concat([df_train] + augmented_groups, ignore_index=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    \n",
    "    return X_aug, y_aug\n",
    "\n",
    "# -----------------------------\n",
    "# Innere Cross-Validation mit Augmentierung\n",
    "# -----------------------------\n",
    "def inner_cv_with_new_augmentation(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Führt eine innere Cross-Validation durch, bei der die Datenaugmentation\n",
    "    **nur auf die Trainingsdaten** eines Folds angewandt wird.\n",
    "    Gibt den durchschnittlichen ROC AUC Score zurück.\n",
    "    \"\"\"\n",
    "    inner_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, test_idx in inner_cv.split(X_train, y_train):\n",
    "        # Aufteilen der Daten im Fold\n",
    "        X_inner_train = X_train.iloc[train_idx].copy()\n",
    "        X_inner_test = X_train.iloc[test_idx].copy()\n",
    "        y_inner_train = y_train.iloc[train_idx]\n",
    "        y_inner_test = y_train.iloc[test_idx]\n",
    "        \n",
    "        # Normalisierung: 'Geschlecht_weiblich' bleibt unberührt\n",
    "        dummy = \"Geschlecht_weiblich\"\n",
    "        cols_to_scale = [col for col in X_inner_train.columns if col != dummy]\n",
    "        scaler = StandardScaler()\n",
    "        X_inner_train[cols_to_scale] = scaler.fit_transform(X_inner_train[cols_to_scale])\n",
    "        X_inner_test[cols_to_scale] = scaler.transform(X_inner_test[cols_to_scale])\n",
    "        \n",
    "        # Augmentation **nur auf den Trainingsdaten**\n",
    "        X_inner_train_aug, y_inner_train_aug = augment_data_by_group_means(\n",
    "            X_inner_train, y_inner_train, augmentation_factor=2\n",
    "        )\n",
    "        \n",
    "        # Modelltraining und Evaluierung innerhalb des Folds\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        score = cross_val_score(model, X_inner_train_aug, y_inner_train_aug, \n",
    "                                cv=3, scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "        scores.append(score)\n",
    "    \n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score\n",
    "\n",
    "# -----------------------------\n",
    "# Innere Cross-Validation ohne Augmentation\n",
    "# -----------------------------\n",
    "def inner_cv_without_augmentation(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Führt eine innere Cross-Validation durch **ohne** Datenaugmentation.\n",
    "    Die Normalisierung erfolgt wie bei der Augmentierung, danach wird das Modell\n",
    "    auf den Original-Trainingsdaten trainiert und validiert.\n",
    "    \n",
    "    Gibt den durchschnittlichen ROC AUC Score zurück.\n",
    "    \"\"\"\n",
    "    inner_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, test_idx in inner_cv.split(X_train, y_train):\n",
    "        # Aufteilen der Daten im Fold\n",
    "        X_inner_train = X_train.iloc[train_idx].copy()\n",
    "        X_inner_test = X_train.iloc[test_idx].copy()\n",
    "        y_inner_train = y_train.iloc[train_idx]\n",
    "        y_inner_test = y_train.iloc[test_idx]\n",
    "        \n",
    "        # Normalisierung: 'Geschlecht_weiblich' bleibt unberührt\n",
    "        dummy = \"Geschlecht_weiblich\"\n",
    "        cols_to_scale = [col for col in X_inner_train.columns if col != dummy]\n",
    "        scaler = StandardScaler()\n",
    "        X_inner_train[cols_to_scale] = scaler.fit_transform(X_inner_train[cols_to_scale])\n",
    "        X_inner_test[cols_to_scale] = scaler.transform(X_inner_test[cols_to_scale])\n",
    "        \n",
    "        # Kein Augmentierungsschritt, Modelltraining direkt mit Originaldaten\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        score = cross_val_score(model, X_inner_train, y_inner_train, \n",
    "                                cv=3, scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "        scores.append(score)\n",
    "    \n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score\n",
    "\n",
    "# -----------------------------\n",
    "# Test-Ablauf\n",
    "# -----------------------------\n",
    "if __name__ == '__main__':\n",
    "    # Datensatz laden\n",
    "    filepath = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_neu.xlsx\"\n",
    "    X, y = load_dataset(filepath)\n",
    "    \n",
    "    # Innere CV mit Augmentierung\n",
    "    avg_auc_aug = inner_cv_with_new_augmentation(X, y)\n",
    "    print(f\"Durchschnittlicher ROC-AUC Score (mit Augmentation): {avg_auc_aug:.3f}\")\n",
    "    \n",
    "    # Innere CV ohne Augmentierung\n",
    "    avg_auc_orig = inner_cv_without_augmentation(X, y)\n",
    "    print(f\"Durchschnittlicher ROC-AUC Score (ohne Augmentation): {avg_auc_orig:.3f}\")\n",
    "\n",
    "   # Differenz der beiden Scores berechnen und ausgeben\n",
    "    diff = avg_auc_aug - avg_auc_orig\n",
    "    print(f\"Differenz (mit - ohne Augmentierung): {diff:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d02c9-5a22-4cf1-a044-af940509e086",
   "metadata": {},
   "source": [
    "Überprüfung der gemischten Datenaugmentation (Verteilungsmetriken und Visualisierung):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f70aeb-f45b-4efe-aceb-7630915b832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import ks_2samp, skew, kurtosis\n",
    "from sklearn.metrics import pairwise_kernels\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# def plot_mean_histograms(df_orig_list, df_aug_list, num_bins=30):\n",
    "#     \"\"\"\n",
    "#     Erstellt eine Vergleichsvisualisierung für die gemittelten Verteilungen\n",
    "#     von Original- und augmentierten Daten über alle Folds hinweg.\n",
    "#     Nur Linien (KDE) werden dargestellt, keine Boxplots.\n",
    "    \n",
    "#     :param df_orig_list: Liste von Original-DataFrames pro Fold.\n",
    "#     :param df_aug_list: Liste von augmentierten DataFrames pro Fold.\n",
    "#     :param num_bins: Anzahl der Bins für das Histogramm (optional).\n",
    "#     \"\"\"\n",
    "#     all_features = df_orig_list[0].select_dtypes(include=[np.number]).columns  # Alle numerischen Features\n",
    "    \n",
    "#     num_features = len(all_features)\n",
    "#     num_cols = 2  # Anzahl der Spalten im Grid\n",
    "#     num_rows = (num_features + num_cols - 1) // num_cols  # Berechne benötigte Zeilen\n",
    "    \n",
    "#     plt.figure(figsize=(15, 4 * num_rows))\n",
    "    \n",
    "#     for i, feature in enumerate(all_features, 1):\n",
    "#         # Sammle Werte über alle Folds hinweg\n",
    "#         orig_values = np.concatenate([df[feature].values for df in df_orig_list])\n",
    "#         aug_values = np.concatenate([df[feature].values for df in df_aug_list])\n",
    "        \n",
    "#         # Subplot für jedes Feature\n",
    "#         plt.subplot(num_rows, num_cols, i)\n",
    "        \n",
    "#         # KDE-Linien für die Original- und augmentierten Daten\n",
    "#         sns.kdeplot(orig_values, color=\"blue\", label=\"Original\", fill=True, alpha=0.5)\n",
    "#         sns.kdeplot(aug_values, color=\"orange\", label=\"Augmentiert\", fill=True, alpha=0.5)\n",
    "        \n",
    "#         # Titel und Beschriftungen\n",
    "#         plt.title(f\"Feature: {feature}\")\n",
    "#         plt.xlabel(\"Wert\")\n",
    "#         plt.ylabel(\"Dichte\")\n",
    "#         plt.legend()\n",
    "    \n",
    "#     # Titel für die gesamte Visualisierung\n",
    "#     plt.suptitle('Feature-Verteilungen: Original vs. Augmentiert', fontsize=16)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "def plot_mean_histograms(df_orig_list, df_aug_list, num_bins=30):\n",
    "    \"\"\"\n",
    "    Erstellt eine Vergleichsvisualisierung für die gemittelten Verteilungen\n",
    "    von Original- und augmentierten Daten über alle Folds hinweg.\n",
    "    Nur Linien (KDE) werden dargestellt, keine Boxplots.\n",
    "    \n",
    "    :param df_orig_list: Liste von Original-DataFrames pro Fold.\n",
    "    :param df_aug_list: Liste von augmentierten DataFrames pro Fold.\n",
    "    :param num_bins: Anzahl der Bins für das Histogramm (optional).\n",
    "    \"\"\"\n",
    "    all_features = df_orig_list[0].select_dtypes(include=[np.number]).columns  # Alle numerischen Features\n",
    "    \n",
    "    num_features = len(all_features)\n",
    "    num_cols = 2  # Anzahl der Spalten im Grid\n",
    "    num_rows = (num_features + num_cols - 1) // num_cols  # Berechne benötigte Zeilen\n",
    "    \n",
    "    plt.figure(figsize=(15, 4 * num_rows))\n",
    "    \n",
    "    for i, feature in enumerate(all_features, 1):\n",
    "        # Sammle Werte über alle Folds hinweg\n",
    "        orig_values = np.concatenate([df[feature].values for df in df_orig_list])\n",
    "        aug_values = np.concatenate([df[feature].values for df in df_aug_list])\n",
    "        \n",
    "        # Subplot für jedes Feature\n",
    "        plt.subplot(num_rows, num_cols, i)\n",
    "        \n",
    "        # KDE-Linien für die Original- und augmentierten Daten mit kontrastreichen Farben\n",
    "        sns.kdeplot(orig_values, color=\"blue\", label=\"Original\", fill=True, alpha=0.3)\n",
    "        sns.kdeplot(aug_values, color=\"red\", label=\"Augmentiert\", fill=True, alpha=0.3)\n",
    "        \n",
    "        # Titel und Beschriftungen\n",
    "        plt.title(f\"Feature: {feature}\")\n",
    "        plt.xlabel(\"Wert\")\n",
    "        plt.ylabel(\"Dichte\")\n",
    "        plt.legend()\n",
    "    \n",
    "    # Titel für die gesamte Visualisierung\n",
    "    plt.suptitle('Feature-Verteilungen: Original vs. Augmentiert', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Hier kommen die bereits definierten Funktionen zur Datenaugmentation:\n",
    "# (perform_clustering, augment_subgroup, process_group_cluster, \n",
    "#  augment_training_data_cluster, add_noise_to_data, add_noise_to_group,\n",
    "#  process_group_cluster_noise, augment_training_data_cluster_noise,\n",
    "#  process_group_means, augment_data_by_group_means, augment_training_data_combined)\n",
    "# =============================================================================\n",
    "def perform_clustering(X_sub, max_clusters=4):\n",
    "    # Wähle alle numerischen Spalten außer den Gruppierungsvariablen\n",
    "    cols = [col for col in X_sub.columns if col not in [\"Verletzungsstatus\", \"Geschlecht_weiblich\"]]\n",
    "    X_num = X_sub[cols]\n",
    "    # Berechne die (absoluten) Korrelationen und transformiere in Distanzen\n",
    "    corr = X_num.corr().abs()\n",
    "    dist = np.clip(1 - corr, a_min=0, a_max=None)\n",
    "    dists = squareform(dist.values)\n",
    "    Z = linkage(dists, method='ward')\n",
    "    cluster_labels = fcluster(Z, max_clusters, criterion='maxclust')\n",
    "    clusters = {}\n",
    "    for col, label in zip(cols, cluster_labels):\n",
    "        clusters.setdefault(label, []).append(col)\n",
    "    return clusters\n",
    "\n",
    "def augment_subgroup(X_sub, clusters, p_augment=0.7):\n",
    "    # Für jede Cluster-Gruppe: berechne Mittelwert und Kovarianzmatrix\n",
    "    augmented_rows = []\n",
    "    cluster_params = {}\n",
    "    for cl_id, cols in clusters.items():\n",
    "        cluster_data = X_sub[cols]\n",
    "        mu = cluster_data.mean().values\n",
    "        if len(cols) == 1:\n",
    "            cov = np.cov(cluster_data.values.flatten(), ddof=0)\n",
    "            cov = np.atleast_2d(cov)\n",
    "        else:\n",
    "            cov = np.cov(cluster_data.values, rowvar=False)\n",
    "        cluster_params[cl_id] = (mu, cov, cols)\n",
    "    # Für jede Zeile werden für jede Cluster-Gruppe (stochastisch) neue Werte gezogen\n",
    "    for idx, row in X_sub.iterrows():\n",
    "        new_row = row.copy()\n",
    "        for cl_id, (mu, cov, cols) in cluster_params.items():\n",
    "            if np.random.rand() < p_augment:\n",
    "                new_values = np.random.multivariate_normal(mu, cov)\n",
    "                for col, val in zip(cols, new_values):\n",
    "                    new_row[col] = val\n",
    "        augmented_rows.append(new_row)\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    for col in [\"Geschlecht_weiblich\", \"Verletzungsstatus\"]:\n",
    "        if col in augmented_df.columns:\n",
    "            augmented_df[col] = augmented_df[col].astype(int)\n",
    "    return augmented_df\n",
    "\n",
    "# Parallel processing for augmenting one group\n",
    "def process_group_cluster(group_df, num_new_samples, max_clusters, p_augment):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    clusters = perform_clustering(group_df, max_clusters=max_clusters)\n",
    "    aug_list = []\n",
    "    for _ in range(num_new_samples):\n",
    "        aug = augment_subgroup(group_df, clusters, p_augment=p_augment)\n",
    "        aug_list.append(aug)\n",
    "    aug_group = pd.concat(aug_list, axis=0)\n",
    "    return aug_group\n",
    "\n",
    "def augment_training_data_cluster(X_train, y_train, num_new_samples=1, max_clusters=4, p_augment=0.7, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Augmentiert die Trainingsdaten nach dem Cluster-Ansatz mit paralleler Verarbeitung.\n",
    "    num_new_samples gibt an, wie viele augmentierte Samples pro Originalzeile generiert werden.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    \n",
    "    # Prepare groups for parallel processing\n",
    "    groups = []\n",
    "    for key, group_df in df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        groups.append(group_df)\n",
    "    \n",
    "    # Process groups in parallel\n",
    "    augmented_groups = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_group_cluster)(\n",
    "            group_df, num_new_samples, max_clusters, p_augment\n",
    "        ) for group_df in groups\n",
    "    )\n",
    "        \n",
    "    augmented_df = pd.concat(augmented_groups, axis=0).reset_index(drop=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "\n",
    "### 2. Cluster-basierte Augmentation mit Rauschen\n",
    "def add_noise_to_data(df, noise_factor=0.1):\n",
    "    df_noisy = df.copy()\n",
    "    numeric_cols = [col for col in df_noisy.select_dtypes(include=['float64', 'int64']).columns \n",
    "                    if col not in [\"Geschlecht_weiblich\", \"Verletzungsstatus\"]]\n",
    "    for col in numeric_cols:\n",
    "        std = df_noisy[col].std()\n",
    "        noise = np.random.normal(0, std * noise_factor, size=df_noisy.shape[0])\n",
    "        df_noisy[col] += noise\n",
    "    return df_noisy\n",
    "\n",
    "def add_noise_to_group(df_group, noise_factor=0.1):\n",
    "    # Hier wird einfach die oben definierte Funktion genutzt\n",
    "    return add_noise_to_data(df_group, noise_factor=noise_factor)\n",
    "\n",
    "# Parallel processing for cluster with noise\n",
    "def process_group_cluster_noise(group_df, num_new_samples, max_clusters, p_augment, noise_factor):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    clusters = perform_clustering(group_df, max_clusters=max_clusters)\n",
    "    aug_list = []\n",
    "    for _ in range(num_new_samples):\n",
    "        aug = augment_subgroup(group_df, clusters, p_augment=p_augment)\n",
    "        aug_list.append(aug)\n",
    "    aug_group = pd.concat(aug_list, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Wende Rauschen an: teile die augmentierten Daten in zwei Hälften\n",
    "    n = len(aug_group)\n",
    "    half = n // 2\n",
    "    global_noise = add_noise_to_data(aug_group.copy(), noise_factor=noise_factor)\n",
    "    group_noise = add_noise_to_group(aug_group.copy(), noise_factor=noise_factor)\n",
    "    # Nehme jeweils die erste Hälfte (bei ungerader Anzahl wird der Rest ignoriert)\n",
    "    aug_noisy = pd.concat([global_noise.iloc[:half], group_noise.iloc[:half]], axis=0)\n",
    "    return aug_noisy\n",
    "\n",
    "def augment_training_data_cluster_noise(X_train, y_train, num_new_samples=1, max_clusters=4, p_augment=0.7, noise_factor=0.1, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Wie augment_training_data_cluster, jedoch wird auf den erzeugten augmentierten Samples\n",
    "    zusätzlich Rauschen angehängt – zur Hälfte global und zur Hälfte gruppenspezifisch.\n",
    "    Parallele Verarbeitung mit n_jobs.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    \n",
    "    # Prepare groups for parallel processing\n",
    "    groups = []\n",
    "    for key, group_df in df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        groups.append(group_df)\n",
    "    \n",
    "    # Process groups in parallel\n",
    "    augmented_groups = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_group_cluster_noise)(\n",
    "            group_df, num_new_samples, max_clusters, p_augment, noise_factor\n",
    "        ) for group_df in groups\n",
    "    )\n",
    "        \n",
    "    augmented_df = pd.concat(augmented_groups, axis=0).reset_index(drop=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "\n",
    "### 3. Augmentation über Mittelwert-Bildung (Gruppenmittelwerte)\n",
    "\n",
    "# Function to process a single group with mean-based augmentation\n",
    "def process_group_means(group_df, group_new_samples):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    new_group_samples = []\n",
    "    for _ in range(group_new_samples):\n",
    "        sample_indices = np.random.choice(len(group_df), 2, replace=False)\n",
    "        sample1 = group_df.iloc[sample_indices[0]]\n",
    "        sample2 = group_df.iloc[sample_indices[1]]\n",
    "        mean_sample = sample1.copy()\n",
    "        numeric_cols = [col for col in group_df.columns if col != \"Geschlecht_weiblich\"]\n",
    "        for col in numeric_cols:\n",
    "            mean_sample[col] = (sample1[col] + sample2[col]) / 2\n",
    "        new_group_samples.append(mean_sample)\n",
    "    if new_group_samples:\n",
    "        return pd.DataFrame(new_group_samples)\n",
    "    return None\n",
    "\n",
    "def augment_data_by_group_means(X_train, y_train, augmentation_factor=2, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Augmentiert Daten basierend auf Gruppenmittelwerten mit paralleler Verarbeitung.\n",
    "    Die Augmentation erfolgt innerhalb der Gruppen, die durch 'Verletzungsstatus'\n",
    "    und 'Geschlecht_weiblich' definiert sind.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    groups = df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"])\n",
    "    total_original_samples = len(df_train)\n",
    "    total_new_samples = int(total_original_samples * (augmentation_factor - 1))\n",
    "    group_sizes = groups.size()\n",
    "    group_proportions = group_sizes / total_original_samples\n",
    "    \n",
    "    # Prepare tasks for parallel processing\n",
    "    tasks = []\n",
    "    for (injury_status, is_female), group_df in groups:\n",
    "        group_new_samples = int(total_new_samples * group_proportions[(injury_status, is_female)])\n",
    "        tasks.append((group_df, group_new_samples))\n",
    "    \n",
    "    # Process groups in parallel\n",
    "    augmented_groups = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_group_means)(group_df, group_new_samples) \n",
    "        for group_df, group_new_samples in tasks\n",
    "    )\n",
    "    \n",
    "    # Filter out None results\n",
    "    augmented_groups = [group for group in augmented_groups if group is not None]\n",
    "    \n",
    "    augmented_df = pd.concat([df_train] + augmented_groups, ignore_index=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "\n",
    "def augment_training_data_combined(X_train, y_train, target_size=1000, visualize=False, max_plots=10, verbose=True, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Augment training data with parallel processing\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    N = len(X_train)\n",
    "    additional_needed = max(target_size - N, 0)\n",
    "    per_method_needed = additional_needed // 3\n",
    "\n",
    "    num_new_samples = max(per_method_needed // N, 1)\n",
    "    augmentation_factor = 1 + (per_method_needed / N)\n",
    "\n",
    "    # Remove the print statements if verbose is False\n",
    "    if verbose:\n",
    "        print(f\"Starting combined augmentation to reach target size: {target_size}\")\n",
    "        print(f\"Original dataset size: {N}\")\n",
    "        print(f\"Samples needed per method: {per_method_needed}\")\n",
    "    \n",
    "    # Parallel execution of all three augmentation methods\n",
    "    results = Parallel(n_jobs=min(3, n_jobs))(\n",
    "        delayed(func)(X_train, y_train, **params) for func, params in [\n",
    "            (augment_training_data_cluster, {\"num_new_samples\": num_new_samples, \"n_jobs\": n_jobs}),\n",
    "            (augment_training_data_cluster_noise, {\"num_new_samples\": num_new_samples, \"n_jobs\": n_jobs}),\n",
    "            (augment_data_by_group_means, {\"augmentation_factor\": augmentation_factor, \"n_jobs\": n_jobs})\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X_aug_cluster, y_aug_cluster = results[0]\n",
    "    X_aug_cluster_noise, y_aug_cluster_noise = results[1] \n",
    "    X_aug_group_means, y_aug_group_means = results[2]\n",
    "    \n",
    "    def subsample(X_aug, y_aug, required):\n",
    "        if len(X_aug) > required:\n",
    "            idx = np.random.choice(len(X_aug), required, replace=False)\n",
    "            return X_aug.iloc[idx].reset_index(drop=True), y_aug.iloc[idx].reset_index(drop=True)\n",
    "        else:\n",
    "            return X_aug, y_aug\n",
    "\n",
    "    X_aug_cluster, y_aug_cluster = subsample(X_aug_cluster, y_aug_cluster, per_method_needed)\n",
    "    X_aug_cluster_noise, y_aug_cluster_noise = subsample(X_aug_cluster_noise, y_aug_cluster_noise, per_method_needed)\n",
    "    X_aug_group_means, y_aug_group_means = subsample(X_aug_group_means, y_aug_group_means, per_method_needed)\n",
    "\n",
    "    X_aug_combined = pd.concat([X_aug_cluster, X_aug_cluster_noise, X_aug_group_means], axis=0).reset_index(drop=True)\n",
    "    y_aug_combined = pd.concat([y_aug_cluster, y_aug_cluster_noise, y_aug_group_means], axis=0).reset_index(drop=True)\n",
    "\n",
    "    X_total = pd.concat([X_train.reset_index(drop=True), X_aug_combined], axis=0).reset_index(drop=True)\n",
    "    y_total = pd.concat([y_train.reset_index(drop=True), y_aug_combined], axis=0).reset_index(drop=True)\n",
    "\n",
    "    if len(X_total) > target_size:\n",
    "        idx = np.random.choice(len(X_total), target_size, replace=False)\n",
    "        X_total = X_total.iloc[idx].reset_index(drop=True)\n",
    "        y_total = y_total.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Remove these print statements if verbose is False\n",
    "    if verbose:\n",
    "        print(f\"Augmentation completed. Final dataset size: {len(X_total)}\")\n",
    "        print(f\"Augmentation took {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    if visualize:\n",
    "        if verbose:\n",
    "            print(\"Visualizing distributions of original vs augmented data...\")\n",
    "        cols_to_plot = list(X_train.columns)[:max_plots]\n",
    "        plot_distribution_comparison(X_train, X_aug_combined, cols_to_plot)\n",
    "        plt.suptitle('Feature Distributions: Original vs Augmented Data', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.countplot(x=y_train)\n",
    "        plt.title('Original Target Distribution')\n",
    "        plt.xlabel('Verletzungsstatus')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.countplot(x=y_total)\n",
    "        plt.title('Augmented Target Distribution')\n",
    "        plt.xlabel('Verletzungsstatus')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return X_total, y_total\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Funktionen zur Berechnung der MMD und zum Vergleichen der Verteilungen\n",
    "# =============================================================================\n",
    "\n",
    "def compute_mmd(X, Y, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Berechnet die Maximum Mean Discrepancy (MMD) zwischen zwei Datensätzen X und Y\n",
    "    unter Verwendung eines RBF-Kernels.\n",
    "    \"\"\"\n",
    "    gamma = 1.0 / (2 * sigma ** 2)\n",
    "    Kxx = pairwise_kernels(X, metric='rbf', gamma=gamma)\n",
    "    Kyy = pairwise_kernels(Y, metric='rbf', gamma=gamma)\n",
    "    Kxy = pairwise_kernels(X, Y, metric='rbf', gamma=gamma)\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    m = Y.shape[0]\n",
    "    sum_Kxx = (Kxx.sum() - np.trace(Kxx)) / (n * (n - 1))\n",
    "    sum_Kyy = (Kyy.sum() - np.trace(Kyy)) / (m * (m - 1))\n",
    "    sum_Kxy = Kxy.mean()  # entspricht 1/(n*m)*sum(Kxy)\n",
    "    \n",
    "    mmd_squared = sum_Kxx + sum_Kyy - 2 * sum_Kxy\n",
    "    return np.sqrt(max(mmd_squared, 0))\n",
    "\n",
    "\n",
    "def compare_distributions(original_df, augmented_df, binary_cols=['Verletzungsstatus', 'Geschlecht_weiblich']):\n",
    "    \"\"\"\n",
    "    Führt für jede kontinuierliche Variable (alle Spalten außer den binären Variablen)\n",
    "    den KS-Test sowie den Vergleich der Momente (Mittelwert, Varianz, Schiefe, Kurtosis) durch.\n",
    "    Gibt die Ergebnisse in einem Dictionary zurück.\n",
    "    \"\"\"\n",
    "    numeric_cols = [col for col in original_df.columns if col not in binary_cols]\n",
    "    results = {}\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        orig_data = original_df[col].dropna().values\n",
    "        aug_data = augmented_df[col].dropna().values\n",
    "        \n",
    "        ks_stat, ks_p = ks_2samp(orig_data, aug_data)\n",
    "        \n",
    "        results[col] = {\n",
    "            'KS-Statistik': ks_stat,\n",
    "            'KS-p-Wert': ks_p,\n",
    "            'Mittelwert Original': np.mean(orig_data),\n",
    "            'Mittelwert Augmentiert': np.mean(aug_data),\n",
    "            'Varianz Original': np.var(orig_data, ddof=1),\n",
    "            'Varianz Augmentiert': np.var(aug_data, ddof=1),\n",
    "            'Schiefe Original': skew(orig_data),\n",
    "            'Schiefe Augmentiert': skew(aug_data),\n",
    "            'Kurtosis Original': kurtosis(orig_data),\n",
    "            'Kurtosis Augmentiert': kurtosis(aug_data)\n",
    "        }\n",
    "        \n",
    "        # # Optionale Ausgabe pro Feature:\n",
    "        # print(f\"Feature: {col}\")\n",
    "        # print(f\"  KS-Test: Stat = {ks_stat:.4f}, p = {ks_p:.4f}\")\n",
    "        # print(f\"  Mittelwert: Original = {np.mean(orig_data):.4f}, Augmentiert = {np.mean(aug_data):.4f}\")\n",
    "        # print(f\"  Varianz: Original = {np.var(orig_data, ddof=1):.4f}, Augmentiert = {np.var(aug_data, ddof=1):.4f}\")\n",
    "        # print(f\"  Schiefe: Original = {skew(orig_data):.4f}, Augmentiert = {skew(aug_data):.4f}\")\n",
    "        # print(f\"  Kurtosis: Original = {kurtosis(orig_data):.4f}, Augmentiert = {kurtosis(aug_data):.4f}\")\n",
    "        # print(\"-\" * 50)\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "def compute_multivariate_mmd(original_df, augmented_df, binary_cols=['Verletzungsstatus', 'Geschlecht_weiblich'], sigma=1.0):\n",
    "    \"\"\"\n",
    "    Berechnet die multivariate MMD für alle kontinuierlichen Variablen (ohne die binären)\n",
    "    zwischen den Original- und den augmentierten Daten.\n",
    "    \"\"\"\n",
    "    numeric_cols = [col for col in original_df.columns if col not in binary_cols]\n",
    "    X_orig = original_df[numeric_cols].dropna().values\n",
    "    X_aug = augmented_df[numeric_cols].dropna().values\n",
    "    \n",
    "    mmd_value = compute_mmd(X_orig, X_aug, sigma=sigma)\n",
    "    #print(f\"Multivariate MMD (sigma={sigma}): {mmd_value:.4f}\")\n",
    "    return mmd_value\n",
    "\n",
    "\n",
    "def compute_binary_metrics(original_df, augmented_df, binary_cols=['Verletzungsstatus', 'Geschlecht_weiblich']):\n",
    "    \"\"\"\n",
    "    Berechnet relative Häufigkeiten für die binären Variablen und \n",
    "    liefert für jedes Level die Differenz zwischen Original- und augmentierten Daten.\n",
    "    \"\"\"\n",
    "    bin_metrics = {}\n",
    "    for col in binary_cols:\n",
    "        orig_counts = original_df[col].value_counts(normalize=True).sort_index()\n",
    "        aug_counts = augmented_df[col].value_counts(normalize=True).sort_index()\n",
    "        # Sicherstellen, dass beide Levels vorhanden sind:\n",
    "        p_orig_0 = orig_counts.get(0, 0)\n",
    "        p_orig_1 = orig_counts.get(1, 0)\n",
    "        p_aug_0 = aug_counts.get(0, 0)\n",
    "        p_aug_1 = aug_counts.get(1, 0)\n",
    "        bin_metrics[col] = {\n",
    "            \"Original\": {0: p_orig_0, 1: p_orig_1},\n",
    "            \"Augmentiert\": {0: p_aug_0, 1: p_aug_1},\n",
    "            \"Differenz\": {0: abs(p_orig_0 - p_aug_0), 1: abs(p_orig_1 - p_aug_1)}\n",
    "        }\n",
    "        # # Optionale Ausgabe:\n",
    "        # print(f\"Verteilung der binären Variable {col}:\")\n",
    "        # print(\"  Original:\", {0: p_orig_0, 1: p_orig_1})\n",
    "        # print(\"  Augmentiert:\", {0: p_aug_0, 1: p_aug_1})\n",
    "        # print(\"  Differenz:\", {0: abs(p_orig_0 - p_aug_0), 1: abs(p_orig_1 - p_aug_1)})\n",
    "        # print(\"-\" * 50)\n",
    "    return bin_metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Daten einlesen – passe den Dateipfad ggf. an\n",
    "    df = pd.read_excel(r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_neu.xlsx\")\n",
    "    \n",
    "    # Annahme: \"Verletzungsstatus\" ist das Target, \"Geschlecht_weiblich\" ist ein weiterer (binärer) Prädiktor.\n",
    "    y = df[\"Verletzungsstatus\"]\n",
    "    X = df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    \n",
    "    # Definiere eine stratified CV \n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "    \n",
    "    # Listen zum Speichern der Metriken pro CV-Durchgang\n",
    "    continuous_metrics_list = []  # pro Fold: Dictionary {Feature: {KS, Moments, ...}}\n",
    "    binary_metrics_list = []      # pro Fold: Dictionary für binäre Variablen\n",
    "    mmd_list = []                 # pro Fold: multivariate MMD\n",
    "    \n",
    "    fold_index = 1\n",
    "    df_orig_list = []\n",
    "    df_aug_list = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_index].copy(), y.iloc[train_index].copy()\n",
    "        target_size = int(len(X_train) * 11)\n",
    "        \n",
    "        # Augmentation durchführen\n",
    "        X_aug, y_aug = augment_training_data_combined(X_train, y_train, target_size=target_size, visualize=False, verbose=False, n_jobs=-1)\n",
    "        \n",
    "        # DataFrames erstellen (inkl. Verletzungsstatus)\n",
    "        df_orig = X_train.copy()\n",
    "        df_orig[\"Verletzungsstatus\"] = y_train\n",
    "        df_aug = X_aug.copy()\n",
    "        df_aug[\"Verletzungsstatus\"] = y_aug\n",
    "        \n",
    "        # Speichere die DataFrames für spätere Histogramme\n",
    "        df_orig_list.append(df_orig)\n",
    "        df_aug_list.append(df_aug)\n",
    "    \n",
    "        # Vergleiche kontinuierliche Features\n",
    "        cont_metrics = compare_distributions(df_orig, df_aug)\n",
    "        continuous_metrics_list.append(cont_metrics)\n",
    "    \n",
    "        # Vergleiche binäre Variablen\n",
    "        bin_metrics = compute_binary_metrics(df_orig, df_aug)\n",
    "        binary_metrics_list.append(bin_metrics)\n",
    "    \n",
    "        # Berechne multivariate MMD\n",
    "        mmd_val = compute_multivariate_mmd(df_orig, df_aug, sigma=1.0)\n",
    "        mmd_list.append(mmd_val)\n",
    "    \n",
    "        fold_index += 1\n",
    "\n",
    "    # =============================================================================\n",
    "    # Aggregation der Metriken über alle CV-Durchgänge\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Aggregiere kontinuierliche Metriken\n",
    "    aggregated_cont_metrics = {}\n",
    "    for fold_metrics in continuous_metrics_list:\n",
    "        for feature, metrics in fold_metrics.items():\n",
    "            if feature not in aggregated_cont_metrics:\n",
    "                aggregated_cont_metrics[feature] = {}\n",
    "            for key, value in metrics.items():\n",
    "                aggregated_cont_metrics[feature].setdefault(key, []).append(value)\n",
    "    # Berechne Durchschnittswerte\n",
    "    for feature, metrics in aggregated_cont_metrics.items():\n",
    "        for key, values in metrics.items():\n",
    "            aggregated_cont_metrics[feature][key] = np.mean(values)\n",
    "    \n",
    "    # Aggregiere binäre Metriken\n",
    "    aggregated_bin_metrics = {}\n",
    "    for fold_bin in binary_metrics_list:\n",
    "        for col, metrics in fold_bin.items():\n",
    "            if col not in aggregated_bin_metrics:\n",
    "                aggregated_bin_metrics[col] = {\"Original\": {0: [], 1: []},\n",
    "                                               \"Augmentiert\": {0: [], 1: []},\n",
    "                                               \"Differenz\": {0: [], 1: []}}\n",
    "            for level in [0, 1]:\n",
    "                aggregated_bin_metrics[col][\"Original\"][level].append(metrics[\"Original\"][level])\n",
    "                aggregated_bin_metrics[col][\"Augmentiert\"][level].append(metrics[\"Augmentiert\"][level])\n",
    "                aggregated_bin_metrics[col][\"Differenz\"][level].append(metrics[\"Differenz\"][level])\n",
    "    # Durchschnittsbildung\n",
    "    for col, metrics in aggregated_bin_metrics.items():\n",
    "        for level in [0, 1]:\n",
    "            aggregated_bin_metrics[col][\"Original\"][level] = np.mean(metrics[\"Original\"][level])\n",
    "            aggregated_bin_metrics[col][\"Augmentiert\"][level] = np.mean(metrics[\"Augmentiert\"][level])\n",
    "            aggregated_bin_metrics[col][\"Differenz\"][level] = np.mean(metrics[\"Differenz\"][level])\n",
    "    \n",
    "    # Aggregiere MMD\n",
    "    avg_mmd = np.mean(mmd_list)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Ausgabe der aggregierten Metriken\n",
    "    # =============================================================================\n",
    "    print(\"\\n=== Aggregierte Metriken über alle CV-Durchgänge ===\\n\")\n",
    "    \n",
    "    print(\"Kontinuierliche Features:\")\n",
    "    for feature, metrics in aggregated_cont_metrics.items():\n",
    "        print(f\"Feature: {feature}\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    print(\"\\nBinäre Variablen:\")\n",
    "    for col, metrics in aggregated_bin_metrics.items():\n",
    "        print(f\"Variable: {col}\")\n",
    "        for level in [0, 1]:\n",
    "            print(f\"  Level {level} - Original: {metrics['Original'][level]:.4f}, \"\n",
    "                  f\"Augmentiert: {metrics['Augmentiert'][level]:.4f}, \"\n",
    "                  f\"Differenz: {metrics['Differenz'][level]:.4f}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    print(f\"\\nDurchschnittliche multivariate MMD: {avg_mmd:.4f}\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # Erstelle Histogramme für alle kontinuierlichen Features\n",
    "    # =============================================================================\n",
    "    # Erstelle Histogramme für alle kontinuierlichen Features\n",
    "    print(\"\\n=== Erstelle gemittelte Histogramme ===\\n\")\n",
    "    plot_mean_histograms(df_orig_list, df_aug_list, num_bins=30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9280e-1802-4bf0-9752-718922054132",
   "metadata": {},
   "source": [
    "Modellvergleich mit Datenaugmentation auf den Testdaten und CV (33% Cluster-Ansatz, 33% Cluster-Ansatz mit Rauschen und 33% Frankenstein-Methode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ebcdc51-036f-46f8-a95b-2da63defd43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_neu.xlsx...\n",
      "Dataset loaded. Shape: (113, 114)\n",
      "Gender column 'Geschlecht_weiblich' found in dataset.\n",
      "\n",
      "Data Overview:\n",
      "Total samples: 113\n",
      "Features: 113\n",
      "Target distribution:\n",
      "Verletzungsstatus\n",
      "1    61\n",
      "0    52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Visualizing original data distributions...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0oAAAIhCAYAAABwnkrAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6q0lEQVR4nO3deZgV1Zk/8PeyNQ00qAjdoC1ibMUF3DAEjIILGNyixLiACiP6U3FDdDRIHFvHNAkmiAmKkYyAMURjXBNRYWSRCSqLEh0X3NgSaXFBIIiNQP3+8Ok73upGAdGL8Pk8Tz0PderUqbeqW5svp+7pTJIkSQAAAJBVJ98FAAAAbG0EJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCWAjZDJZDZqmzp1ar5LzfHKK69EeXl5LFiw4Ev7nnLKKVFYWBgfffTRBvv06dMn6tevH+++++5Xrm3BggWRyWRi7Nixm3zu1KlTI5PJxJ///Ocv7VteXh6ZTGYzKvzia1dvDRo0iBYtWsRhhx0WQ4YMiYULF9Y4Z+zYsZHJZDbq6/B5FRUV8fDDD2/SObVdq1u3brH//vtv0jhfZsKECVFeXl7rsd133z369eu3Ra8H8E0TlAA2wjPPPJOzHXfccVFYWFij/eCDD853qTleeeWVuOGGGzbqL+j9+/ePTz75JMaPH1/r8eXLl8dDDz0UJ5xwQhQXF3/l2lq1ahXPPPNMHH/88V95rHyoqKiIZ555JqZMmRL/9V//Fd26dYu77ror9tlnn/jDH/6Q0/f444+PZ555Jlq1arXJ19jUoLS519pUEyZMiBtuuKHWYw899FBcd911X+v1Ab5u9fJdAMC3wfe+972c/RYtWkSdOnVqtG+ujz/+OBo1arRFxtpcPXv2jNatW8ddd90VAwYMqHH8j3/8Y6xevTr69+//la6zbt26WLt2bRQUFGyx55cPZWVlOfWfdNJJceWVV8YxxxwT/fr1iw4dOkT79u0j4rPvlxYtWnyt9axevToaNmz4jVzryxx00EF5vT7AlmBGCWALue222+KII46Ili1bRuPGjaN9+/YxbNiw+PTTT3P6Vb8G9fTTT0eXLl2iUaNGce6550ZExD/+8Y849dRTo6ioKHbYYYfo06dPzJo1q9ZX1GbPnh0nnXRS7LTTTtGwYcM46KCD4k9/+lP2+NixY+PHP/5xREQceeSR2VfFNvSqW926daNv374xZ86ceOmll2ocHzNmTLRq1Sp69uwZ7733XgwYMCD23XffaNKkSbRs2TKOOuqomD59es451a/XDRs2LG666aZo27ZtFBQUxJQpU2p99e7NN9+Mf/u3f4uysrJo1KhR7LLLLnHiiSfWWk9ExCeffBKDBg2KkpKSKCwsjK5du8YLL7xQa9+0++67Lzp37hyNGzeOJk2axLHHHrvR527ITjvtFL/97W9j7dq1ccstt2Tba3sd7oUXXogTTjghWrZsGQUFBdG6des4/vjj4x//+EdEfPa656pVq2LcuHHZr123bt1yxps4cWKce+650aJFi2jUqFFUVVV94Wt+06dPj+9973tRWFgYu+yyS1x33XWxbt267PHq1wrTr5Cmv1b9+vWL2267LVtn9VZ9zdpevVu0aFGcddZZ2fvdZ5994le/+lWsX7++xnV++ctfxvDhw6Nt27bRpEmT6Ny5czz77LOb8JUA+OoEJYAt5K233orevXvH73//+/jrX/8a/fv3j5tvvjkuuOCCGn2XLFkSZ511VvTu3TsmTJgQAwYMiFWrVsWRRx4ZU6ZMiV/84hfxpz/9KYqLi+P000+vcf6UKVPisMMOi48++ijuuOOOeOSRR+LAAw+M008/PfuX2eOPPz4qKioi4rMQV/164Be96nbuuedGJpOJu+66K6f9lVdeiZkzZ0bfvn2jbt268eGHH0ZExPXXXx+PPfZYjBkzJvbYY4/o1q1brZ/T+vWvfx2TJ0+OX/7yl/H4449Hu3btar3+O++8E82bN4+f//zn8cQTT8Rtt90W9erVi06dOsW8efNq9L/22mvj7bffjt/97nfxu9/9Lt55553o1q1bvP322xu8x4jPXmk788wzY999940//elP8fvf/z5WrlwZhx9+eLzyyitfeO6XOfTQQ6NVq1bx9NNPb7DPqlWronv37vHuu+/GbbfdFpMmTYoRI0bEbrvtFitXroyIz173LCwsjOOOOy77tbv99ttzxjn33HOjfv368fvf/z7+/Oc/R/369Td4zcrKyjjjjDOiT58+8cgjj8Spp54aN910U1x++eWbfI/XXXddnHrqqdk6q7cNve733nvvRZcuXWLixInxn//5n/Hoo4/GMcccE1dddVVccsklNfp//pn84Q9/iFWrVsVxxx0Xy5cv3+RaATZbAsAm69u3b9K4ceMNHl+3bl3y6aefJnfffXdSt27d5MMPP8we69q1axIRyVNPPZVzzm233ZZERPL444/ntF9wwQVJRCRjxozJtrVr1y456KCDkk8//TSn7wknnJC0atUqWbduXZIkSXL//fcnEZFMmTJlo++ta9euyc4775ysWbMm23bllVcmEZG8/vrrtZ6zdu3a5NNPP02OPvro5JRTTsm2z58/P4mI5Dvf+U7OeJ8/9vn7qm3cNWvWJGVlZckVV1yRbZ8yZUoSEcnBBx+crF+/Ptu+YMGCpH79+sl5552Xbbv++uuTz/+4W7RoUVKvXr3k0ksvzbnWypUrk5KSkuS0007bYD2fv/b999+/wT6dOnVKCgsLs/tjxoxJIiKZP39+kiRJMnv27CQikocffvgLr9W4ceOkb9++NdqrxzvnnHM2eKz6Wknyf99zjzzySE7f888/P6lTp06ycOHCnHtLf7/U9rW6+OKLkw39NaJNmzY5df/kJz9JIiJ57rnncvpddNFFSSaTSebNm5dznfbt2ydr167N9ps5c2YSEckf//jHWq8H8HUwowSwhbzwwgtx0kknRfPmzaNu3bpRv379OOecc2LdunXx+uuv5/Tdcccd46ijjsppmzZtWhQVFcUPfvCDnPYzzzwzZ//NN9+M1157Lfr06RMREWvXrs1uxx13XCxZsqTW2ZeN1b9//3j//ffj0UcfzY5/zz33xOGHHx5lZWXZfnfccUccfPDB0bBhw6hXr17Ur18/nnrqqXj11VdrjHnSSSd94WxHtbVr10ZFRUXsu+++0aBBg6hXr140aNAg3njjjVrH7d27d86Kdm3atIkuXbrElClTNniNJ598MtauXRvnnHNOzrNr2LBhdO3adYusXJgkyRce33PPPWPHHXeMa665Ju64447NnsX60Y9+tNF9i4qK4qSTTspp6927d6xfv/4LZ7+2hMmTJ8e+++4b3/3ud3Pa+/XrF0mSxOTJk3Pajz/++Khbt252v0OHDhERta4oCPB1EZQAtoBFixbF4YcfHv/85z/j1ltvjenTp8esWbOyn+NYvXp1Tv/aXlH64IMPal1NLt1WvTT3VVddFfXr18/ZqhdheP/99zf7Xk499dRo1qxZjBkzJiI+W93s3XffzVnEYfjw4XHRRRdFp06d4oEHHohnn302Zs2aFT/4wQ9q3OuG7rc2gwYNiuuuuy5OPvnk+Mtf/hLPPfdczJo1Kw444IBaxy0pKam17YMPPtjgNaqf36GHHlrj+d13331f6dlVW7RoUbRu3XqDx5s1axbTpk2LAw88MK699trYb7/9onXr1nH99dfX+EzbF9mUle1q+96qfn5f9Ly2hA8++KDWWqufUfr6zZs3z9kvKCiIiJr/HQF8nax6B7AFPPzww7Fq1ap48MEHo02bNtn2uXPn1tq/tt/r07x585g5c2aN9srKypz9nXfeOSIiBg8eHL169ap1/L333ntjS6+hsLAwzjzzzBg9enQsWbIk7rrrrigqKsouDBERcc8990S3bt1i1KhROedWf74mbWN/j9E999wT55xzTvazVdXef//92GGHHWr0Tz+b6rb0X7Q/r/r5/fnPf875Wm0pM2fOjMrKyi9dHbB9+/Zx7733RpIk8eKLL8bYsWPjxhtvjMLCwvjJT36yUdfalN8PVdvvvqp+ftXPq2HDhhERUVVVldPvq4bH5s2bx5IlS2q0v/POOxHxf18TgK2JGSWALaD6L6zV//Id8dnrV6NHj97oMbp27RorV66Mxx9/PKf93nvvzdnfe++9o6ysLP7+979Hx44da92Kiopy6tnUf4nv379/rFu3Lm6++eaYMGFCnHHGGTnLl2cymZx7jYh48cUX45lnntmk66TVNu5jjz0W//znP2vt/8c//jHnNbeFCxfGjBkzsqvD1ebYY4+NevXqxVtvvbXB57e5Pvzww7jwwgujfv36ccUVV2zUOZlMJg444IC45ZZbYocddojnn38+e6ygoGCLzaKsXLky+zpltfHjx0edOnXiiCOOiIjPVquL+Oxr+Xnp86pri9i4762jjz46XnnllZx7i4i4++67I5PJxJFHHrnR9wHwTTGjBLAFdO/ePRo0aBBnnnlmXH311fHJJ5/EqFGjYtmyZRs9Rt++feOWW26Js846K2666abYc8894/HHH48nn3wyIiLq1Pm/f9v67W9/Gz179oxjjz02+vXrF7vsskt8+OGH8eqrr8bzzz8f999/f0RE7L///hERceedd0ZRUVE0bNgw2rZt+4UzLhERHTt2jA4dOsSIESMiSZIasyMnnHBC/Od//mdcf/310bVr15g3b17ceOON0bZt21i7du1G33PaCSecEGPHjo127dpFhw4dYs6cOXHzzTfHrrvuWmv/pUuXximnnBLnn39+LF++PK6//vpo2LBhDB48eIPX2H333ePGG2+MIUOGxNtvvx0/+MEPYscdd4x33303Zs6cGY0bN97gL1L9vDfeeCOeffbZWL9+fXzwwQfx3HPPxX/913/FihUr4u6774799ttvg+f+9a9/jdtvvz1OPvnk2GOPPSJJknjwwQfjo48+iu7du2f7tW/fPqZOnRp/+ctfolWrVlFUVLTZs4XNmzePiy66KBYtWhR77bVXTJgwIUaPHh0XXXRR7LbbbhHx2at4xxxzTAwdOjR23HHHaNOmTTz11FPx4IMP1hiv+ndE/eIXv4iePXtG3bp1o0OHDtGgQYMafa+44oq4++674/jjj48bb7wx2rRpE4899ljcfvvtcdFFF8Vee+21WfcE8LXK40ISAN9ata1695e//CU54IADkoYNGya77LJL8u///u/J448/XmMVsa5duyb77bdfreMuWrQo6dWrV9KkSZOkqKgo+dGPfpRMmDCh1hXL/v73vyennXZa0rJly6R+/fpJSUlJctRRRyV33HFHTr8RI0Ykbdu2TerWrfulq8x93q233ppERLLvvvvWOFZVVZVcddVVyS677JI0bNgwOfjgg5OHH3446du3b9KmTZtsv+pVzG6++eYaY9S2ktqyZcuS/v37Jy1btkwaNWqUfP/730+mT5+edO3aNenatWu2X/XqbL///e+Tyy67LGnRokVSUFCQHH744cns2bNzrpNe9a7aww8/nBx55JFJ06ZNk4KCgqRNmzbJqaeemvz3f//3Fz6X6mtXb/Xq1UuaN2+edO7cObn22muTBQsW1DgnvRLda6+9lpx55pnJd77znaSwsDBp1qxZ8t3vfjcZO3Zsznlz585NDjvssKRRo0ZJRGSfQfV4s2bN+tJrJcn/fc9NnTo16dixY1JQUJC0atUqufbaa2usnLhkyZLk1FNPTXbaaaekWbNmyVlnnZVdpe/zX6uqqqrkvPPOS1q0aJFkMpmca6ZXvUuSJFm4cGHSu3fvpHnz5kn9+vWTvffeO7n55puzKzQmyRd/v0REcv3119doB/i6ZJLkS5bmASCvKioq4qc//WksWrRogzMrAMCW5dU7gK3IyJEjIyKiXbt28emnn8bkyZPj17/+dZx11llCEgB8gwQlgK1Io0aN4pZbbokFCxZEVVVV7LbbbnHNNdfET3/603yXBgDbFa/eAQAApFgeHAAAIEVQAgAASBGUAAAAUrb5xRzWr18f77zzThQVFUUmk8l3OQAAQJ4kSRIrV66M1q1b5/wi99ps80HpnXfeidLS0nyXAQAAbCUWL178pb92Y5sPSkVFRRHx2cNo2rRpnqsBAADyZcWKFVFaWprNCF9kmw9K1a/bNW3aVFACAAA26iM5FnMAAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgJR6+S4AALZ3h/z73fkuAWCLmnPzOfku4SszowQAAJAiKAEAAKTkPSj985//jLPOOiuaN28ejRo1igMPPDDmzJmTPZ4kSZSXl0fr1q2jsLAwunXrFi+//HIeKwYAALZ1eQ1Ky5Yti8MOOyzq168fjz/+eLzyyivxq1/9KnbYYYdsn2HDhsXw4cNj5MiRMWvWrCgpKYnu3bvHypUr81c4AACwTcvrYg6/+MUvorS0NMaMGZNt23333bN/TpIkRowYEUOGDIlevXpFRMS4ceOiuLg4xo8fHxdccME3XTIAALAdyOuM0qOPPhodO3aMH//4x9GyZcs46KCDYvTo0dnj8+fPj8rKyujRo0e2raCgILp27RozZsyodcyqqqpYsWJFzgYAALAp8hqU3n777Rg1alSUlZXFk08+GRdeeGFcdtllcffdny2TWllZGRERxcXFOecVFxdnj6UNHTo0mjVrlt1KS0u/3psAAAC2OXkNSuvXr4+DDz44Kioq4qCDDooLLrggzj///Bg1alROv0wmk7OfJEmNtmqDBw+O5cuXZ7fFixd/bfUDAADbprwGpVatWsW+++6b07bPPvvEokWLIiKipKQkIqLG7NHSpUtrzDJVKygoiKZNm+ZsAAAAmyKvQemwww6LefPm5bS9/vrr0aZNm4iIaNu2bZSUlMSkSZOyx9esWRPTpk2LLl26fKO1AgAA24+8rnp3xRVXRJcuXaKioiJOO+20mDlzZtx5551x5513RsRnr9wNHDgwKioqoqysLMrKyqKioiIaNWoUvXv3zmfpAADANiyvQenQQw+Nhx56KAYPHhw33nhjtG3bNkaMGBF9+vTJ9rn66qtj9erVMWDAgFi2bFl06tQpJk6cGEVFRXmsHAAA2JZlkiRJ8l3E12nFihXRrFmzWL58uc8rAbBVOuTf7853CQBb1Jybz8l3CbXalGyQ188oAQAAbI0EJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIKVevgvY3h3y73fnuwSALWrOzefkuwQA+MrMKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACk5DUolZeXRyaTydlKSkqyx5MkifLy8mjdunUUFhZGt27d4uWXX85jxQAAwPYg7zNK++23XyxZsiS7vfTSS9ljw4YNi+HDh8fIkSNj1qxZUVJSEt27d4+VK1fmsWIAAGBbl/egVK9evSgpKcluLVq0iIjPZpNGjBgRQ4YMiV69esX+++8f48aNi48//jjGjx+f56oBAIBtWd6D0htvvBGtW7eOtm3bxhlnnBFvv/12RETMnz8/Kisro0ePHtm+BQUF0bVr15gxY8YGx6uqqooVK1bkbAAAAJsir0GpU6dOcffdd8eTTz4Zo0ePjsrKyujSpUt88MEHUVlZGRERxcXFOecUFxdnj9Vm6NCh0axZs+xWWlr6td4DAACw7clrUOrZs2f86Ec/ivbt28cxxxwTjz32WEREjBs3Ltsnk8nknJMkSY22zxs8eHAsX748uy1evPjrKR4AANhm5f3Vu89r3LhxtG/fPt54443s6nfp2aOlS5fWmGX6vIKCgmjatGnOBgAAsCm2qqBUVVUVr776arRq1Sratm0bJSUlMWnSpOzxNWvWxLRp06JLly55rBIAANjW1cvnxa+66qo48cQTY7fddoulS5fGTTfdFCtWrIi+fftGJpOJgQMHRkVFRZSVlUVZWVlUVFREo0aNonfv3vksGwAA2MblNSj94x//iDPPPDPef//9aNGiRXzve9+LZ599Ntq0aRMREVdffXWsXr06BgwYEMuWLYtOnTrFxIkTo6ioKJ9lAwAA27i8BqV77733C49nMpkoLy+P8vLyb6YgAACA2Mo+owQAALA1EJQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABI2WqC0tChQyOTycTAgQOzbUmSRHl5ebRu3ToKCwujW7du8fLLL+evSAAAYLuwVQSlWbNmxZ133hkdOnTIaR82bFgMHz48Ro4cGbNmzYqSkpLo3r17rFy5Mk+VAgAA24O8B6V//etf0adPnxg9enTsuOOO2fYkSWLEiBExZMiQ6NWrV+y///4xbty4+Pjjj2P8+PF5rBgAANjW5T0oXXzxxXH88cfHMccck9M+f/78qKysjB49emTbCgoKomvXrjFjxowNjldVVRUrVqzI2QAAADZFvXxe/N57743nn38+Zs2aVeNYZWVlREQUFxfntBcXF8fChQs3OObQoUPjhhtu2LKFAgAA25W8zSgtXrw4Lr/88rjnnnuiYcOGG+yXyWRy9pMkqdH2eYMHD47ly5dnt8WLF2+xmgEAgO1D3maU5syZE0uXLo1DDjkk27Zu3bp4+umnY+TIkTFv3ryI+GxmqVWrVtk+S5curTHL9HkFBQVRUFDw9RUOAABs8/I2o3T00UfHSy+9FHPnzs1uHTt2jD59+sTcuXNjjz32iJKSkpg0aVL2nDVr1sS0adOiS5cu+SobAADYDuRtRqmoqCj233//nLbGjRtH8+bNs+0DBw6MioqKKCsri7KysqioqIhGjRpF796981EyAACwncjrYg5f5uqrr47Vq1fHgAEDYtmyZdGpU6eYOHFiFBUV5bs0AABgG7ZVBaWpU6fm7GcymSgvL4/y8vK81AMAAGyf8v57lAAAALY2ghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAymYFpaOOOio++uijGu0rVqyIo4466qvWBAAAkFebFZSmTp0aa9asqdH+ySefxPTp079yUQAAAPlUb1M6v/jii9k/v/LKK1FZWZndX7duXTzxxBOxyy67bLnqAAAA8mCTgtKBBx4YmUwmMplMra/YFRYWxm9+85stVhwAAEA+bFJQmj9/fiRJEnvssUfMnDkzWrRokT3WoEGDaNmyZdStW3eLFwkAAPBN2qSg1KZNm4iIWL9+/ddSDAAAwNZgk4LS573++usxderUWLp0aY3g9B//8R9fuTAAAIB82aygNHr06Ljoooti5513jpKSkshkMtljmUxGUAIAAL7VNiso3XTTTfGzn/0srrnmmi1dDwAAQN5t1u9RWrZsWfz4xz/e0rUAAABsFTYrKP34xz+OiRMnbulaAAAAtgqb9erdnnvuGdddd108++yz0b59+6hfv37O8csuu2yLFAcAAJAPmxWU7rzzzmjSpElMmzYtpk2blnMsk8kISgAAwLfaZgWl+fPnb+k6AAAAthqb9RklAACAbdlmzSide+65X3j8rrvu2qxiAAAAtgabFZSWLVuWs//pp5/G//7v/8ZHH30URx111BYpDAAAIF82Kyg99NBDNdrWr18fAwYMiD322OMrFwUAAJBPW+wzSnXq1Ikrrrgibrnlli01JAAAQF5s0cUc3nrrrVi7du2WHBIAAOAbt1mv3g0aNChnP0mSWLJkSTz22GPRt2/fLVIYAABAvmxWUHrhhRdy9uvUqRMtWrSIX/3qV1+6Ih4AAMDWbrOC0pQpU7Z0HQAAAFuNzQpK1d57772YN29eZDKZ2GuvvaJFixZbqi4AAIC82azFHFatWhXnnntutGrVKo444og4/PDDo3Xr1tG/f//4+OOPt3SNAAAA36jNCkqDBg2KadOmxV/+8pf46KOP4qOPPopHHnkkpk2bFldeeeWWrhEAAOAbtVmv3j3wwAPx5z//Obp165ZtO+6446KwsDBOO+20GDVq1JaqDwAA4Bu3WTNKH3/8cRQXF9dob9my5Sa9ejdq1Kjo0KFDNG3aNJo2bRqdO3eOxx9/PHs8SZIoLy+P1q1bR2FhYXTr1i1efvnlzSkZAABgo21WUOrcuXNcf/318cknn2TbVq9eHTfccEN07tx5o8fZdddd4+c//3nMnj07Zs+eHUcddVT88Ic/zIahYcOGxfDhw2PkyJExa9asKCkpie7du8fKlSs3p2wAAICNslmv3o0YMSJ69uwZu+66axxwwAGRyWRi7ty5UVBQEBMnTtzocU488cSc/Z/97GcxatSoePbZZ2PfffeNESNGxJAhQ6JXr14RETFu3LgoLi6O8ePHxwUXXLA5pQMAAHypzQpK7du3jzfeeCPuueeeeO211yJJkjjjjDOiT58+UVhYuFmFrFu3Lu6///5YtWpVdO7cOebPnx+VlZXRo0ePbJ+CgoLo2rVrzJgxY4NBqaqqKqqqqrL7K1as2Kx6AACA7ddmBaWhQ4dGcXFxnH/++Tntd911V7z33ntxzTXXbPRYL730UnTu3Dk++eSTaNKkSTz00EOx7777xowZMyIianwWqri4OBYuXPiFtd1www2bcDcAAAC5NuszSr/97W+jXbt2Ndr322+/uOOOOzZprL333jvmzp0bzz77bFx00UXRt2/feOWVV7LHM5lMTv8kSWq0fd7gwYNj+fLl2W3x4sWbVA8AAMBmzShVVlZGq1atarS3aNEilixZskljNWjQIPbcc8+IiOjYsWPMmjUrbr311uysVPpaS5curXXFvWoFBQVRUFCwSTUAAAB83mbNKJWWlsbf/va3Gu1/+9vfonXr1l+poCRJoqqqKtq2bRslJSUxadKk7LE1a9bEtGnTokuXLl/pGgAAAF9ks2aUzjvvvBg4cGB8+umncdRRR0VExFNPPRVXX311XHnllRs9zrXXXhs9e/aM0tLSWLlyZdx7770xderUeOKJJyKTycTAgQOjoqIiysrKoqysLCoqKqJRo0bRu3fvzSkbAABgo2xWULr66qvjww8/jAEDBsSaNWsiIqJhw4ZxzTXXxODBgzd6nHfffTfOPvvsWLJkSTRr1iw6dOgQTzzxRHTv3j17ndWrV8eAAQNi2bJl0alTp5g4cWIUFRVtTtkAAAAbJZMkSbK5J//rX/+KV199NQoLC6OsrGyr/GzQihUrolmzZrF8+fJo2rRpvsup4ZB/vzvfJQBsUXNuPiffJXzr+FkAbGu21p8Fm5INNmtGqVqTJk3i0EMP/SpDAAAAbHU2azEHAACAbZmgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQEpeg9LQoUPj0EMPjaKiomjZsmWcfPLJMW/evJw+SZJEeXl5tG7dOgoLC6Nbt27x8ssv56liAABge5DXoDRt2rS4+OKL49lnn41JkybF2rVro0ePHrFq1apsn2HDhsXw4cNj5MiRMWvWrCgpKYnu3bvHypUr81g5AACwLauXz4s/8cQTOftjxoyJli1bxpw5c+KII46IJElixIgRMWTIkOjVq1dERIwbNy6Ki4tj/PjxccEFF9QYs6qqKqqqqrL7K1as+HpvAgAA2OZsVZ9RWr58eURE7LTTThERMX/+/KisrIwePXpk+xQUFETXrl1jxowZtY4xdOjQaNasWXYrLS39+gsHAAC2KVtNUEqSJAYNGhTf//73Y//994+IiMrKyoiIKC4uzulbXFycPZY2ePDgWL58eXZbvHjx11s4AACwzcnrq3efd8kll8SLL74Y//M//1PjWCaTydlPkqRGW7WCgoIoKCj4WmoEAAC2D1vFjNKll14ajz76aEyZMiV23XXXbHtJSUlERI3Zo6VLl9aYZQIAANhS8hqUkiSJSy65JB588MGYPHlytG3bNud427Zto6SkJCZNmpRtW7NmTUybNi26dOnyTZcLAABsJ/L66t3FF18c48ePj0ceeSSKioqyM0fNmjWLwsLCyGQyMXDgwKioqIiysrIoKyuLioqKaNSoUfTu3TufpQMAANuwvAalUaNGRUREt27dctrHjBkT/fr1i4iIq6++OlavXh0DBgyIZcuWRadOnWLixIlRVFT0DVcLAABsL/IalJIk+dI+mUwmysvLo7y8/OsvCAAAILaSxRwAAAC2JoISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKYISAABAiqAEAACQIigBAACkCEoAAAApghIAAECKoAQAAJAiKAEAAKQISgAAACmCEgAAQIqgBAAAkCIoAQAApAhKAAAAKXkNSk8//XSceOKJ0bp168hkMvHwww/nHE+SJMrLy6N169ZRWFgY3bp1i5dffjk/xQIAANuNvAalVatWxQEHHBAjR46s9fiwYcNi+PDhMXLkyJg1a1aUlJRE9+7dY+XKld9wpQAAwPakXj4v3rNnz+jZs2etx5IkiREjRsSQIUOiV69eERExbty4KC4ujvHjx8cFF1zwTZYKAABsR7bazyjNnz8/Kisro0ePHtm2goKC6Nq1a8yYMWOD51VVVcWKFStyNgAAgE2x1QalysrKiIgoLi7OaS8uLs4eq83QoUOjWbNm2a20tPRrrRMAANj2bLVBqVomk8nZT5KkRtvnDR48OJYvX57dFi9e/HWXCAAAbGPy+hmlL1JSUhIRn80stWrVKtu+dOnSGrNMn1dQUBAFBQVfe30AAMC2a6udUWrbtm2UlJTEpEmTsm1r1qyJadOmRZcuXfJYGQAAsK3L64zSv/71r3jzzTez+/Pnz4+5c+fGTjvtFLvttlsMHDgwKioqoqysLMrKyqKioiIaNWoUvXv3zmPVAADAti6vQWn27Nlx5JFHZvcHDRoUERF9+/aNsWPHxtVXXx2rV6+OAQMGxLJly6JTp04xceLEKCoqylfJAADAdiCvQalbt26RJMkGj2cymSgvL4/y8vJvrigAAGC7t9V+RgkAACBfBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSBCUAAIAUQQkAACBFUAIAAEgRlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABSvhVB6fbbb4+2bdtGw4YN45BDDonp06fnuyQAAGAbttUHpfvuuy8GDhwYQ4YMiRdeeCEOP/zw6NmzZyxatCjfpQEAANuorT4oDR8+PPr37x/nnXde7LPPPjFixIgoLS2NUaNG5bs0AABgG1Uv3wV8kTVr1sScOXPiJz/5SU57jx49YsaMGbWeU1VVFVVVVdn95cuXR0TEihUrvr5Cv4J1VavzXQLAFrW1/v92a+ZnAbCt2Vp/FlTXlSTJl/bdqoPS+++/H+vWrYvi4uKc9uLi4qisrKz1nKFDh8YNN9xQo720tPRrqRGAXM1+c2G+SwAgz7b2nwUrV66MZs2afWGfrTooVctkMjn7SZLUaKs2ePDgGDRoUHZ//fr18eGHH0bz5s03eA5s61asWBGlpaWxePHiaNq0ab7LASAP/CyAz3LEypUro3Xr1l/ad6sOSjvvvHPUrVu3xuzR0qVLa8wyVSsoKIiCgoKcth122OHrKhG+VZo2beqHI8B2zs8CtndfNpNUbatezKFBgwZxyCGHxKRJk3LaJ02aFF26dMlTVQAAwLZuq55RiogYNGhQnH322dGxY8fo3Llz3HnnnbFo0aK48MKt+71HAADg22urD0qnn356fPDBB3HjjTfGkiVLYv/9948JEyZEmzZt8l0afGsUFBTE9ddfX+O1VAC2H34WwKbJJBuzNh4AAMB2ZKv+jBIAAEA+CEoAAAApghIAAECKoAQAAJAiKME27vbbb4+2bdtGw4YN45BDDonp06fnuyQAvkFPP/10nHjiidG6devIZDLx8MMP57sk+FYQlGAbdt9998XAgQNjyJAh8cILL8Thhx8ePXv2jEWLFuW7NAC+IatWrYoDDjggRo4cme9S4FvF8uCwDevUqVMcfPDBMWrUqGzbPvvsEyeffHIMHTo0j5UBkA+ZTCYeeuihOPnkk/NdCmz1zCjBNmrNmjUxZ86c6NGjR057jx49YsaMGXmqCgDg20FQgm3U+++/H+vWrYvi4uKc9uLi4qisrMxTVQAA3w6CEmzjMplMzn6SJDXaAADIJSjBNmrnnXeOunXr1pg9Wrp0aY1ZJgAAcglKsI1q0KBBHHLIITFp0qSc9kmTJkWXLl3yVBUAwLdDvXwXAHx9Bg0aFGeffXZ07NgxOnfuHHfeeWcsWrQoLrzwwnyXBsA35F//+le8+eab2f358+fH3LlzY6eddorddtstj5XB1s3y4LCNu/3222PYsGGxZMmS2H///eOWW26JI444It9lAfANmTp1ahx55JE12vv27Rtjx4795guCbwlBCQAAIMVnlAAAAFIEJQAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQA2GIWLFgQmUwm5s6dm+9SAOArEZQAtkMnnnhiHHPMMbUee+aZZyKTycTzzz//jdTSrVu3GDhw4DdyrW/K1KlTI5PJxEcffbRJ5wmaAFsPQQlgO9S/f/+YPHlyLFy4sMaxu+66Kw488MA4+OCDN2nMNWvWbKnyACDvBCWA7dAJJ5wQLVu2jLFjx+a0f/zxx3HfffdF//79Y8aMGXHEEUdEYWFhlJaWxmWXXRarVq3K9t19993jpptuin79+kWzZs3i/PPPr/Var7zyShx33HHRpEmTKC4ujrPPPjvef//9iIjo169fTJs2LW699dbIZDKRyWRiwYIF0a9fv+z+57epU6dGREQmk4mHH3445zo77LBD9n6qZ2YefPDBOPLII6NRo0ZxwAEHxDPPPJNzzujRo6O0tDQaNWoUp5xySgwfPjx22GGH7PG///3vceSRR0ZRUVE0bdo0DjnkkJg9e3ZERCxcuDBOPPHE2HHHHaNx48ax3377xYQJE2LBggVx5JFHRkTEjjvuGJlMJvr16xcREU888UR8//vfjx122CGaN28eJ5xwQrz11lvZ67Vt2zYiIg466KDIZDLRrVu3iKh91u3kk0/OjhsRcfvtt0dZWVk0bNgwiouL49RTT6316wHAxhGUALZD9erVi3POOSfGjh0bSZJk2++///5Ys2ZNHHDAAXHsscdGr1694sUXX4z77rsv/ud//icuueSSnHFuvvnm2H///WPOnDlx3XXX1bjOkiVLomvXrnHggQfG7Nmz44knnoh33303TjvttIiIuPXWW6Nz585x/vnnx5IlS2LJkiVRWloat956a3Z/yZIlcfnll0fLli2jXbt2m3SfQ4YMiauuuirmzp0be+21V5x55pmxdu3aiIj429/+FhdeeGFcfvnlMXfu3OjevXv87Gc/yzm/T58+seuuu8asWbNizpw58ZOf/CTq168fEREXX3xxVFVVxdNPPx0vvfRS/OIXv4gmTZpEaWlpPPDAAxERMW/evFiyZEnceuutERGxatWqGDRoUMyaNSueeuqpqFOnTpxyyimxfv36iIiYOXNmRET893//dyxZsiQefPDBjbrP2bNnx2WXXRY33nhjzJs3L5544ok44ogjNulZAZCSALBdevXVV5OISCZPnpxtO+KII5IzzzwzOfvss5P/9//+X07/6dOnJ3Xq1ElWr16dJEmStGnTJjn55JNz+syfPz+JiOSFF15IkiRJrrvuuqRHjx45fRYvXpxERDJv3rwkSZKka9euyeWXX77BOh944IGkoKAgmT59erYtIpKHHnoop1+zZs2SMWPG5NTxu9/9Lnv85ZdfTiIiefXVV5MkSZLTTz89Of7443PG6NOnT9KsWbPsflFRUTJ27Nha62rfvn1SXl5e67EpU6YkEZEsW7Zsg/eVJEmydOnSJCKSl156Kafu6udXrbZn9MMf/jDp27dvkiSfPaOmTZsmK1as+MLrAbDxzCgBbKfatWsXXbp0ibvuuisiIt56662YPn16nHvuuTFnzpwYO3ZsNGnSJLsde+yxsX79+pg/f352jI4dO37hNebMmRNTpkzJGad6Vujzr5xtyAsvvBDnnHNO3HbbbfH9739/k++xQ4cO2T+3atUqIiKWLl0aEZ/N9nz3u9/N6Z/eHzRoUJx33nlxzDHHxM9//vOcmi+77LK46aab4rDDDovrr78+XnzxxS+t56233orevXvHHnvsEU2bNs2+ardo0aJNvrfP6969e7Rp0yb22GOPOPvss+MPf/hDfPzxx19pTIDtnaAEsB3r379/PPDAA7FixYoYM2ZMtGnTJo4++uhYv359XHDBBTF37tzs9ve//z3eeOON+M53vpM9v3Hjxl84/vr16+PEE0/MGWfu3LnxxhtvfOmrYZWVlXHSSSdF//79o3///jnHMplMziuDERGffvppjTGqX5OrPqe6poiIJEmybdXSY5aXl8fLL78cxx9/fEyePDn23XffeOihhyIi4rzzzou33347zj777HjppZeiY8eO8Zvf/OYL7+nEE0+MDz74IEaPHh3PPfdcPPfccxHx5Qth1KlT5wvvt6ioKJ5//vn44x//GK1atYr/+I//iAMOOGCTV90D4P8ISgDbsdNOOy3q1q0b48ePj3HjxsW//du/RSaTiYMPPjhefvnl2HPPPWtsDRo02Ojxq8fZfffda4xTHbIaNGgQ69atyznvk08+iR/+8IfRrl27GD58eI1xW7RoEUuWLMnuv/HGG5s8g9KuXbvsZ4KqVS/U8Hl77bVXXHHFFTFx4sTo1atXjBkzJnustLQ0LrzwwnjwwQfjyiuvjNGjR2fvKSJy7uuDDz6IV199NX7605/G0UcfHfvss08sW7Ys51q1nVfb/a5bty7+93//N6dPvXr14phjjolhw4bFiy++GAsWLIjJkydv9PMAIJegBLAda9KkSZx++ulx7bXXxjvvvJNdRe2aa66JZ555Ji6++OLsDNCjjz4al1566SaNf/HFF8eHH34YZ555ZsycOTPefvvtmDhxYpx77rnZMLD77rvHc889FwsWLIj3338/O5u1ePHi+PWvfx3vvfdeVFZWRmVlZXbm5aijjoqRI0fG888/H7Nnz44LL7wwZ/ZoY1x66aUxYcKEGD58eLzxxhvx29/+Nh5//PHsLNPq1avjkksuialTp8bChQvjb3/7W8yaNSv22WefiIgYOHBgPPnkkzF//vx4/vnnY/Lkydljbdq0iUwmE3/961/jvffei3/961+x4447RvPmzePOO++MN998MyZPnhyDBg3Kqally5ZRWFiYXfRi+fLl2ft97LHH4rHHHovXXnstBgwYkDNb9Ne//jV+/etfx9y5c2PhwoVx9913x/r162PvvffepGcCwOfk9yNSAOTbjBkzkoiosejCzJkzk+7duydNmjRJGjdunHTo0CH52c9+lj3epk2b5JZbbsk5p7bFCF5//fXklFNOSXbYYYeksLAwadeuXTJw4MBk/fr1SZIkybx585Lvfe97SWFhYRIRyfz585M2bdokEVFjmzJlSpIkSfLPf/4z6dGjR9K4ceOkrKwsmTBhQq2LOXy+jmXLluWMkSRJcueddya77LJLUlhYmJx88snJTTfdlJSUlCRJkiRVVVXJGWeckZSWliYNGjRIWrdunVxyySXZxSwuueSS5Dvf+U5SUFCQtGjRIjn77LOT999/Pzv2jTfemJSUlCSZTCa76MKkSZOSffbZJykoKEg6dOiQTJ06tcbCFKNHj05KS0uTOnXqJF27dk2SJEnWrFmTXHTRRclOO+2UtGzZMhk6dGjOYg7Tp09Punbtmuy4445JYWFh0qFDh+S+++77si89AF8gkySpl54BYDt1/vnnx2uvvRbTp0/PdykA5Fm9fBcAAPnyy1/+Mrp37x6NGzeOxx9/PMaNGxe33357vssCYCtgRgmA7dZpp50WU6dOjZUrV8Yee+wRl156aVx44YX5LguArYCgBAAAkGLVOwAAgBRBCQAAIEVQAgAASBGUAAAAUgQlAACAFEEJAAAgRVACAABIEZQAAABS/j9o447CXc1VWwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining models with parallel processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:   0%|          | 0/700 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:   7%|▋         | 50/700 [00:23<05:08,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  14%|█▍        | 100/700 [00:34<03:13,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  21%|██▏       | 150/700 [00:48<02:44,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  29%|██▊       | 200/700 [01:10<03:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  36%|███▌      | 250/700 [01:24<02:29,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: LightGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  43%|████▎     | 300/700 [02:04<03:14,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  50%|█████     | 350/700 [02:16<02:22,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: k-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  57%|█████▋    | 400/700 [02:34<01:57,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: MLP Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  64%|██████▍   | 450/700 [02:51<01:33,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: Gaussian Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  71%|███████▏  | 500/700 [03:02<01:05,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: Linear Discriminant Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  79%|███████▊  | 550/700 [03:12<00:43,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: Quadratic Discriminant Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  86%|████████▌ | 600/700 [03:24<00:27,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: Bagging Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  93%|█████████▎| 650/700 [03:37<00:13,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating model: Extra Trees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress: 100%|██████████| 700/700 [03:49<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary:\n",
      "                              Model   Train Accuracy    Test Accuracy         F1-Score           Recall          ROC-AUC\n",
      "0               Logistic Regression  0.9998 ± 0.0005  0.8834 ± 0.0689  0.8856 ± 0.0738  0.8635 ± 0.1182  0.9562 ± 0.0438\n",
      "8                    MLP Classifier  1.0000 ± 0.0000  0.8903 ± 0.0629  0.8958 ± 0.0663  0.8932 ± 0.1005  0.9554 ± 0.0402\n",
      "4                           XGBoost  1.0000 ± 0.0000  0.8609 ± 0.0555  0.8707 ± 0.0522  0.8758 ± 0.0936  0.9489 ± 0.0341\n",
      "13                      Extra Trees  1.0000 ± 0.0000  0.8426 ± 0.0768  0.8546 ± 0.0759  0.8677 ± 0.1069  0.9450 ± 0.0450\n",
      "5                          LightGBM  1.0000 ± 0.0000  0.8708 ± 0.0677  0.8791 ± 0.0674  0.8806 ± 0.0955  0.9450 ± 0.0405\n",
      "6                               SVC  0.9995 ± 0.0009  0.8679 ± 0.0662  0.8790 ± 0.0605  0.8883 ± 0.0830  0.9441 ± 0.0387\n",
      "3                 Gradient Boosting  1.0000 ± 0.0000  0.8582 ± 0.0651  0.8687 ± 0.0617  0.8721 ± 0.0886  0.9429 ± 0.0350\n",
      "10     Linear Discriminant Analysis  0.9975 ± 0.0017  0.8637 ± 0.0631  0.8638 ± 0.0716  0.8264 ± 0.1204  0.9382 ± 0.0484\n",
      "2                     Random Forest  1.0000 ± 0.0000  0.8354 ± 0.0654  0.8537 ± 0.0563  0.8858 ± 0.0791  0.9348 ± 0.0451\n",
      "12               Bagging Classifier  0.9982 ± 0.0013  0.8255 ± 0.0836  0.8416 ± 0.0773  0.8637 ± 0.1093  0.9017 ± 0.0588\n",
      "9              Gaussian Naive Bayes  0.9410 ± 0.0143  0.8301 ± 0.0760  0.8525 ± 0.0618  0.8990 ± 0.0754  0.8996 ± 0.0737\n",
      "7               k-Nearest Neighbors  0.9825 ± 0.0052  0.8012 ± 0.0950  0.7997 ± 0.1044  0.7562 ± 0.1342  0.8613 ± 0.0767\n",
      "1                     Decision Tree  1.0000 ± 0.0000  0.7960 ± 0.0728  0.8171 ± 0.0655  0.8481 ± 0.0942  0.7916 ± 0.0733\n",
      "11  Quadratic Discriminant Analysis  1.0000 ± 0.0000  0.6255 ± 0.0895  0.7353 ± 0.0568  0.9555 ± 0.0579  0.6524 ± 0.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "\n",
    "pd.set_option(\"display.width\", 200)\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n",
    "\n",
    "\n",
    "#############################################\n",
    "# HELPER FUNCTIONS FOR VISUALIZATION\n",
    "#############################################\n",
    "\n",
    "def plot_distribution_comparison(X_original, X_augmented, cols_to_plot=None, n_cols=3, figsize=(18, 15)):\n",
    "    \"\"\"\n",
    "    Plot distribution comparison between original and augmented data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_original : DataFrame\n",
    "        Original feature dataframe\n",
    "    X_augmented : DataFrame\n",
    "        Augmented feature dataframe\n",
    "    cols_to_plot : list, optional\n",
    "        List of columns to plot. If None, all columns will be plotted.\n",
    "    n_cols : int, optional\n",
    "        Number of columns in the subplot grid\n",
    "    figsize : tuple, optional\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    if cols_to_plot is None:\n",
    "        cols_to_plot = X_original.columns\n",
    "\n",
    "    n_rows = (len(cols_to_plot) + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(cols_to_plot):\n",
    "        ax = axes[i]\n",
    "        if col == \"Geschlecht_weiblich\":\n",
    "            # For categorical features like gender, use countplot\n",
    "            counts_orig = X_original[col].value_counts().reset_index()\n",
    "            counts_orig.columns = [col, 'count']\n",
    "            counts_orig['Source'] = 'Original'\n",
    "\n",
    "            counts_aug = X_augmented[col].value_counts().reset_index()\n",
    "            counts_aug.columns = [col, 'count']\n",
    "            counts_aug['Source'] = 'Augmented'\n",
    "\n",
    "            counts = pd.concat([counts_orig, counts_aug], ignore_index=True)\n",
    "\n",
    "            sns.barplot(x=col, y='count', hue='Source', data=counts, ax=ax)\n",
    "            ax.set_xlabel('Gender (Female=1)')\n",
    "        else:\n",
    "            # For continuous features, use KDE plots\n",
    "            if X_original[col].nunique() > 1:  # Nur plotten, wenn mehr als 1 Wert vorhanden\n",
    "                sns.kdeplot(X_original[col], label='Original', ax=ax, color='blue', fill=True)\n",
    "            if X_augmented[col].nunique() > 1:  # Nur plotten, wenn mehr als 1 Wert vorhanden\n",
    "                sns.kdeplot(X_augmented[col], label='Augmented', ax=ax, color='red', fill=True)\n",
    "\n",
    "        ax.set_title(f'Distribution of {col}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for i in range(len(cols_to_plot), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "#############################################\n",
    "# AUGMENTATIONSMETHODEN\n",
    "#############################################\n",
    "\n",
    "### 1. Cluster-basierte Augmentation (ohne zusätzliches Rauschen)\n",
    "def perform_clustering(X_sub, max_clusters=4):\n",
    "    # Wähle alle numerischen Spalten außer den Gruppierungsvariablen\n",
    "    cols = [col for col in X_sub.columns if col not in [\"Verletzungsstatus\", \"Geschlecht_weiblich\"]]\n",
    "    X_num = X_sub[cols]\n",
    "    # Berechne die (absoluten) Korrelationen und transformiere in Distanzen\n",
    "    corr = X_num.corr().abs()\n",
    "    dist = np.clip(1 - corr, a_min=0, a_max=None)\n",
    "    dists = squareform(dist.values)\n",
    "    Z = linkage(dists, method='ward')\n",
    "    cluster_labels = fcluster(Z, max_clusters, criterion='maxclust')\n",
    "    clusters = {}\n",
    "    for col, label in zip(cols, cluster_labels):\n",
    "        clusters.setdefault(label, []).append(col)\n",
    "    return clusters\n",
    "\n",
    "def augment_subgroup(X_sub, clusters, p_augment=0.7):\n",
    "    # Für jede Cluster-Gruppe: berechne Mittelwert und Kovarianzmatrix\n",
    "    augmented_rows = []\n",
    "    cluster_params = {}\n",
    "    for cl_id, cols in clusters.items():\n",
    "        cluster_data = X_sub[cols]\n",
    "        mu = cluster_data.mean().values\n",
    "        if len(cols) == 1:\n",
    "            cov = np.cov(cluster_data.values.flatten(), ddof=0)\n",
    "            cov = np.atleast_2d(cov)\n",
    "        else:\n",
    "            cov = np.cov(cluster_data.values, rowvar=False)\n",
    "        cluster_params[cl_id] = (mu, cov, cols)\n",
    "    # Für jede Zeile werden für jede Cluster-Gruppe (stochastisch) neue Werte gezogen\n",
    "    for idx, row in X_sub.iterrows():\n",
    "        new_row = row.copy()\n",
    "        for cl_id, (mu, cov, cols) in cluster_params.items():\n",
    "            if np.random.rand() < p_augment:\n",
    "                new_values = np.random.multivariate_normal(mu, cov)\n",
    "                for col, val in zip(cols, new_values):\n",
    "                    new_row[col] = val\n",
    "        augmented_rows.append(new_row)\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    for col in [\"Geschlecht_weiblich\", \"Verletzungsstatus\"]:\n",
    "        if col in augmented_df.columns:\n",
    "            augmented_df[col] = augmented_df[col].astype(int)\n",
    "    return augmented_df\n",
    "\n",
    "# Parallel processing for augmenting one group\n",
    "def process_group_cluster(group_df, num_new_samples, max_clusters, p_augment):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    clusters = perform_clustering(group_df, max_clusters=max_clusters)\n",
    "    aug_list = []\n",
    "    for _ in range(num_new_samples):\n",
    "        aug = augment_subgroup(group_df, clusters, p_augment=p_augment)\n",
    "        aug_list.append(aug)\n",
    "    aug_group = pd.concat(aug_list, axis=0)\n",
    "    return aug_group\n",
    "\n",
    "def augment_training_data_cluster(X_train, y_train, num_new_samples=1, max_clusters=4, p_augment=0.7, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Augmentiert die Trainingsdaten nach dem Cluster-Ansatz mit paralleler Verarbeitung.\n",
    "    num_new_samples gibt an, wie viele augmentierte Samples pro Originalzeile generiert werden.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    \n",
    "    # Prepare groups for parallel processing\n",
    "    groups = []\n",
    "    for key, group_df in df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        groups.append(group_df)\n",
    "    \n",
    "    # Process groups in parallel\n",
    "    augmented_groups = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_group_cluster)(\n",
    "            group_df, num_new_samples, max_clusters, p_augment\n",
    "        ) for group_df in groups\n",
    "    )\n",
    "        \n",
    "    augmented_df = pd.concat(augmented_groups, axis=0).reset_index(drop=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "\n",
    "### 2. Cluster-basierte Augmentation mit Rauschen\n",
    "def add_noise_to_data(df, noise_factor=0.1):\n",
    "    df_noisy = df.copy()\n",
    "    numeric_cols = [col for col in df_noisy.select_dtypes(include=['float64', 'int64']).columns \n",
    "                    if col not in [\"Geschlecht_weiblich\", \"Verletzungsstatus\"]]\n",
    "    for col in numeric_cols:\n",
    "        std = df_noisy[col].std()\n",
    "        noise = np.random.normal(0, std * noise_factor, size=df_noisy.shape[0])\n",
    "        df_noisy[col] += noise\n",
    "    return df_noisy\n",
    "\n",
    "def add_noise_to_group(df_group, noise_factor=0.1):\n",
    "    # Hier wird einfach die oben definierte Funktion genutzt\n",
    "    return add_noise_to_data(df_group, noise_factor=noise_factor)\n",
    "\n",
    "# Parallel processing for cluster with noise\n",
    "def process_group_cluster_noise(group_df, num_new_samples, max_clusters, p_augment, noise_factor):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    clusters = perform_clustering(group_df, max_clusters=max_clusters)\n",
    "    aug_list = []\n",
    "    for _ in range(num_new_samples):\n",
    "        aug = augment_subgroup(group_df, clusters, p_augment=p_augment)\n",
    "        aug_list.append(aug)\n",
    "    aug_group = pd.concat(aug_list, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Wende Rauschen an: teile die augmentierten Daten in zwei Hälften\n",
    "    n = len(aug_group)\n",
    "    half = n // 2\n",
    "    global_noise = add_noise_to_data(aug_group.copy(), noise_factor=noise_factor)\n",
    "    group_noise = add_noise_to_group(aug_group.copy(), noise_factor=noise_factor)\n",
    "    # Nehme jeweils die erste Hälfte (bei ungerader Anzahl wird der Rest ignoriert)\n",
    "    aug_noisy = pd.concat([global_noise.iloc[:half], group_noise.iloc[:half]], axis=0)\n",
    "    return aug_noisy\n",
    "\n",
    "def augment_training_data_cluster_noise(X_train, y_train, num_new_samples=1, max_clusters=4, p_augment=0.7, noise_factor=0.1, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Wie augment_training_data_cluster, jedoch wird auf den erzeugten augmentierten Samples\n",
    "    zusätzlich Rauschen angehängt – zur Hälfte global und zur Hälfte gruppenspezifisch.\n",
    "    Parallele Verarbeitung mit n_jobs.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    \n",
    "    # Prepare groups for parallel processing\n",
    "    groups = []\n",
    "    for key, group_df in df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        groups.append(group_df)\n",
    "    \n",
    "    # Process groups in parallel\n",
    "    augmented_groups = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_group_cluster_noise)(\n",
    "            group_df, num_new_samples, max_clusters, p_augment, noise_factor\n",
    "        ) for group_df in groups\n",
    "    )\n",
    "        \n",
    "    augmented_df = pd.concat(augmented_groups, axis=0).reset_index(drop=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "\n",
    "### 3. Augmentation über Mittelwert-Bildung (Gruppenmittelwerte)\n",
    "\n",
    "# Function to process a single group with mean-based augmentation\n",
    "def process_group_means(group_df, group_new_samples):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    new_group_samples = []\n",
    "    for _ in range(group_new_samples):\n",
    "        sample_indices = np.random.choice(len(group_df), 2, replace=False)\n",
    "        sample1 = group_df.iloc[sample_indices[0]]\n",
    "        sample2 = group_df.iloc[sample_indices[1]]\n",
    "        mean_sample = sample1.copy()\n",
    "        numeric_cols = [col for col in group_df.columns if col != \"Geschlecht_weiblich\"]\n",
    "        for col in numeric_cols:\n",
    "            mean_sample[col] = (sample1[col] + sample2[col]) / 2\n",
    "        new_group_samples.append(mean_sample)\n",
    "    if new_group_samples:\n",
    "        return pd.DataFrame(new_group_samples)\n",
    "    return None\n",
    "\n",
    "def augment_data_by_group_means(X_train, y_train, augmentation_factor=2, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Augmentiert Daten basierend auf Gruppenmittelwerten mit paralleler Verarbeitung.\n",
    "    Die Augmentation erfolgt innerhalb der Gruppen, die durch 'Verletzungsstatus'\n",
    "    und 'Geschlecht_weiblich' definiert sind.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    groups = df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"])\n",
    "    total_original_samples = len(df_train)\n",
    "    total_new_samples = int(total_original_samples * (augmentation_factor - 1))\n",
    "    group_sizes = groups.size()\n",
    "    group_proportions = group_sizes / total_original_samples\n",
    "    \n",
    "    # Prepare tasks for parallel processing\n",
    "    tasks = []\n",
    "    for (injury_status, is_female), group_df in groups:\n",
    "        group_new_samples = int(total_new_samples * group_proportions[(injury_status, is_female)])\n",
    "        tasks.append((group_df, group_new_samples))\n",
    "    \n",
    "    # Process groups in parallel\n",
    "    augmented_groups = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_group_means)(group_df, group_new_samples) \n",
    "        for group_df, group_new_samples in tasks\n",
    "    )\n",
    "    \n",
    "    # Filter out None results\n",
    "    augmented_groups = [group for group in augmented_groups if group is not None]\n",
    "    \n",
    "    augmented_df = pd.concat([df_train] + augmented_groups, ignore_index=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "\n",
    "def augment_training_data_combined(X_train, y_train, target_size=1000, visualize=False, max_plots=10, verbose=True, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Augment training data with parallel processing\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    N = len(X_train)\n",
    "    additional_needed = max(target_size - N, 0)\n",
    "    per_method_needed = additional_needed // 3\n",
    "\n",
    "    num_new_samples = max(per_method_needed // N, 1)\n",
    "    augmentation_factor = 1 + (per_method_needed / N)\n",
    "\n",
    "    # Remove the print statements if verbose is False\n",
    "    if verbose:\n",
    "        print(f\"Starting combined augmentation to reach target size: {target_size}\")\n",
    "        print(f\"Original dataset size: {N}\")\n",
    "        print(f\"Samples needed per method: {per_method_needed}\")\n",
    "    \n",
    "    # Parallel execution of all three augmentation methods\n",
    "    results = Parallel(n_jobs=min(3, n_jobs))(\n",
    "        delayed(func)(X_train, y_train, **params) for func, params in [\n",
    "            (augment_training_data_cluster, {\"num_new_samples\": num_new_samples, \"n_jobs\": n_jobs}),\n",
    "            (augment_training_data_cluster_noise, {\"num_new_samples\": num_new_samples, \"n_jobs\": n_jobs}),\n",
    "            (augment_data_by_group_means, {\"augmentation_factor\": augmentation_factor, \"n_jobs\": n_jobs})\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X_aug_cluster, y_aug_cluster = results[0]\n",
    "    X_aug_cluster_noise, y_aug_cluster_noise = results[1] \n",
    "    X_aug_group_means, y_aug_group_means = results[2]\n",
    "    \n",
    "    def subsample(X_aug, y_aug, required):\n",
    "        if len(X_aug) > required:\n",
    "            idx = np.random.choice(len(X_aug), required, replace=False)\n",
    "            return X_aug.iloc[idx].reset_index(drop=True), y_aug.iloc[idx].reset_index(drop=True)\n",
    "        else:\n",
    "            return X_aug, y_aug\n",
    "\n",
    "    X_aug_cluster, y_aug_cluster = subsample(X_aug_cluster, y_aug_cluster, per_method_needed)\n",
    "    X_aug_cluster_noise, y_aug_cluster_noise = subsample(X_aug_cluster_noise, y_aug_cluster_noise, per_method_needed)\n",
    "    X_aug_group_means, y_aug_group_means = subsample(X_aug_group_means, y_aug_group_means, per_method_needed)\n",
    "\n",
    "    X_aug_combined = pd.concat([X_aug_cluster, X_aug_cluster_noise, X_aug_group_means], axis=0).reset_index(drop=True)\n",
    "    y_aug_combined = pd.concat([y_aug_cluster, y_aug_cluster_noise, y_aug_group_means], axis=0).reset_index(drop=True)\n",
    "\n",
    "    X_total = pd.concat([X_train.reset_index(drop=True), X_aug_combined], axis=0).reset_index(drop=True)\n",
    "    y_total = pd.concat([y_train.reset_index(drop=True), y_aug_combined], axis=0).reset_index(drop=True)\n",
    "\n",
    "    if len(X_total) > target_size:\n",
    "        idx = np.random.choice(len(X_total), target_size, replace=False)\n",
    "        X_total = X_total.iloc[idx].reset_index(drop=True)\n",
    "        y_total = y_total.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Remove these print statements if verbose is False\n",
    "    if verbose:\n",
    "        print(f\"Augmentation completed. Final dataset size: {len(X_total)}\")\n",
    "        print(f\"Augmentation took {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    if visualize:\n",
    "        if verbose:\n",
    "            print(\"Visualizing distributions of original vs augmented data...\")\n",
    "        cols_to_plot = list(X_train.columns)[:max_plots]\n",
    "        plot_distribution_comparison(X_train, X_aug_combined, cols_to_plot)\n",
    "        plt.suptitle('Feature Distributions: Original vs Augmented Data', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.countplot(x=y_train)\n",
    "        plt.title('Original Target Distribution')\n",
    "        plt.xlabel('Verletzungsstatus')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.countplot(x=y_total)\n",
    "        plt.title('Augmented Target Distribution')\n",
    "        plt.xlabel('Verletzungsstatus')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return X_total, y_total\n",
    "\n",
    "\n",
    "#############################################\n",
    "# MODELLVERGLEICH (REPEATED STRATIFIED CV)\n",
    "#############################################\n",
    "\n",
    "# Function to process a single fold\n",
    "def process_fold(fold_idx, train_index, test_index, X, y, model, use_augmentation, target_size, visualize_first_fold):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    X_test_df = pd.DataFrame(X_test)\n",
    "    \n",
    "    feature_cols = [f\"F{i}\" for i in range(X_train_df.shape[1])]\n",
    "    \n",
    "    gender_col_name = None\n",
    "    gender_col_idx = None\n",
    "    \n",
    "    try:\n",
    "        if isinstance(X, pd.DataFrame) and \"Geschlecht_weiblich\" in X.columns:\n",
    "            gender_col_idx = list(X.columns).index(\"Geschlecht_weiblich\")\n",
    "            feature_cols[gender_col_idx] = \"Geschlecht_weiblich\"\n",
    "            gender_col_name = \"Geschlecht_weiblich\"\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    X_train_df.columns = feature_cols\n",
    "    X_test_df.columns = feature_cols\n",
    "\n",
    "    cols_to_scale = feature_cols\n",
    "    if gender_col_name:\n",
    "        cols_to_scale = [col for col in feature_cols if col != gender_col_name]\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    X_train_df[cols_to_scale] = scaler.fit_transform(X_train_df[cols_to_scale])\n",
    "    X_test_df[cols_to_scale] = scaler.transform(X_test_df[cols_to_scale])\n",
    "\n",
    "    if use_augmentation:\n",
    "        visualize_this_fold = visualize_first_fold and fold_idx == 0\n",
    "        X_train_aug, y_train_aug = augment_training_data_combined(\n",
    "            X_train_df, pd.Series(y_train), \n",
    "            target_size=target_size,\n",
    "            visualize=visualize_this_fold,\n",
    "            verbose=False,\n",
    "            n_jobs=-1  # Use parallel processing here too\n",
    "        )\n",
    "    else:\n",
    "        X_train_aug, y_train_aug = X_train_df, pd.Series(y_train)\n",
    "\n",
    "    model.fit(X_train_aug, y_train_aug)\n",
    "    y_train_pred = model.predict(X_train_aug)\n",
    "    y_test_pred = model.predict(X_test_df)\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train_aug, y_train_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    f1_val = f1_score(y_test, y_test_pred)\n",
    "    recall_val = recall_score(y_test, y_test_pred)\n",
    "    \n",
    "    try:\n",
    "        roc_auc_val = roc_auc_score(y_test, model.predict_proba(X_test_df)[:, 1])\n",
    "    except:\n",
    "        roc_auc_val = np.nan\n",
    "\n",
    "    return accuracy_train, accuracy_test, f1_val, recall_val, roc_auc_val\n",
    "\n",
    "\n",
    "def repeated_k_fold(model, X, y, n_splits=5, n_repeats=10, use_augmentation=False, target_size=1000, visualize_first_fold=False, progress_bar=None, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Perform repeated k-fold cross-validation with parallel processing\n",
    "    \"\"\"\n",
    "    rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "    \n",
    "    # Create a list of fold parameters\n",
    "    fold_params = []\n",
    "    for fold_idx, (train_index, test_index) in enumerate(rkf.split(X, y)):\n",
    "        fold_params.append((fold_idx, train_index, test_index))\n",
    "    \n",
    "    # Process folds in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_fold)(\n",
    "            fold_idx, train_index, test_index, X, y, model, \n",
    "            use_augmentation, target_size, visualize_first_fold\n",
    "        ) for fold_idx, train_index, test_index in fold_params\n",
    "    )\n",
    "    \n",
    "    # Extract metrics from results\n",
    "    accuracy_train = [r[0] for r in results]\n",
    "    accuracy_test = [r[1] for r in results]\n",
    "    f1 = [r[2] for r in results]\n",
    "    recall = [r[3] for r in results]\n",
    "    roc_auc = [r[4] for r in results]\n",
    "    \n",
    "    # Update the global progress bar if provided\n",
    "    if progress_bar is not None:\n",
    "        progress_bar.update(len(fold_params))\n",
    "\n",
    "    return {\n",
    "        \"Train Accuracy\": (np.mean(accuracy_train), np.std(accuracy_train)),\n",
    "        \"Test Accuracy\": (np.mean(accuracy_test), np.std(accuracy_test)),\n",
    "        \"F1-Score\": (np.mean(f1), np.std(f1)),\n",
    "        \"Recall\": (np.mean(recall), np.std(recall)),\n",
    "        \"ROC-AUC\": (np.nanmean(roc_auc), np.nanstd(roc_auc)),\n",
    "    }\n",
    "\n",
    "\n",
    "#############################################\n",
    "# HAUPT-EXECUTION: MODELLE VERGLEICHEN\n",
    "#############################################\n",
    "if __name__ == '__main__':\n",
    "    # ---------------------------------------------\n",
    "    # 1. Datensatz laden\n",
    "    # ---------------------------------------------\n",
    "    file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_neu.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading dataset from {file_path}...\")\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(f\"Dataset loaded. Shape: {df.shape}\")\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        # 2. Zielvariable und Feature-Matrix erstellen\n",
    "        # ---------------------------------------------\n",
    "        y = df['Verletzungsstatus']\n",
    "        \n",
    "        # Prüfen, ob \"Geschlecht_weiblich\" existiert\n",
    "        if 'Geschlecht_weiblich' in df.columns:\n",
    "            print(\"Gender column 'Geschlecht_weiblich' found in dataset.\")\n",
    "            X_df = df.drop(columns=['Verletzungsstatus'])  # Alles außer Zielvariable\n",
    "        else:\n",
    "            print(\"No gender column found in dataset.\")\n",
    "            X_df = df.drop(columns=['Verletzungsstatus'])  # Alles außer Zielvariable\n",
    "\n",
    "        print(\"\\nData Overview:\")\n",
    "        print(f\"Total samples: {len(df)}\")\n",
    "        print(f\"Features: {X_df.shape[1]}\")\n",
    "        print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        # 3. Erste Visualisierung der Daten\n",
    "        # ---------------------------------------------\n",
    "        # print(\"\\nVisualizing original data distributions...\")\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # sns.countplot(x=y)\n",
    "        # plt.title('Target Variable Distribution')\n",
    "        # plt.show()\n",
    "\n",
    "        # # Beispielhafte Feature-Visualisierung\n",
    "        # num_features_to_show = min(5, X_df.shape[1])\n",
    "        # cols_to_plot = X_df.columns[:num_features_to_show]\n",
    "        \n",
    "        # plt.figure(figsize=(15, 10))\n",
    "        # for i, col in enumerate(cols_to_plot):\n",
    "        #     plt.subplot(2, 3, i + 1)\n",
    "        #     if X_df[col].nunique() < 10:  # Für kategorische Spalten\n",
    "        #         sns.countplot(x=X_df[col])\n",
    "        #     else:\n",
    "        #         sns.histplot(X_df[col], kde=True)\n",
    "        #     plt.title(f'Distribution of {col}')\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        # 4. Modelle definieren mit n_jobs=-1 für parallele Verarbeitung\n",
    "        # ---------------------------------------------\n",
    "        print(\"\\nDefining models with parallel processing...\")\n",
    "        models = {\n",
    "            \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1),\n",
    "            \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "            \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "            \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "            \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42, n_jobs=-1),\n",
    "            \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42, n_jobs=-1),\n",
    "            \"SVC\": SVC(probability=True, random_state=42),\n",
    "            \"k-Nearest Neighbors\": KNeighborsClassifier(n_jobs=-1),\n",
    "            \"MLP Classifier\": MLPClassifier(max_iter=1000, random_state=42),\n",
    "            \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "            \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "            \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "            \"Bagging Classifier\": BaggingClassifier(random_state=42, n_jobs=-1),\n",
    "            \"Extra Trees\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "        }\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        # 5. Augmentationseinstellungen\n",
    "        # ---------------------------------------------\n",
    "        use_augmentation = True\n",
    "        target_size = 1000\n",
    "        visualize_first_fold = True\n",
    "        \n",
    "        # ---------------------------------------------\n",
    "        # 6. Cross-Validation & Modellvergleich\n",
    "        # ---------------------------------------------\n",
    "        results = []\n",
    "        \n",
    "        # Definiere die Werte für n_splits und n_repeats\n",
    "        n_splits = 5\n",
    "        n_repeats = 10\n",
    "        \n",
    "        # Berechne die Gesamtzahl der Iterationen für den Fortschrittsbalken\n",
    "        total_iterations = len(models) * n_splits * n_repeats\n",
    "        \n",
    "        # Globaler Fortschrittsbalken\n",
    "        with tqdm(total=total_iterations, desc=\"Overall Progress\") as global_progress:\n",
    "            for model_name, model in models.items():\n",
    "                # Nur das Modell ausgeben\n",
    "                print(f\"\\nValidating model: {model_name}\")\n",
    "\n",
    "                # Übergebe den Fortschrittsbalken an die Funktion\n",
    "                metrics = repeated_k_fold(\n",
    "                    model, X_df, y,\n",
    "                    n_splits=n_splits,  # explizit übergeben\n",
    "                    n_repeats=n_repeats,  # explizit übergeben\n",
    "                    use_augmentation=use_augmentation,\n",
    "                    target_size=target_size,\n",
    "                    visualize_first_fold=(visualize_first_fold and model_name == list(models.keys())[0]),\n",
    "                    progress_bar=global_progress  # Fortschrittsbalken übergeben\n",
    "                )\n",
    "\n",
    "                # Ergebnisse formatieren\n",
    "                formatted_metrics = {\n",
    "                    \"Model\": model_name,\n",
    "                    \"Train Accuracy\": f\"{metrics['Train Accuracy'][0]:.4f} ± {metrics['Train Accuracy'][1]:.4f}\",\n",
    "                    \"Test Accuracy\": f\"{metrics['Test Accuracy'][0]:.4f} ± {metrics['Test Accuracy'][1]:.4f}\",\n",
    "                    \"F1-Score\": f\"{metrics['F1-Score'][0]:.4f} ± {metrics['F1-Score'][1]:.4f}\",\n",
    "                    \"Recall\": f\"{metrics['Recall'][0]:.4f} ± {metrics['Recall'][1]:.4f}\",\n",
    "                    \"ROC-AUC\": f\"{metrics['ROC-AUC'][0]:.4f} ± {metrics['ROC-AUC'][1]:.4f}\",\n",
    "                }\n",
    "\n",
    "                results.append(formatted_metrics)\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        # 7. Ergebnisübersicht\n",
    "        # ---------------------------------------------\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(by=\"ROC-AUC\", ascending=False)\n",
    "        print(\"\\nModel Performance Summary:\")\n",
    "        print(results_df)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Die Datei wurde nicht gefunden. Bitte überprüfe den Pfad.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ein Fehler ist aufgetreten: {e}\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3dac51-be3e-4cc2-9cf2-164f749a4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "Modellvergleich mit Min-Max-Normalisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd7c5e-3ae3-475e-a8a6-17033f8b3d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "\n",
    "pd.set_option(\"display.width\", 200)\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n",
    "\n",
    "\n",
    "#############################################\n",
    "# HELPER FUNCTIONS FOR VISUALIZATION\n",
    "#############################################\n",
    "\n",
    "def plot_distribution_comparison(X_original, X_augmented, cols_to_plot=None, n_cols=3, figsize=(18, 15)):\n",
    "    \"\"\"\n",
    "    Plot distribution comparison between original and augmented data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_original : DataFrame\n",
    "        Original feature dataframe\n",
    "    X_augmented : DataFrame\n",
    "        Augmented feature dataframe\n",
    "    cols_to_plot : list, optional\n",
    "        List of columns to plot. If None, all columns will be plotted.\n",
    "    n_cols : int, optional\n",
    "        Number of columns in the subplot grid\n",
    "    figsize : tuple, optional\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    if cols_to_plot is None:\n",
    "        cols_to_plot = X_original.columns\n",
    "\n",
    "    n_rows = (len(cols_to_plot) + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(cols_to_plot):\n",
    "        ax = axes[i]\n",
    "        if col == \"Geschlecht_weiblich\":\n",
    "            # For categorical features like gender, use countplot\n",
    "            counts_orig = X_original[col].value_counts().reset_index()\n",
    "            counts_orig.columns = [col, 'count']\n",
    "            counts_orig['Source'] = 'Original'\n",
    "\n",
    "            counts_aug = X_augmented[col].value_counts().reset_index()\n",
    "            counts_aug.columns = [col, 'count']\n",
    "            counts_aug['Source'] = 'Augmented'\n",
    "\n",
    "            counts = pd.concat([counts_orig, counts_aug], ignore_index=True)\n",
    "\n",
    "            sns.barplot(x=col, y='count', hue='Source', data=counts, ax=ax)\n",
    "            ax.set_xlabel('Gender (Female=1)')\n",
    "        else:\n",
    "            # For continuous features, use KDE plots\n",
    "            if X_original[col].nunique() > 1:  # Nur plotten, wenn mehr als 1 Wert vorhanden\n",
    "                sns.kdeplot(X_original[col], label='Original', ax=ax, color='blue', fill=True)\n",
    "            if X_augmented[col].nunique() > 1:  # Nur plotten, wenn mehr als 1 Wert vorhanden\n",
    "                sns.kdeplot(X_augmented[col], label='Augmented', ax=ax, color='red', fill=True)\n",
    "\n",
    "        ax.set_title(f'Distribution of {col}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for i in range(len(cols_to_plot), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "#############################################\n",
    "# AUGMENTATIONSMETHODEN\n",
    "#############################################\n",
    "\n",
    "### 1. Cluster-basierte Augmentation (ohne zusätzliches Rauschen)\n",
    "def perform_clustering(X_sub, max_clusters=4):\n",
    "    # Wähle alle numerischen Spalten außer den Gruppierungsvariablen\n",
    "    cols = [col for col in X_sub.columns if col not in [\"Verletzungsstatus\", \"Geschlecht_weiblich\"]]\n",
    "    X_num = X_sub[cols]\n",
    "    # Berechne die (absoluten) Korrelationen und transformiere in Distanzen\n",
    "    corr = X_num.corr().abs()\n",
    "    dist = np.clip(1 - corr, a_min=0, a_max=None)\n",
    "    dists = squareform(dist.values)\n",
    "    Z = linkage(dists, method='ward')\n",
    "    cluster_labels = fcluster(Z, max_clusters, criterion='maxclust')\n",
    "    clusters = {}\n",
    "    for col, label in zip(cols, cluster_labels):\n",
    "        clusters.setdefault(label, []).append(col)\n",
    "    return clusters\n",
    "\n",
    "def augment_subgroup(X_sub, clusters, p_augment=0.7):\n",
    "    # Für jede Cluster-Gruppe: berechne Mittelwert und Kovarianzmatrix\n",
    "    augmented_rows = []\n",
    "    cluster_params = {}\n",
    "    for cl_id, cols in clusters.items():\n",
    "        cluster_data = X_sub[cols]\n",
    "        mu = cluster_data.mean().values\n",
    "        if len(cols) == 1:\n",
    "            cov = np.cov(cluster_data.values.flatten(), ddof=0)\n",
    "            cov = np.atleast_2d(cov)\n",
    "        else:\n",
    "            cov = np.cov(cluster_data.values, rowvar=False)\n",
    "        cluster_params[cl_id] = (mu, cov, cols)\n",
    "    # Für jede Zeile werden für jede Cluster-Gruppe (stochastisch) neue Werte gezogen\n",
    "    for idx, row in X_sub.iterrows():\n",
    "        new_row = row.copy()\n",
    "        for cl_id, (mu, cov, cols) in cluster_params.items():\n",
    "            if np.random.rand() < p_augment:\n",
    "                new_values = np.random.multivariate_normal(mu, cov)\n",
    "                for col, val in zip(cols, new_values):\n",
    "                    new_row[col] = val\n",
    "        augmented_rows.append(new_row)\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    for col in [\"Geschlecht_weiblich\", \"Verletzungsstatus\"]:\n",
    "        if col in augmented_df.columns:\n",
    "            augmented_df[col] = augmented_df[col].astype(int)\n",
    "    return augmented_df\n",
    "\n",
    "# Parallel processing for augmenting one group\n",
    "def process_group_cluster(group_df, num_new_samples, max_clusters, p_augment):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    clusters = perform_clustering(group_df, max_clusters=max_clusters)\n",
    "    aug_list = []\n",
    "    for _ in range(num_new_samples):\n",
    "        aug = augment_subgroup(group_df, clusters, p_augment=p_augment)\n",
    "        aug_list.append(aug)\n",
    "    aug_group = pd.concat(aug_list, axis=0)\n",
    "    return aug_group\n",
    "\n",
    "def augment_training_data_cluster(X_train, y_train, num_new_samples=1, max_clusters=4, p_augment=0.7, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Augmentiert die Trainingsdaten nach dem Cluster-Ansatz mit paralleler Verarbeitung.\n",
    "    num_new_samples gibt an, wie viele augmentierte Samples pro Originalzeile generiert werden.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    \n",
    "    # Prepare groups for parallel processing\n",
    "    groups = []\n",
    "    for key, group_df in df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        groups.append(group_df)\n",
    "    \n",
    "    # Process groups in parallel\n",
    "    augmented_groups = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_group_cluster)(\n",
    "            group_df, num_new_samples, max_clusters, p_augment\n",
    "        ) for group_df in groups\n",
    "    )\n",
    "        \n",
    "    augmented_df = pd.concat(augmented_groups, axis=0).reset_index(drop=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "\n",
    "### 2. Cluster-basierte Augmentation mit Rauschen\n",
    "def add_noise_to_data(df, noise_factor=0.1):\n",
    "    df_noisy = df.copy()\n",
    "    numeric_cols = [col for col in df_noisy.select_dtypes(include=['float64', 'int64']).columns \n",
    "                    if col not in [\"Geschlecht_weiblich\", \"Verletzungsstatus\"]]\n",
    "    for col in numeric_cols:\n",
    "        std = df_noisy[col].std()\n",
    "        noise = np.random.normal(0, std * noise_factor, size=df_noisy.shape[0])\n",
    "        df_noisy[col] += noise\n",
    "    return df_noisy\n",
    "\n",
    "def add_noise_to_group(df_group, noise_factor=0.1):\n",
    "    # Hier wird einfach die oben definierte Funktion genutzt\n",
    "    return add_noise_to_data(df_group, noise_factor=noise_factor)\n",
    "\n",
    "# Parallel processing for cluster with noise\n",
    "def process_group_cluster_noise(group_df, num_new_samples, max_clusters, p_augment, noise_factor):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    clusters = perform_clustering(group_df, max_clusters=max_clusters)\n",
    "    aug_list = []\n",
    "    for _ in range(num_new_samples):\n",
    "        aug = augment_subgroup(group_df, clusters, p_augment=p_augment)\n",
    "        aug_list.append(aug)\n",
    "    aug_group = pd.concat(aug_list, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Wende Rauschen an: teile die augmentierten Daten in zwei Hälften\n",
    "    n = len(aug_group)\n",
    "    half = n // 2\n",
    "    global_noise = add_noise_to_data(aug_group.copy(), noise_factor=noise_factor)\n",
    "    group_noise = add_noise_to_group(aug_group.copy(), noise_factor=noise_factor)\n",
    "    # Nehme jeweils die erste Hälfte (bei ungerader Anzahl wird der Rest ignoriert)\n",
    "    aug_noisy = pd.concat([global_noise.iloc[:half], group_noise.iloc[:half]], axis=0)\n",
    "    return aug_noisy\n",
    "\n",
    "def augment_training_data_cluster_noise(X_train, y_train, num_new_samples=1, max_clusters=4, p_augment=0.7, noise_factor=0.1, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Wie augment_training_data_cluster, jedoch wird auf den erzeugten augmentierten Samples\n",
    "    zusätzlich Rauschen angehängt – zur Hälfte global und zur Hälfte gruppenspezifisch.\n",
    "    Parallele Verarbeitung mit n_jobs.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    \n",
    "    # Prepare groups for parallel processing\n",
    "    groups = []\n",
    "    for key, group_df in df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"]):\n",
    "        groups.append(group_df)\n",
    "    \n",
    "    # Process groups in parallel\n",
    "    augmented_groups = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_group_cluster_noise)(\n",
    "            group_df, num_new_samples, max_clusters, p_augment, noise_factor\n",
    "        ) for group_df in groups\n",
    "    )\n",
    "        \n",
    "    augmented_df = pd.concat(augmented_groups, axis=0).reset_index(drop=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "\n",
    "### 3. Augmentation über Mittelwert-Bildung (Gruppenmittelwerte)\n",
    "\n",
    "# Function to process a single group with mean-based augmentation\n",
    "def process_group_means(group_df, group_new_samples):\n",
    "    group_df = group_df.reset_index(drop=True)\n",
    "    new_group_samples = []\n",
    "    for _ in range(group_new_samples):\n",
    "        sample_indices = np.random.choice(len(group_df), 2, replace=False)\n",
    "        sample1 = group_df.iloc[sample_indices[0]]\n",
    "        sample2 = group_df.iloc[sample_indices[1]]\n",
    "        mean_sample = sample1.copy()\n",
    "        numeric_cols = [col for col in group_df.columns if col != \"Geschlecht_weiblich\"]\n",
    "        for col in numeric_cols:\n",
    "            mean_sample[col] = (sample1[col] + sample2[col]) / 2\n",
    "        new_group_samples.append(mean_sample)\n",
    "    if new_group_samples:\n",
    "        return pd.DataFrame(new_group_samples)\n",
    "    return None\n",
    "\n",
    "def augment_data_by_group_means(X_train, y_train, augmentation_factor=2, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Augmentiert Daten basierend auf Gruppenmittelwerten mit paralleler Verarbeitung.\n",
    "    Die Augmentation erfolgt innerhalb der Gruppen, die durch 'Verletzungsstatus'\n",
    "    und 'Geschlecht_weiblich' definiert sind.\n",
    "    \"\"\"\n",
    "    df_train = X_train.copy()\n",
    "    df_train[\"Verletzungsstatus\"] = y_train\n",
    "    groups = df_train.groupby([\"Verletzungsstatus\", \"Geschlecht_weiblich\"])\n",
    "    total_original_samples = len(df_train)\n",
    "    total_new_samples = int(total_original_samples * (augmentation_factor - 1))\n",
    "    group_sizes = groups.size()\n",
    "    group_proportions = group_sizes / total_original_samples\n",
    "    \n",
    "    # Prepare tasks for parallel processing\n",
    "    tasks = []\n",
    "    for (injury_status, is_female), group_df in groups:\n",
    "        group_new_samples = int(total_new_samples * group_proportions[(injury_status, is_female)])\n",
    "        tasks.append((group_df, group_new_samples))\n",
    "    \n",
    "    # Process groups in parallel\n",
    "    augmented_groups = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_group_means)(group_df, group_new_samples) \n",
    "        for group_df, group_new_samples in tasks\n",
    "    )\n",
    "    \n",
    "    # Filter out None results\n",
    "    augmented_groups = [group for group in augmented_groups if group is not None]\n",
    "    \n",
    "    augmented_df = pd.concat([df_train] + augmented_groups, ignore_index=True)\n",
    "    y_aug = augmented_df[\"Verletzungsstatus\"]\n",
    "    X_aug = augmented_df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    return X_aug, y_aug\n",
    "\n",
    "\n",
    "def augment_training_data_combined(X_train, y_train, target_size=1000, visualize=False, max_plots=10, verbose=True, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Augment training data with parallel processing\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    N = len(X_train)\n",
    "    additional_needed = max(target_size - N, 0)\n",
    "    per_method_needed = additional_needed // 3\n",
    "\n",
    "    num_new_samples = max(per_method_needed // N, 1)\n",
    "    augmentation_factor = 1 + (per_method_needed / N)\n",
    "\n",
    "    # Remove the print statements if verbose is False\n",
    "    if verbose:\n",
    "        print(f\"Starting combined augmentation to reach target size: {target_size}\")\n",
    "        print(f\"Original dataset size: {N}\")\n",
    "        print(f\"Samples needed per method: {per_method_needed}\")\n",
    "    \n",
    "    # Parallel execution of all three augmentation methods\n",
    "    results = Parallel(n_jobs=min(3, n_jobs))(\n",
    "        delayed(func)(X_train, y_train, **params) for func, params in [\n",
    "            (augment_training_data_cluster, {\"num_new_samples\": num_new_samples, \"n_jobs\": n_jobs}),\n",
    "            (augment_training_data_cluster_noise, {\"num_new_samples\": num_new_samples, \"n_jobs\": n_jobs}),\n",
    "            (augment_data_by_group_means, {\"augmentation_factor\": augmentation_factor, \"n_jobs\": n_jobs})\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X_aug_cluster, y_aug_cluster = results[0]\n",
    "    X_aug_cluster_noise, y_aug_cluster_noise = results[1] \n",
    "    X_aug_group_means, y_aug_group_means = results[2]\n",
    "    \n",
    "    def subsample(X_aug, y_aug, required):\n",
    "        if len(X_aug) > required:\n",
    "            idx = np.random.choice(len(X_aug), required, replace=False)\n",
    "            return X_aug.iloc[idx].reset_index(drop=True), y_aug.iloc[idx].reset_index(drop=True)\n",
    "        else:\n",
    "            return X_aug, y_aug\n",
    "\n",
    "    X_aug_cluster, y_aug_cluster = subsample(X_aug_cluster, y_aug_cluster, per_method_needed)\n",
    "    X_aug_cluster_noise, y_aug_cluster_noise = subsample(X_aug_cluster_noise, y_aug_cluster_noise, per_method_needed)\n",
    "    X_aug_group_means, y_aug_group_means = subsample(X_aug_group_means, y_aug_group_means, per_method_needed)\n",
    "\n",
    "    X_aug_combined = pd.concat([X_aug_cluster, X_aug_cluster_noise, X_aug_group_means], axis=0).reset_index(drop=True)\n",
    "    y_aug_combined = pd.concat([y_aug_cluster, y_aug_cluster_noise, y_aug_group_means], axis=0).reset_index(drop=True)\n",
    "\n",
    "    X_total = pd.concat([X_train.reset_index(drop=True), X_aug_combined], axis=0).reset_index(drop=True)\n",
    "    y_total = pd.concat([y_train.reset_index(drop=True), y_aug_combined], axis=0).reset_index(drop=True)\n",
    "\n",
    "    if len(X_total) > target_size:\n",
    "        idx = np.random.choice(len(X_total), target_size, replace=False)\n",
    "        X_total = X_total.iloc[idx].reset_index(drop=True)\n",
    "        y_total = y_total.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Remove these print statements if verbose is False\n",
    "    if verbose:\n",
    "        print(f\"Augmentation completed. Final dataset size: {len(X_total)}\")\n",
    "        print(f\"Augmentation took {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    if visualize:\n",
    "        if verbose:\n",
    "            print(\"Visualizing distributions of original vs augmented data...\")\n",
    "        cols_to_plot = list(X_train.columns)[:max_plots]\n",
    "        plot_distribution_comparison(X_train, X_aug_combined, cols_to_plot)\n",
    "        plt.suptitle('Feature Distributions: Original vs Augmented Data', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.countplot(x=y_train)\n",
    "        plt.title('Original Target Distribution')\n",
    "        plt.xlabel('Verletzungsstatus')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.countplot(x=y_total)\n",
    "        plt.title('Augmented Target Distribution')\n",
    "        plt.xlabel('Verletzungsstatus')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return X_total, y_total\n",
    "\n",
    "\n",
    "#############################################\n",
    "# MODELLVERGLEICH (REPEATED STRATIFIED CV)\n",
    "#############################################\n",
    "\n",
    "# Function to process a single fold\n",
    "def process_fold(fold_idx, train_index, test_index, X, y, model, use_augmentation, target_size, visualize_first_fold):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    X_test_df = pd.DataFrame(X_test)\n",
    "    \n",
    "    feature_cols = [f\"F{i}\" for i in range(X_train_df.shape[1])]\n",
    "    \n",
    "    gender_col_name = None\n",
    "    gender_col_idx = None\n",
    "    \n",
    "    try:\n",
    "        if isinstance(X, pd.DataFrame) and \"Geschlecht_weiblich\" in X.columns:\n",
    "            gender_col_idx = list(X.columns).index(\"Geschlecht_weiblich\")\n",
    "            feature_cols[gender_col_idx] = \"Geschlecht_weiblich\"\n",
    "            gender_col_name = \"Geschlecht_weiblich\"\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    X_train_df.columns = feature_cols\n",
    "    X_test_df.columns = feature_cols\n",
    "\n",
    "    cols_to_scale = feature_cols\n",
    "    if gender_col_name:\n",
    "        cols_to_scale = [col for col in feature_cols if col != gender_col_name]\n",
    "        \n",
    "    # Änderung hier: Verwende MinMaxScaler statt StandardScaler\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_df[cols_to_scale] = scaler.fit_transform(X_train_df[cols_to_scale])\n",
    "    X_test_df[cols_to_scale] = scaler.transform(X_test_df[cols_to_scale])\n",
    "\n",
    "    if use_augmentation:\n",
    "        visualize_this_fold = visualize_first_fold and fold_idx == 0\n",
    "        X_train_aug, y_train_aug = augment_training_data_combined(\n",
    "            X_train_df, pd.Series(y_train), \n",
    "            target_size=target_size,\n",
    "            visualize=visualize_this_fold,\n",
    "            verbose=False,\n",
    "            n_jobs=-1  # Use parallel processing here too\n",
    "        )\n",
    "    else:\n",
    "        X_train_aug, y_train_aug = X_train_df, pd.Series(y_train)\n",
    "\n",
    "    model.fit(X_train_aug, y_train_aug)\n",
    "    y_train_pred = model.predict(X_train_aug)\n",
    "    y_test_pred = model.predict(X_test_df)\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train_aug, y_train_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    f1_val = f1_score(y_test, y_test_pred)\n",
    "    recall_val = recall_score(y_test, y_test_pred)\n",
    "    \n",
    "    try:\n",
    "        roc_auc_val = roc_auc_score(y_test, model.predict_proba(X_test_df)[:, 1])\n",
    "    except:\n",
    "        roc_auc_val = np.nan\n",
    "\n",
    "    return accuracy_train, accuracy_test, f1_val, recall_val, roc_auc_val\n",
    "\n",
    "def repeated_k_fold(model, X, y, n_splits=5, n_repeats=10, use_augmentation=False, target_size=1000, visualize_first_fold=False, progress_bar=None, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Perform repeated k-fold cross-validation with parallel processing\n",
    "    \"\"\"\n",
    "    rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "    \n",
    "    # Create a list of fold parameters\n",
    "    fold_params = []\n",
    "    for fold_idx, (train_index, test_index) in enumerate(rkf.split(X, y)):\n",
    "        fold_params.append((fold_idx, train_index, test_index))\n",
    "    \n",
    "    # Process folds in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_fold)(\n",
    "            fold_idx, train_index, test_index, X, y, model, \n",
    "            use_augmentation, target_size, visualize_first_fold\n",
    "        ) for fold_idx, train_index, test_index in fold_params\n",
    "    )\n",
    "    \n",
    "    # Extract metrics from results\n",
    "    accuracy_train = [r[0] for r in results]\n",
    "    accuracy_test = [r[1] for r in results]\n",
    "    f1 = [r[2] for r in results]\n",
    "    recall = [r[3] for r in results]\n",
    "    roc_auc = [r[4] for r in results]\n",
    "    \n",
    "    # Update the global progress bar if provided\n",
    "    if progress_bar is not None:\n",
    "        progress_bar.update(len(fold_params))\n",
    "\n",
    "    return {\n",
    "        \"Train Accuracy\": (np.mean(accuracy_train), np.std(accuracy_train)),\n",
    "        \"Test Accuracy\": (np.mean(accuracy_test), np.std(accuracy_test)),\n",
    "        \"F1-Score\": (np.mean(f1), np.std(f1)),\n",
    "        \"Recall\": (np.mean(recall), np.std(recall)),\n",
    "        \"ROC-AUC\": (np.nanmean(roc_auc), np.nanstd(roc_auc)),\n",
    "    }\n",
    "\n",
    "\n",
    "#############################################\n",
    "# HAUPT-EXECUTION: MODELLE VERGLEICHEN\n",
    "#############################################\n",
    "if __name__ == '__main__':\n",
    "    # ---------------------------------------------\n",
    "    # 1. Datensatz laden\n",
    "    # ---------------------------------------------\n",
    "    file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML_neu.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading dataset from {file_path}...\")\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(f\"Dataset loaded. Shape: {df.shape}\")\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        # 2. Zielvariable und Feature-Matrix erstellen\n",
    "        # ---------------------------------------------\n",
    "        y = df['Verletzungsstatus']\n",
    "        \n",
    "        # Prüfen, ob \"Geschlecht_weiblich\" existiert\n",
    "        if 'Geschlecht_weiblich' in df.columns:\n",
    "            print(\"Gender column 'Geschlecht_weiblich' found in dataset.\")\n",
    "            X_df = df.drop(columns=['Verletzungsstatus'])  # Alles außer Zielvariable\n",
    "        else:\n",
    "            print(\"No gender column found in dataset.\")\n",
    "            X_df = df.drop(columns=['Verletzungsstatus'])  # Alles außer Zielvariable\n",
    "\n",
    "        print(\"\\nData Overview:\")\n",
    "        print(f\"Total samples: {len(df)}\")\n",
    "        print(f\"Features: {X_df.shape[1]}\")\n",
    "        print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        # 3. Erste Visualisierung der Daten\n",
    "        # ---------------------------------------------\n",
    "        # print(\"\\nVisualizing original data distributions...\")\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # sns.countplot(x=y)\n",
    "        # plt.title('Target Variable Distribution')\n",
    "        # plt.show()\n",
    "\n",
    "        # # Beispielhafte Feature-Visualisierung\n",
    "        # num_features_to_show = min(5, X_df.shape[1])\n",
    "        # cols_to_plot = X_df.columns[:num_features_to_show]\n",
    "        \n",
    "        # plt.figure(figsize=(15, 10))\n",
    "        # for i, col in enumerate(cols_to_plot):\n",
    "        #     plt.subplot(2, 3, i + 1)\n",
    "        #     if X_df[col].nunique() < 10:  # Für kategorische Spalten\n",
    "        #         sns.countplot(x=X_df[col])\n",
    "        #     else:\n",
    "        #         sns.histplot(X_df[col], kde=True)\n",
    "        #     plt.title(f'Distribution of {col}')\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        # 4. Modelle definieren mit n_jobs=-1 für parallele Verarbeitung\n",
    "        # ---------------------------------------------\n",
    "        print(\"\\nDefining models with parallel processing...\")\n",
    "        models = {\n",
    "            \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1),\n",
    "            \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "            \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "            \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "            \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42, n_jobs=-1),\n",
    "            \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42, n_jobs=-1),\n",
    "            \"SVC\": SVC(probability=True, random_state=42),\n",
    "            \"k-Nearest Neighbors\": KNeighborsClassifier(n_jobs=-1),\n",
    "            \"MLP Classifier\": MLPClassifier(max_iter=1000, random_state=42),\n",
    "            \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "            \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "            \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "            \"Bagging Classifier\": BaggingClassifier(random_state=42, n_jobs=-1),\n",
    "            \"Extra Trees\": ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "        }\n",
    "\n",
    "        # ---------------------------------------------\n",
    "        # 5. Augmentationseinstellungen\n",
    "        # ---------------------------------------------\n",
    "        use_augmentation = True\n",
    "        target_size = 1000\n",
    "        visualize_first_fold = True\n",
    "        \n",
    "        # ---------------------------------------------\n",
    "        # 6. Cross-Validation & Modellvergleich\n",
    "        # ---------------------------------------------\n",
    "        results = []\n",
    "        \n",
    "        # Definiere die Werte für n_splits und n_repeats\n",
    "        n_splits = 5\n",
    "        n_repeats = 10\n",
    "        \n",
    "        # Berechne die Gesamtzahl der Iterationen für den Fortschrittsbalken\n",
    "        total_iterations = len(models) * n_splits * n_repeats\n",
    "        \n",
    "        # Globaler Fortschrittsbalken\n",
    "        with tqdm(total=total_iterations, desc=\"Overall Progress\") as global_progress:\n",
    "            for model_name, model in models.items():\n",
    "                # Nur das Modell ausgeben\n",
    "                print(f\"\\nValidating model: {model_name}\")\n",
    "\n",
    "                # Übergebe den Fortschrittsbalken an die Funktion\n",
    "                metrics = repeated_k_fold(\n",
    "                    model, X_df, y,\n",
    "                    n_splits=n_splits,  # explizit übergeben\n",
    "                    n_repeats=n_repeats,  # explizit übergeben\n",
    "                    use_augmentation=use_augmentation,\n",
    "                    target_size=target_size,\n",
    "                    visualize_first_fold=(visualize_first_fold and model_name == list(models.keys())[0]),\n",
    "                    progress_bar=global_progress  # Fortschrittsbalken übergeben\n",
    "                )\n",
    "\n",
    "                # Ergebnisse formatieren\n",
    "                formatted_metrics = {\n",
    "                    \"Model\": model_name,\n",
    "                    \"Train Accuracy\": f\"{metrics['Train Accuracy'][0]:.4f} ± {metrics['Train Accuracy'][1]:.4f}\",\n",
    "                    \"Test Accuracy\": f\"{metrics['Test Accuracy'][0]:.4f} ± {metrics['Test Accuracy'][1]:.4f}\",\n",
    "                    \"F1-Score\": f\"{metrics['F1-Score'][0]:.4f} ± {metrics['F1-Score'][1]:.4f}\",\n",
    "                    \"Recall\": f\"{metrics['Recall'][0]:.4f} ± {metrics['Recall'][1]:.4f}\",\n",
    "                    \"ROC-AUC\": f\"{metrics['ROC-AUC'][0]:.4f} ± {metrics['ROC-AUC'][1]:.4f}\",\n",
    "                }\n",
    "\n",
    "                results.append(formatted_metrics)\n",
    "                \n",
    "        # ---------------------------------------------\n",
    "        # 7. Ergebnisübersicht\n",
    "        # ---------------------------------------------\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(by=\"ROC-AUC\", ascending=False)\n",
    "        print(\"\\nModel Performance Summary:\")\n",
    "        print(results_df)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Die Datei wurde nicht gefunden. Bitte überprüfe den Pfad.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ein Fehler ist aufgetreten: {e}\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985f03b-b552-46cd-ac29-5dea120106ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
